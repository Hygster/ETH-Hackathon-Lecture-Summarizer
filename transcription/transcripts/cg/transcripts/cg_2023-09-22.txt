
[00:00:00.000 --> 00:00:02.240]   - Great, hello everyone.
[00:00:02.240 --> 00:00:07.240]   Welcome to Advanced Computer Graphics, 2023 edition.
[00:00:07.240 --> 00:00:09.040]   My name is Daniel.
[00:00:09.040 --> 00:00:14.520]   I am a PhD student at the Computer Graphics Lab,
[00:00:14.520 --> 00:00:19.060]   and I'm one of the TAs for this class.
[00:00:19.060 --> 00:00:21.920]   The other TAs are out there in the corner watching.
[00:00:21.920 --> 00:00:25.040]   You'll get to know them over the course of the next few months.
[00:00:25.040 --> 00:00:27.620]   (gentle music)
[00:00:28.620 --> 00:00:31.660]   (gentle music)
[00:00:31.660 --> 00:00:34.340]   And it's my pleasure to give you this first
[00:00:34.340 --> 00:00:38.500]   introductory tutorial session.
[00:00:38.500 --> 00:00:43.220]   So what we'll cover is some basic information
[00:00:43.220 --> 00:00:46.900]   about the course, some background about
[00:00:46.900 --> 00:00:50.500]   what we'll be learning, and then an explanation
[00:00:50.500 --> 00:00:55.500]   of the Norry program, which we'll be working with
[00:00:55.580 --> 00:00:59.760]   during this course to implement our path tracing renderers.
[00:00:59.760 --> 00:01:05.620]   Basic info, I think you've all found this room,
[00:01:05.620 --> 00:01:07.780]   so I don't need to repeat this.
[00:01:07.780 --> 00:01:12.940]   Evaluation is an exam at the end of the course,
[00:01:12.940 --> 00:01:17.300]   as well as 50% in the assignments that we do.
[00:01:17.300 --> 00:01:22.220]   The homework counts for 50%, 20 of that will be
[00:01:22.220 --> 00:01:26.740]   the first four exercises, and 30% a final project,
[00:01:26.740 --> 00:01:29.140]   where you have a bit more freedom to choose
[00:01:29.140 --> 00:01:30.900]   features that you want to implement.
[00:01:30.900 --> 00:01:36.420]   In these sessions, we will mainly be doing a Q&A,
[00:01:36.420 --> 00:01:38.340]   where you can ask us questions about things
[00:01:38.340 --> 00:01:41.100]   you don't understand, things that aren't working
[00:01:41.100 --> 00:01:44.600]   with the assignments, and when a new assignment comes out,
[00:01:44.600 --> 00:01:48.580]   we'll also tell you some information about it
[00:01:48.580 --> 00:01:52.100]   that might help you solve it more quickly.
[00:01:53.100 --> 00:01:57.620]   Needless to say, we have a zero tolerance for cheating,
[00:01:57.620 --> 00:02:02.140]   so we have plagiarism detector that will validate
[00:02:02.140 --> 00:02:04.700]   your code against the code of other students,
[00:02:04.700 --> 00:02:06.900]   as well as of previous students,
[00:02:06.900 --> 00:02:10.100]   so just don't copy other people's code.
[00:02:10.100 --> 00:02:16.920]   Rendering competition, questions at the end.
[00:02:16.920 --> 00:02:20.940]   A rendering competition, now this is the
[00:02:21.940 --> 00:02:24.580]   you could say, what do they call it?
[00:02:24.580 --> 00:02:27.500]   The Academy Awards of the Computer Graphics course.
[00:02:27.500 --> 00:02:31.580]   You have complete freedom to choose and design
[00:02:31.580 --> 00:02:35.340]   an image that you will render, and you will render it
[00:02:35.340 --> 00:02:37.460]   with the software that you've created.
[00:02:37.460 --> 00:02:40.900]   There's a theme every year, which we will disclose
[00:02:40.900 --> 00:02:45.340]   to you later, and as mentioned, you'll be able to
[00:02:45.340 --> 00:02:50.260]   decide which features you want for the image that you want.
[00:02:51.260 --> 00:02:54.820]   We'll have judges come from industry,
[00:02:54.820 --> 00:02:56.820]   and we always give very nice prizes,
[00:02:56.820 --> 00:02:59.300]   which I'm very jealous of.
[00:02:59.300 --> 00:03:01.380]   There's no prizes for the best, here is the.
[00:03:01.380 --> 00:03:06.260]   Here's some images that you might have seen
[00:03:06.260 --> 00:03:08.460]   in the lectures already of previous winners.
[00:03:08.460 --> 00:03:11.500]   These are some really wonderful images
[00:03:11.500 --> 00:03:16.260]   that people create every year, and there's always
[00:03:16.260 --> 00:03:18.980]   an aesthetic component, as well as a technical component,
[00:03:18.980 --> 00:03:21.900]   so here you can see the very complex atmosphere
[00:03:21.900 --> 00:03:23.060]   around the planet.
[00:03:23.060 --> 00:03:27.460]   That's probably heterogeneous volume.
[00:03:27.460 --> 00:03:32.180]   Here we have a lovely scene with a typewriter,
[00:03:32.180 --> 00:03:36.740]   with the wood material, this very nice texture.
[00:03:36.740 --> 00:03:40.660]   Here's another winner, where we have this
[00:03:40.660 --> 00:03:44.340]   quite cute looking pumpkin with a cat.
[00:03:47.660 --> 00:03:50.660]   We had a forest theme, so I think this was
[00:03:50.660 --> 00:03:54.500]   the theme of seasons, and the grass here
[00:03:54.500 --> 00:03:55.980]   was procedurally generated.
[00:03:55.980 --> 00:03:58.620]   You can see a lot of complex details in it.
[00:03:58.620 --> 00:04:04.980]   Another year's winner was this quite abstract
[00:04:04.980 --> 00:04:09.980]   imaginative scene, where I think the theme was opposites.
[00:04:09.980 --> 00:04:14.660]   So you can see a piece of land in the sky
[00:04:14.660 --> 00:04:16.260]   where it doesn't really belong.
[00:04:17.180 --> 00:04:19.860]   And the technical aspects of it were
[00:04:19.860 --> 00:04:22.300]   some participating media for the water,
[00:04:22.300 --> 00:04:24.260]   volumetric rendering for the clouds,
[00:04:24.260 --> 00:04:26.820]   as well as a very complex modeling of the trees
[00:04:26.820 --> 00:04:28.220]   and the foliage.
[00:04:28.220 --> 00:04:34.420]   From 2020, we had this very well composed rocket scene.
[00:04:34.420 --> 00:04:36.100]   I mean, this looks fantastic.
[00:04:36.100 --> 00:04:40.100]   And as well as this example of a water splash
[00:04:40.100 --> 00:04:43.980]   in a, inside of a room you'll become very familiar with.
[00:04:45.940 --> 00:04:49.340]   And this was one of the winners because
[00:04:49.340 --> 00:04:52.260]   the implementation that it takes to create these
[00:04:52.260 --> 00:04:56.140]   caustics, these reflections and refractions of light.
[00:04:56.140 --> 00:04:59.100]   Hey, that's not easy.
[00:04:59.100 --> 00:05:03.580]   So you can perform great in the rendering competition
[00:05:03.580 --> 00:05:06.500]   with a mixture of both technical prowess
[00:05:06.500 --> 00:05:09.020]   and artistic skill.
[00:05:09.020 --> 00:05:12.300]   And we look forward to seeing what you do.
[00:05:12.300 --> 00:05:14.540]   Last year's winners, we have here.
[00:05:15.820 --> 00:05:18.820]   With a very imaginative scene.
[00:05:18.820 --> 00:05:21.900]   The theme was, can you remind me again?
[00:05:21.900 --> 00:05:26.860]   Out of place, which amount in a terrarium.
[00:05:26.860 --> 00:05:28.460]   Oh, that fits.
[00:05:28.460 --> 00:05:31.980]   So that's the rendering competition.
[00:05:31.980 --> 00:05:35.420]   This is what we'll be working on
[00:05:35.420 --> 00:05:36.740]   before the rendering competition.
[00:05:36.740 --> 00:05:39.340]   Well, not actually, but it's similar.
[00:05:39.340 --> 00:05:40.940]   And there's the famous Cornell box,
[00:05:40.940 --> 00:05:43.580]   which you're probably familiar with.
[00:05:43.580 --> 00:05:44.980]   There'll be a lot of that.
[00:05:45.980 --> 00:05:48.980]   What you should know already is C++ programming,
[00:05:48.980 --> 00:05:52.140]   mainly, that is the big thing that,
[00:05:52.140 --> 00:05:57.180]   if you're a bit rusty on it, I recommend revising.
[00:05:57.180 --> 00:05:59.620]   But you'll get to know more as the course progresses
[00:05:59.620 --> 00:06:02.620]   by bashing your head against our renderer.
[00:06:02.620 --> 00:06:08.380]   Now, the code can be found on GitLab.
[00:06:08.380 --> 00:06:11.540]   We have a base repository.
[00:06:11.540 --> 00:06:14.100]   And for each of you, we will make a fork of that,
[00:06:14.100 --> 00:06:16.340]   which you can find at this address.
[00:06:16.340 --> 00:06:20.100]   So you can follow that.
[00:06:20.100 --> 00:06:23.780]   If you have a problem, if the repository isn't there yet,
[00:06:23.780 --> 00:06:26.660]   contact our IT genius Carlos,
[00:06:26.660 --> 00:06:28.420]   and he'll try to sort you out.
[00:06:28.420 --> 00:06:33.540]   We'll issue more instructions
[00:06:33.540 --> 00:06:36.420]   about how to submit your projects, et cetera,
[00:06:36.420 --> 00:06:40.860]   in the next class, when exercise one comes out.
[00:06:40.860 --> 00:06:43.300]   And the most important thing we ask of you
[00:06:43.300 --> 00:06:47.340]   is please do not open source your solution code,
[00:06:47.340 --> 00:06:50.660]   because we use these exercises every year for new students,
[00:06:50.660 --> 00:06:54.740]   and we don't want people copying solutions.
[00:06:54.740 --> 00:06:57.620]   Even though your code's gonna be wonderful, I'm sure of it,
[00:06:57.620 --> 00:06:58.620]   keep it to yourselves.
[00:06:58.620 --> 00:07:04.580]   In case you're not familiar with Git or a bit rusty,
[00:07:04.580 --> 00:07:07.340]   there's a nice handbook tutorial, so I recommend that.
[00:07:07.340 --> 00:07:12.740]   And in terms of other infrastructure, we have Moodle,
[00:07:12.740 --> 00:07:15.540]   which we'll use for announcements,
[00:07:15.540 --> 00:07:18.380]   releasing and submitting the homeworks,
[00:07:18.380 --> 00:07:21.340]   and as well as releasing the lecture materials.
[00:07:21.340 --> 00:07:26.500]   Then to provide you with a forum
[00:07:26.500 --> 00:07:29.940]   where you can ask questions about the problems you encounter,
[00:07:29.940 --> 00:07:34.940]   we have GitLab issues on the Nori page.
[00:07:34.940 --> 00:07:39.740]   So the structure is kind of an online Q and A
[00:07:39.740 --> 00:07:42.500]   where you'll be able to post questions,
[00:07:42.500 --> 00:07:44.580]   we encourage all of you to participate,
[00:07:44.580 --> 00:07:47.420]   to solve problems together.
[00:07:47.420 --> 00:07:49.620]   We'll of course be there monitoring it too.
[00:07:49.620 --> 00:07:54.260]   There's a few ground rules, which is one,
[00:07:54.260 --> 00:07:57.180]   no publishing code that is part of your solution.
[00:07:57.180 --> 00:08:02.940]   So no screen shots of error here on line 34.
[00:08:02.940 --> 00:08:06.380]   But posting code of Nori is fine,
[00:08:06.380 --> 00:08:09.700]   and of course posting images that you've rendered
[00:08:09.700 --> 00:08:14.180]   and that look wrong, that is natural and allowed.
[00:08:14.180 --> 00:08:19.100]   Then the book, I think you've heard about it,
[00:08:19.100 --> 00:08:23.100]   it's a very good book, quite dense,
[00:08:23.100 --> 00:08:27.460]   so don't be afraid of while you're doing the course,
[00:08:27.460 --> 00:08:31.180]   it looks a bit intimidating, but it is a very good resource,
[00:08:31.180 --> 00:08:33.940]   especially when you get into the project
[00:08:33.940 --> 00:08:35.300]   or to revision time.
[00:08:37.980 --> 00:08:42.420]   Now in the course, we'll focus mainly on rendering,
[00:08:42.420 --> 00:08:47.420]   so how to generate images from a digital 3D representation
[00:08:47.420 --> 00:08:54.060]   and specifically we'll be looking at light transport,
[00:08:54.060 --> 00:08:56.500]   how light bounces around the scene
[00:08:56.500 --> 00:08:58.300]   and how we can develop algorithms
[00:08:58.300 --> 00:09:02.800]   for tracing the rays of light and getting our images.
[00:09:02.800 --> 00:09:06.900]   I think you've seen this animation before,
[00:09:06.900 --> 00:09:10.460]   essentially what we're trying to do is follow those rays of light
[00:09:10.460 --> 00:09:15.460]   into the camera, except that becomes a little bit inefficient
[00:09:15.460 --> 00:09:19.540]   when we have very far away light sources.
[00:09:19.540 --> 00:09:25.620]   Come on, PowerPoints.
[00:09:25.620 --> 00:09:34.660]   So then it's very hard to hit our cameras,
[00:09:34.660 --> 00:09:37.860]   which is why what we'll do is we'll implement
[00:09:37.860 --> 00:09:40.140]   a path tracing algorithm,
[00:09:40.140 --> 00:09:43.700]   where we shoot rays from cameras into the scene
[00:09:43.700 --> 00:09:48.700]   and accumulate the colors that build up into an image.
[00:09:48.700 --> 00:09:54.540]   There will be four assignments released
[00:09:54.540 --> 00:09:56.380]   on a more or less bi-weekly schedule,
[00:09:56.380 --> 00:09:58.980]   which you'll be able to find online.
[00:09:58.980 --> 00:10:01.500]   We'll start with fundamentals of ray tracing,
[00:10:01.500 --> 00:10:03.180]   where you'll generate an image like this,
[00:10:03.180 --> 00:10:07.340]   which is then using the average visibility integrator.
[00:10:07.340 --> 00:10:12.540]   And then we'll go on to exercise in sampling,
[00:10:12.540 --> 00:10:15.060]   because when you're doing path tracing,
[00:10:15.060 --> 00:10:18.460]   you want to sample from a lot of domains, discs,
[00:10:18.460 --> 00:10:21.100]   hemisphere, spheres, et cetera,
[00:10:21.100 --> 00:10:23.540]   and you need to be able to write algorithms
[00:10:23.540 --> 00:10:27.700]   that can uniformly or with a given distribution sample
[00:10:27.700 --> 00:10:28.740]   from that domain.
[00:10:28.740 --> 00:10:32.220]   Then we get on to slightly nicer images
[00:10:32.220 --> 00:10:34.820]   using Monte Carlo ray tracing,
[00:10:34.820 --> 00:10:35.780]   and you'll learn a bit more
[00:10:35.780 --> 00:10:37.460]   about multiple important sampling,
[00:10:37.460 --> 00:10:42.220]   before finally moving on to global illumination,
[00:10:42.220 --> 00:10:45.380]   which creates much nicer images.
[00:10:45.380 --> 00:10:47.980]   It accumulates light from the whole scene,
[00:10:47.980 --> 00:10:52.980]   and then we set you free to do whatever you feel like
[00:10:52.980 --> 00:10:55.460]   from our curated list of features
[00:10:55.460 --> 00:10:57.060]   that you're able to implement.
[00:10:58.460 --> 00:11:02.900]   And we hope that you can get very creative with it.
[00:11:02.900 --> 00:11:07.900]   So for next week, we'll be doing an intro
[00:11:07.900 --> 00:11:10.180]   into integrators, you'll implement a shape,
[00:11:10.180 --> 00:11:12.980]   and some textures just to get an overview
[00:11:12.980 --> 00:11:16.420]   of the components of Nori.
[00:11:16.420 --> 00:11:20.100]   Here's our schedule.
[00:11:20.100 --> 00:11:22.820]   You can find it online as well.
[00:11:22.820 --> 00:11:25.660]   One thing to mention is there'll probably be
[00:11:25.660 --> 00:11:28.420]   a few special lectures along the way,
[00:11:28.420 --> 00:11:30.940]   and we'll have a special exercise session
[00:11:30.940 --> 00:11:33.860]   where closer to the time of the rendering competition,
[00:11:33.860 --> 00:11:37.380]   we teach you about framing and color theory,
[00:11:37.380 --> 00:11:39.220]   how to compose a beautiful image.
[00:11:39.220 --> 00:11:43.460]   So that's always fun.
[00:11:43.460 --> 00:11:50.660]   And that's the information section of this exercise.
[00:11:50.660 --> 00:11:54.740]   What I'll move on to next is a bit of an overview
[00:11:54.740 --> 00:11:58.660]   of Nori, the pipeline, how the image is created,
[00:11:58.660 --> 00:12:00.020]   how the program works.
[00:12:00.020 --> 00:12:05.220]   Because when you first run it, it looks very simple.
[00:12:05.220 --> 00:12:11.020]   You click a nice button, an interface opens up,
[00:12:11.020 --> 00:12:13.820]   and you get a picture.
[00:12:13.820 --> 00:12:16.860]   And then you look inside of it,
[00:12:16.860 --> 00:12:20.780]   and there's like classes, functions, it's a mess.
[00:12:22.500 --> 00:12:27.500]   So I'll talk to you about how to get from run,
[00:12:27.500 --> 00:12:29.820]   Ignori to the nice picture.
[00:12:29.820 --> 00:12:35.060]   And this hopefully allows you to realize
[00:12:35.060 --> 00:12:38.060]   how your code fits into this grand pipeline,
[00:12:38.060 --> 00:12:39.700]   the integrators that you write,
[00:12:39.700 --> 00:12:42.100]   the samplers, geometry functions, et cetera.
[00:12:42.100 --> 00:12:45.180]   So let's start.
[00:12:45.180 --> 00:12:52.020]   You begin in main.
[00:12:53.020 --> 00:12:55.340]   (audience laughs)
[00:12:55.340 --> 00:12:57.740]   It does a bunch of boilerplate.
[00:12:57.740 --> 00:12:58.980]   That doesn't really matter.
[00:12:58.980 --> 00:13:00.540]   It sets up some gooey elements.
[00:13:00.540 --> 00:13:04.500]   The first interesting part is when you click
[00:13:04.500 --> 00:13:09.500]   on the open XML button, or you launch it with an XML argument.
[00:13:09.500 --> 00:13:16.060]   Inside of this file, more boilerplate.
[00:13:16.060 --> 00:13:21.380]   What's interesting is the render scene method
[00:13:21.380 --> 00:13:22.540]   with render thread.
[00:13:22.540 --> 00:13:25.260]   And that you do with the file name.
[00:13:25.260 --> 00:13:29.620]   And this is where things start to get more interesting.
[00:13:29.620 --> 00:13:33.820]   First of all, you take that file name,
[00:13:33.820 --> 00:13:36.420]   you open the XML file, and you parse it.
[00:13:36.420 --> 00:13:38.820]   Now the XML file contains all the information
[00:13:38.820 --> 00:13:39.660]   about your scene.
[00:13:39.660 --> 00:13:42.340]   It's a representation of the geometry,
[00:13:42.340 --> 00:13:44.820]   the materials, the camera, the lights.
[00:13:44.820 --> 00:13:49.300]   And you load that into a Nori object,
[00:13:49.300 --> 00:13:51.340]   which we represent then as a scene.
[00:13:51.340 --> 00:13:56.900]   From the scene, we get the elements we care about,
[00:13:56.900 --> 00:14:00.660]   integrate this passes, and then we can start thinking
[00:14:00.660 --> 00:14:02.020]   about rendering the image.
[00:14:02.020 --> 00:14:06.700]   To do that, we initiate so-called image blocks.
[00:14:06.700 --> 00:14:09.420]   So what are image blocks?
[00:14:09.420 --> 00:14:13.140]   They're little patches of the image
[00:14:13.140 --> 00:14:16.900]   that you render in parallel, asynchronously.
[00:14:17.740 --> 00:14:21.620]   And then you assemble them into the final image.
[00:14:21.620 --> 00:14:23.740]   So this lets you render more efficiently.
[00:14:23.740 --> 00:14:28.820]   The assembly is a little bit involved.
[00:14:28.820 --> 00:14:30.140]   You don't need to worry about it,
[00:14:30.140 --> 00:14:33.380]   but I'll tell you how it works just for your information.
[00:14:33.380 --> 00:14:39.140]   Essentially, the image blocks, a bit of info,
[00:14:39.140 --> 00:14:41.740]   they extend eigen arrays.
[00:14:41.740 --> 00:14:45.300]   They store the samples of radiance that you compute
[00:14:45.300 --> 00:14:48.060]   by shooting rays into the scene,
[00:14:48.060 --> 00:14:50.140]   and then they calculate that final bitmap.
[00:14:50.140 --> 00:14:58.380]   And you do this process via the render block method,
[00:14:58.380 --> 00:15:02.580]   which takes the scene, a sampler,
[00:15:02.580 --> 00:15:05.580]   for generating random numbers, and the image block.
[00:15:05.580 --> 00:15:11.220]   Now to get that final image, like I said,
[00:15:11.220 --> 00:15:15.900]   we have this master block and block,
[00:15:15.900 --> 00:15:20.220]   and that gives us the final image.
[00:15:20.220 --> 00:15:23.700]   To assemble it, we put smaller blocks
[00:15:23.700 --> 00:15:27.140]   into that large full block.
[00:15:27.140 --> 00:15:31.060]   This is done using the put method.
[00:15:31.060 --> 00:15:32.860]   It does some clever things to keep track
[00:15:32.860 --> 00:15:34.660]   of where each patch should go,
[00:15:34.660 --> 00:15:38.380]   and the small blocks are generated by a block generator
[00:15:38.380 --> 00:15:39.820]   and rendered in parallel.
[00:15:39.820 --> 00:15:43.780]   Once we've rendered many, many blocks,
[00:15:43.780 --> 00:15:46.060]   multiple blocks for each patch of the image
[00:15:46.060 --> 00:15:48.380]   to reduce the noise,
[00:15:48.380 --> 00:15:50.900]   then we can call the two-bitmap method
[00:15:50.900 --> 00:15:52.260]   and we get an image.
[00:15:52.260 --> 00:15:57.900]   And like I said, we render many blocks,
[00:15:57.900 --> 00:16:00.780]   many samples per pixel,
[00:16:00.780 --> 00:16:03.100]   where we sample different light paths
[00:16:03.100 --> 00:16:06.300]   and different camera conditions and average it out.
[00:16:06.300 --> 00:16:08.180]   Well, it's not quite averaging,
[00:16:08.180 --> 00:16:13.180]   it's filtering that gives us a clean denoised image.
[00:16:13.180 --> 00:16:18.860]   So that's what we were doing.
[00:16:18.860 --> 00:16:23.100]   We were, if you recall, in the render scene method.
[00:16:23.100 --> 00:16:26.220]   We passed our file, we made image blocks,
[00:16:26.220 --> 00:16:28.940]   and now we're rendering them in parallel
[00:16:28.940 --> 00:16:31.220]   using the render block method.
[00:16:31.220 --> 00:16:33.140]   And this is where things get really interesting.
[00:16:33.140 --> 00:16:36.700]   This is really inside this method, what you care about.
[00:16:37.660 --> 00:16:41.380]   After this is done, you assemble and save the final image
[00:16:41.380 --> 00:16:43.100]   and then figure out what went wrong.
[00:16:43.100 --> 00:16:49.340]   So how do we actually render the blocks?
[00:16:49.340 --> 00:16:54.340]   Let's get the code up on the screen.
[00:16:54.340 --> 00:16:58.060]   Hopefully it's large enough.
[00:16:58.060 --> 00:17:01.180]   If not, you can find it in your repository.
[00:17:01.180 --> 00:17:04.580]   What we do to render a block
[00:17:05.980 --> 00:17:08.820]   is we loop over all of the pixels
[00:17:08.820 --> 00:17:11.580]   that are contained inside that block.
[00:17:11.580 --> 00:17:12.820]   And for each of those,
[00:17:12.820 --> 00:17:17.940]   we will sample a camera ray.
[00:17:17.940 --> 00:17:22.780]   So what that means is we can decide at random
[00:17:22.780 --> 00:17:26.900]   a position inside the pixel to shoot from and a direction.
[00:17:26.900 --> 00:17:29.740]   And we just choose one.
[00:17:29.740 --> 00:17:33.020]   And this is a ray 3F, so-called.
[00:17:35.860 --> 00:17:40.420]   With that ray, we call the integrator.
[00:17:40.420 --> 00:17:43.140]   Specifically the integrator's LI method.
[00:17:43.140 --> 00:17:46.420]   So we calculate the radiance that you get
[00:17:46.420 --> 00:17:48.980]   from shooting that ray into the scene,
[00:17:48.980 --> 00:17:55.420]   which gives us back a color 3F value
[00:17:55.420 --> 00:18:02.380]   that we then store inside of the block in the buffer
[00:18:02.380 --> 00:18:06.620]   with a weight attached to it to inform the block
[00:18:06.620 --> 00:18:08.540]   how to use that return radiance values
[00:18:08.540 --> 00:18:10.780]   to compute actual pixel colors.
[00:18:10.780 --> 00:18:16.660]   And that's about it.
[00:18:16.660 --> 00:18:19.900]   The important part where you'll be spending most of your time
[00:18:19.900 --> 00:18:22.220]   is inside these integrators.
[00:18:22.220 --> 00:18:26.580]   This technique for shooting a ray into the scene
[00:18:26.580 --> 00:18:28.580]   and getting the color that's returned.
[00:18:31.540 --> 00:18:35.660]   So just to recap, we start nori.
[00:18:35.660 --> 00:18:38.300]   Stuff happens to do GUI.
[00:18:38.300 --> 00:18:39.700]   Then we render the scene.
[00:18:39.700 --> 00:18:43.140]   This opens the scene, creates a bunch of image blocks,
[00:18:43.140 --> 00:18:45.180]   and then we render them.
[00:18:45.180 --> 00:18:48.620]   When we render the blocks, we sample a camera ray,
[00:18:48.620 --> 00:18:53.660]   call the integrator, and repeat this many times.
[00:18:53.660 --> 00:18:58.500]   And your job's mainly in this small part of it.
[00:19:00.740 --> 00:19:05.340]   So that concludes the tutorial of nori.
[00:19:05.340 --> 00:19:07.500]   I can now do a live demo,
[00:19:07.500 --> 00:19:09.820]   but are there any questions at this point
[00:19:09.820 --> 00:19:13.980]   about the structure or nori itself?
[00:19:13.980 --> 00:19:16.100]   Yes?
[00:19:16.100 --> 00:19:21.100]   - What about nori said, how powerful of a computer
[00:19:21.100 --> 00:19:22.180]   do we need to run?
[00:19:22.180 --> 00:19:25.860]   Just to get an idea of the run thing we can expect.
[00:19:27.700 --> 00:19:32.700]   So I think the average laptop from the past five years
[00:19:32.700 --> 00:19:38.540]   should be able to run this reasonably.
[00:19:38.540 --> 00:19:42.340]   Of course, if it's slower, then you wait longer
[00:19:42.340 --> 00:19:43.900]   for your images.
[00:19:43.900 --> 00:19:46.660]   There's also the option, and this is during the assignment,
[00:19:46.660 --> 00:19:48.940]   when you have a lot more complicated features
[00:19:48.940 --> 00:19:51.300]   and complicated geometry,
[00:19:51.300 --> 00:19:54.540]   to render your images on the Euler cluster.
[00:19:54.540 --> 00:19:58.100]   Where, if compute becomes a limitation,
[00:19:58.100 --> 00:20:00.700]   you just slap it on a very large GPU.
[00:20:00.700 --> 00:20:04.300]   CPU.
[00:20:04.300 --> 00:20:07.980]   Any other questions?
[00:20:07.980 --> 00:20:10.180]   Yes?
[00:20:10.180 --> 00:20:12.940]   - Does that mean nori is not GPU accelerated,
[00:20:12.940 --> 00:20:16.380]   or that we don't have access to GPU nodes?
[00:20:16.380 --> 00:20:18.980]   - I think nori isn't GPU accelerated.
[00:20:18.980 --> 00:20:21.060]   Yes, it's CPU based.
[00:20:21.060 --> 00:20:24.180]   - Mm-hmm.
[00:20:25.180 --> 00:20:26.300]   (audience member speaking faintly)
[00:20:26.300 --> 00:20:27.140]   - These slides?
[00:20:27.140 --> 00:20:28.380]   Yes, they will be uploaded.
[00:20:28.380 --> 00:20:34.700]   All right, wonderful.
[00:20:34.700 --> 00:20:38.860]   Well, let's look at how you get nori and compile it.
[00:20:38.860 --> 00:20:42.220]   There's always usually a couple of problems with this.
[00:20:42.220 --> 00:20:46.180]   So, we went through a few of them ourselves
[00:20:46.180 --> 00:20:48.260]   when we tried to compile it before the class,
[00:20:48.260 --> 00:20:52.860]   and hopefully they'll be smoothly addressed.
[00:20:52.860 --> 00:20:57.860]   Well, what you do to get nori is you have to clone it,
[00:20:57.860 --> 00:21:04.940]   which you'll find here.
[00:21:04.940 --> 00:21:08.300]   You can copy that, and then,
[00:21:08.300 --> 00:21:13.620]   now you can see I already cloned it,
[00:21:13.620 --> 00:21:15.980]   which is very bad.
[00:21:15.980 --> 00:21:18.220]   So, we'll delete it, and I'll show you again
[00:21:18.220 --> 00:21:19.860]   how to do all of it.
[00:21:19.860 --> 00:21:24.020]   (audience member speaking faintly)
[00:21:24.020 --> 00:21:28.440]   Well, I didn't like it at all.
[00:21:28.440 --> 00:21:32.440]   Okay.
[00:21:32.440 --> 00:21:40.700]   (audience member speaking faintly)
[00:21:40.700 --> 00:21:41.700]   - Be third.
[00:21:41.700 --> 00:21:47.300]   - It doesn't like that.
[00:21:47.300 --> 00:21:48.140]   It doesn't like that.
[00:21:48.140 --> 00:21:52.420]   It's PowerShell, it's Microsoft.
[00:21:52.420 --> 00:21:53.740]   Why do you do this?
[00:21:53.740 --> 00:21:56.860]   Life demos, all right.
[00:21:56.860 --> 00:22:01.060]   We'll do it that way.
[00:22:01.060 --> 00:22:05.020]   Why do they make us live like this?
[00:22:05.020 --> 00:22:11.620]   All right, all right.
[00:22:11.620 --> 00:22:15.140]   Nope, this is beyond me.
[00:22:15.140 --> 00:22:16.700]   Let's clone another copy.
[00:22:17.700 --> 00:22:20.260]   Which you can do with Visual Studio.
[00:22:20.260 --> 00:22:22.340]   So, I'm running on Windows, as you can see,
[00:22:22.340 --> 00:22:27.980]   and I do recommend using Visual Studio 2022 for this.
[00:22:27.980 --> 00:22:29.780]   It's rather painless,
[00:22:29.780 --> 00:22:33.680]   but of course, we do support other platforms too.
[00:22:33.680 --> 00:22:44.340]   Great.
[00:22:45.220 --> 00:22:48.860]   (audience member speaking faintly)
[00:22:48.860 --> 00:22:49.820]   And then it clones.
[00:22:49.820 --> 00:22:52.660]   It takes a while to download because it is quite large.
[00:22:52.660 --> 00:22:54.620]   Yes?
[00:22:54.620 --> 00:22:58.780]   (audience member speaking faintly)
[00:22:58.780 --> 00:23:05.940]   Visual Studio Code is a text editor
[00:23:05.940 --> 00:23:08.460]   with a lot of powerful plugins.
[00:23:08.460 --> 00:23:14.140]   Visual Studio is a fully fledged C++ IDE.
[00:23:14.740 --> 00:23:17.060]   So, it already comes pre-built with all the features
[00:23:17.060 --> 00:23:20.820]   you might need for CMake, for example,
[00:23:20.820 --> 00:23:22.820]   a lot of support for that.
[00:23:22.820 --> 00:23:25.580]   I think you can do it in Visual Studio Code.
[00:23:25.580 --> 00:23:29.620]   Personally, I haven't tested it,
[00:23:29.620 --> 00:23:32.420]   and it might require a bit more configuration.
[00:23:32.420 --> 00:23:34.580]   But if that's what you know,
[00:23:34.580 --> 00:23:36.700]   I recommend you use that, as always.
[00:23:36.700 --> 00:23:38.740]   Use the tools that you know how to use.
[00:23:38.740 --> 00:23:42.900]   (audience member speaking faintly)
[00:23:42.900 --> 00:23:54.980]   Uh-huh.
[00:23:54.980 --> 00:23:55.980]   It's downloaded.
[00:23:55.980 --> 00:23:59.940]   So, you can see, we start out here
[00:23:59.940 --> 00:24:03.900]   with this annoying view that Microsoft insists we look at.
[00:24:03.900 --> 00:24:06.900]   Then, we click that,
[00:24:06.900 --> 00:24:09.180]   and it shows you the actual folder structure.
[00:24:09.180 --> 00:24:13.900]   Now, you can see the tutorial for this part
[00:24:13.900 --> 00:24:16.620]   on our website.
[00:24:16.620 --> 00:24:19.820]   So, if you go to CGL website,
[00:24:19.820 --> 00:24:24.580]   Teaching, Computer Graphics, and Nori,
[00:24:24.580 --> 00:24:28.700]   you get to this wonderful site
[00:24:28.700 --> 00:24:31.540]   where we have some instructions
[00:24:31.540 --> 00:24:33.420]   on how you can do this yourself
[00:24:33.420 --> 00:24:35.420]   should you wish to follow along later.
[00:24:36.260 --> 00:24:41.260]   We have an intro about Git and the file storage system,
[00:24:41.260 --> 00:24:47.140]   as well as cloning and compilation instructions.
[00:24:47.140 --> 00:24:51.100]   So, what I'm gonna follow is this part here
[00:24:51.100 --> 00:24:54.420]   where we do it on Windows Visual Studio.
[00:24:54.420 --> 00:25:02.380]   And what we want to do is we want to click on the project
[00:25:02.380 --> 00:25:04.700]   and CMake settings.
[00:25:05.700 --> 00:25:09.060]   And it gives us a configuration file
[00:25:09.060 --> 00:25:13.260]   of how to build the CMake project.
[00:25:13.260 --> 00:25:15.220]   There's a few things we might want to change.
[00:25:15.220 --> 00:25:18.300]   So, first of all, you can do a debug run,
[00:25:18.300 --> 00:25:20.060]   but that's very slow.
[00:25:20.060 --> 00:25:23.260]   So, if we click on
[00:25:23.260 --> 00:25:28.020]   Release, we get another build,
[00:25:28.020 --> 00:25:29.980]   relative to that info.
[00:25:29.980 --> 00:25:32.220]   It's a good middle ground.
[00:25:33.260 --> 00:25:37.460]   Then all this is fine, and, oh, errors already.
[00:25:37.460 --> 00:25:39.660]   Good start.
[00:25:39.660 --> 00:25:44.620]   Likely what you might need to do
[00:25:44.620 --> 00:25:45.940]   on the default branches,
[00:25:45.940 --> 00:25:49.140]   switch to one of these other generators.
[00:25:49.140 --> 00:25:55.500]   For example, this one, 64 bit, Visual Studio 17.
[00:25:55.500 --> 00:25:58.900]   And then you can save this
[00:26:01.260 --> 00:26:03.420]   and hope that everything works.
[00:26:03.420 --> 00:26:10.460]   Oh, no.
[00:26:10.460 --> 00:26:17.180]   (man speaking off mic)
[00:26:17.180 --> 00:26:19.220]   Oh, right.
[00:26:19.220 --> 00:26:25.060]   So, we generate our release build
[00:26:25.060 --> 00:26:26.420]   on this, we get rid of.
[00:26:26.420 --> 00:26:29.760]   (man speaking off mic)
[00:26:29.760 --> 00:26:46.020]   And it takes a while.
[00:26:46.020 --> 00:26:54.300]   But it does work.
[00:26:54.820 --> 00:26:58.380]   (man speaking off mic)
[00:26:58.380 --> 00:27:00.620]   Then you can select your startup item,
[00:27:00.620 --> 00:27:05.260]   which will be nori.exe, if it's built already,
[00:27:05.260 --> 00:27:07.940]   which it might not be bad.
[00:27:07.940 --> 00:27:09.260]   Okay.
[00:27:09.260 --> 00:27:10.100]   So,
[00:27:10.100 --> 00:27:13.100]   unless we can build our project.
[00:27:13.100 --> 00:27:16.440]   (man speaking off mic)
[00:27:42.820 --> 00:27:44.900]   And this takes a while for the first time you run it,
[00:27:44.900 --> 00:27:47.260]   because there's a lot of libraries
[00:27:47.260 --> 00:27:50.180]   that we need to compile in the background
[00:27:50.180 --> 00:27:52.940]   for doing the asynchronous computing.
[00:27:52.940 --> 00:27:55.820]   For the GUI, I think, a couple of others.
[00:27:55.820 --> 00:27:59.860]   While that's working, let me tell you about
[00:27:59.860 --> 00:28:03.540]   a nice image viewer that we have for you.
[00:28:03.540 --> 00:28:05.740]   Because you can view images,
[00:28:05.740 --> 00:28:08.140]   your EXR images inside of nori.
[00:28:08.140 --> 00:28:11.860]   And these are images with a much larger dynamic range
[00:28:11.860 --> 00:28:16.700]   than what you can represent in PNGs or JPEGs.
[00:28:16.700 --> 00:28:18.100]   And you need special viewers.
[00:28:18.100 --> 00:28:24.140]   For that, we have TV, which is somewhere mentioned.
[00:28:24.140 --> 00:28:35.740]   Well, not here.
[00:28:35.740 --> 00:28:36.580]   Do we do that?
[00:28:36.580 --> 00:28:38.300]   (man speaking off mic)
[00:28:38.300 --> 00:28:39.140]   Yeah.
[00:28:41.180 --> 00:28:44.940]   We invoke Google and type in TV.
[00:28:44.940 --> 00:28:47.300]   And we don't get the right result
[00:28:47.300 --> 00:28:49.460]   because that is a very generic acronym.
[00:28:49.460 --> 00:28:54.260]   Ah, that's the one.
[00:28:54.260 --> 00:28:57.060]   So you can get this.
[00:28:57.060 --> 00:29:00.660]   It's got some pre-compiled binaries already,
[00:29:00.660 --> 00:29:02.460]   if you're on Windows, which is nice.
[00:29:02.460 --> 00:29:05.500]   And it's this lovely interface,
[00:29:05.500 --> 00:29:10.180]   which allows you to look at EXR images,
[00:29:10.180 --> 00:29:12.020]   adjust how they're displayed,
[00:29:12.020 --> 00:29:14.700]   as well as compare them to one another.
[00:29:14.700 --> 00:29:18.300]   So in your assignments, when you have your image
[00:29:18.300 --> 00:29:20.620]   and the reference, and they don't look the same,
[00:29:20.620 --> 00:29:22.500]   but it's sometimes very hard to tell,
[00:29:22.500 --> 00:29:24.700]   it's very subtle where the errors are.
[00:29:24.700 --> 00:29:27.780]   This allows you to do that,
[00:29:27.780 --> 00:29:30.060]   which I have it downloaded already.
[00:29:30.060 --> 00:29:33.620]   It looks like so.
[00:29:35.380 --> 00:29:40.380]   And if we look at some nice EXR images,
[00:29:40.380 --> 00:29:51.740]   which are contained in here,
[00:29:51.740 --> 00:29:56.340]   you'll be able to see,
[00:29:56.340 --> 00:30:01.340]   reference.
[00:30:02.340 --> 00:30:06.340]   And then you'll have a different kind of sphere.
[00:30:06.340 --> 00:30:08.340]   Hmm, I wonder why that could be.
[00:30:08.340 --> 00:30:11.340]   And when you compare them,
[00:30:11.340 --> 00:30:13.340]   you'll see that there's a difference.
[00:30:13.340 --> 00:30:15.340]   And you'll see that there's a difference.
[00:30:15.340 --> 00:30:17.340]   And you'll see that there's a difference.
[00:30:17.340 --> 00:30:19.340]   And you'll see that there's a difference.
[00:30:19.340 --> 00:30:21.340]   And you'll see that there's a difference.
[00:30:21.340 --> 00:30:23.340]   And you'll see that there's a difference.
[00:30:23.340 --> 00:30:25.340]   And you'll see that there's a difference.
[00:30:25.340 --> 00:30:27.340]   And you'll see that there's a difference.
[00:30:27.340 --> 00:30:29.340]   And you'll see that there's a difference.
[00:30:29.340 --> 00:30:31.340]   And when you compare them,
[00:30:31.340 --> 00:30:34.340]   you can see the difference between the two images,
[00:30:34.340 --> 00:30:36.340]   which, as mentioned before,
[00:30:36.340 --> 00:30:40.340]   is very hard to see in one image alone.
[00:30:40.340 --> 00:30:43.340]   You have a number of different error metrics
[00:30:43.340 --> 00:30:44.340]   that you can use,
[00:30:44.340 --> 00:30:47.340]   which are described when you hover over the image.
[00:30:47.340 --> 00:30:53.340]   And they can help you figure out what is going on,
[00:30:53.340 --> 00:30:55.340]   why are these two different?
[00:30:55.340 --> 00:30:57.340]   We'll find out soon enough.
[00:30:58.340 --> 00:31:03.340]   But, last, going back to Nori.
[00:31:03.340 --> 00:31:06.340]   It's built, and then you can run it.
[00:31:06.340 --> 00:31:09.340]   Select start-up item,
[00:31:09.340 --> 00:31:12.340]   or run it from the command line,
[00:31:12.340 --> 00:31:14.340]   and we should have...
[00:31:14.340 --> 00:31:18.340]   Nori.
[00:31:18.340 --> 00:31:25.340]   Nori.
[00:31:26.340 --> 00:31:28.340]   Nori.
[00:31:28.340 --> 00:31:33.340]   Nori.
[00:31:33.340 --> 00:31:38.340]   Live demos.
[00:31:38.340 --> 00:31:43.340]   It is very...
[00:31:43.340 --> 00:31:47.340]   very insistent.
[00:31:53.340 --> 00:31:55.340]   Any ideas?
[00:31:55.340 --> 00:31:57.340]   Ah, yeah, yeah, yeah, yeah.
[00:31:57.340 --> 00:32:00.340]   Okay, let's try the command line.
[00:32:00.340 --> 00:32:11.340]   So, it'll be an out-build-release.
[00:32:11.340 --> 00:32:15.340]   Nori.
[00:32:22.340 --> 00:32:24.340]   Hmm.
[00:32:24.340 --> 00:32:29.340]   There it is.
[00:32:29.340 --> 00:32:38.340]   Just like that.
[00:32:38.340 --> 00:32:41.340]   Smooth.
[00:32:41.340 --> 00:32:45.340]   And, as I mentioned, we have this interface
[00:32:45.340 --> 00:32:47.340]   where you can render images.
[00:32:47.340 --> 00:32:49.340]   Of course, at the moment, nothing's implemented.
[00:32:49.340 --> 00:32:53.340]   So, if you try to launch anything, it'll give you errors.
[00:32:53.340 --> 00:32:57.340]   What you need to do is you need to follow our tutorial,
[00:32:57.340 --> 00:33:01.340]   and add the first integrator,
[00:33:01.340 --> 00:33:07.340]   which conveniently is already given to you.
[00:33:07.340 --> 00:33:12.340]   And this is a bit of a description about the XML format
[00:33:12.340 --> 00:33:14.340]   that we use for representing scenes.
[00:33:18.340 --> 00:33:23.340]   And then there's a section about making your first Nori class.
[00:33:23.340 --> 00:33:26.340]   So, to do that, we need to...
[00:33:26.340 --> 00:33:29.340]   get into this file
[00:33:29.340 --> 00:33:34.340]   and put this boilerplate in.
[00:33:34.340 --> 00:33:38.340]   And once we do that...
[00:33:46.340 --> 00:33:48.340]   So, that should be source.
[00:33:48.340 --> 00:33:50.340]   And...
[00:33:50.340 --> 00:33:54.340]   Let's see, normal CPP.
[00:33:54.340 --> 00:33:57.340]   There we have it, a blank template.
[00:33:57.340 --> 00:34:03.340]   We can paste this and then have a look at what's going on.
[00:34:03.340 --> 00:34:10.340]   So, you include the integrators,
[00:34:10.340 --> 00:34:14.340]   and each integrator will be an extension of the integrators.
[00:34:15.340 --> 00:34:18.340]   You're able to pass certain properties.
[00:34:18.340 --> 00:34:24.340]   And, as you recall, when we shoot a ray of light,
[00:34:24.340 --> 00:34:28.340]   or a ray from the camera into the scene, we call this Li method.
[00:34:28.340 --> 00:34:35.340]   And the Li method is supposed to return the color that lies along that ray.
[00:34:35.340 --> 00:34:38.340]   So, what do we return here?
[00:34:38.340 --> 00:34:42.340]   We just, for whatever input, return green.
[00:34:44.340 --> 00:34:50.340]   I can think about what the image that we generate from this is going to look like.
[00:34:50.340 --> 00:34:58.340]   And let's try building it and testing it out.
[00:34:58.340 --> 00:35:06.340]   And, as you can see, we've registered this class as a normal integrator.
[00:35:06.340 --> 00:35:11.340]   This allows you to pass it from the config file.
[00:35:11.340 --> 00:35:16.340]   So, we will specify in the XML the normal integrator,
[00:35:16.340 --> 00:35:18.340]   and use this in our scene.
[00:35:18.340 --> 00:35:23.340]   Okay, so you make generation finished.
[00:35:23.340 --> 00:35:25.340]   Let's build.
[00:35:25.340 --> 00:35:43.340]   [silence]
[00:35:43.340 --> 00:35:49.340]   And now, hopefully, with a bit of luck,
[00:35:49.340 --> 00:35:51.340]   Ajax normals should render.
[00:35:51.340 --> 00:35:56.340]   [silence]
[00:35:56.340 --> 00:35:59.340]   Hmm, my property is missing.
[00:35:59.340 --> 00:36:01.340]   Oh, no.
[00:36:01.340 --> 00:36:05.340]   [silence]
[00:36:05.340 --> 00:36:07.340]   What's that about?
[00:36:07.340 --> 00:36:09.340]   Maybe if we remove my property from the XML,
[00:36:09.340 --> 00:36:11.340]   although that's probably not the right approach.
[00:36:11.340 --> 00:36:14.340]   [audience member speaking]
[00:36:14.340 --> 00:36:17.340]   Oh, is it test scene?
[00:36:17.340 --> 00:36:20.340]   Hmm, right.
[00:36:21.340 --> 00:36:24.340]   That's the test scene.
[00:36:24.340 --> 00:36:27.340]   Okay, so you can see spoilers.
[00:36:27.340 --> 00:36:30.340]   When you return green, you get green.
[00:36:30.340 --> 00:36:37.340]   And the scene file for that is this one.
[00:36:37.340 --> 00:36:40.340]   I don't know if that's visible enough.
[00:36:40.340 --> 00:36:42.340]   Hopefully, maybe you can see one.
[00:36:42.340 --> 00:36:45.340]   With the property that we have,
[00:36:45.340 --> 00:36:47.340]   with the integrator that we have,
[00:36:47.340 --> 00:36:50.340]   and with the camera type that we have.
[00:36:50.340 --> 00:37:01.340]   And if we have a more interesting integrator,
[00:37:01.340 --> 00:37:05.340]   such as this one, with our normal scene,
[00:37:05.340 --> 00:37:08.340]   we can actually start rendering scenes.
[00:37:08.340 --> 00:37:10.340]   So what happens here?
[00:37:10.340 --> 00:37:15.340]   In this example, we render the normals
[00:37:15.340 --> 00:37:18.340]   of each surface that we intersect with.
[00:37:18.340 --> 00:37:20.340]   When we shoot a camera ray,
[00:37:20.340 --> 00:37:22.340]   we find the surface that we intersect,
[00:37:22.340 --> 00:37:24.340]   as you can see here.
[00:37:24.340 --> 00:37:27.340]   So, intersect the camera ray with the scene.
[00:37:27.340 --> 00:37:31.340]   If we hit nothing, darkness.
[00:37:31.340 --> 00:37:34.340]   And if we do hit something,
[00:37:34.340 --> 00:37:39.340]   we compute the normal from the shading frame
[00:37:39.340 --> 00:37:41.340]   at the intersection point.
[00:37:41.340 --> 00:37:45.340]   And return it as a color.
[00:37:45.340 --> 00:37:48.340]   So, that's Nori.
[00:37:48.340 --> 00:37:50.340]   That's your first assignment for the week.
[00:37:50.340 --> 00:37:52.340]   Hopefully, not too much.
[00:37:52.340 --> 00:37:56.340]   Hopefully, we'll see you back here in another week
[00:37:56.340 --> 00:37:58.340]   for something a bit more interesting.
[00:37:58.340 --> 00:38:00.340]   And then it gets very interesting.
[00:38:00.340 --> 00:38:04.340]   And then we start having a lot of headaches.
[00:38:04.340 --> 00:38:07.340]   But we'll get there when we get there.
[00:38:07.340 --> 00:38:09.340]   Thank you for your attention.
[00:38:09.340 --> 00:38:13.340]   We'll be available for questions, et cetera, et cetera.
[00:38:14.340 --> 00:38:19.340]   (applause)

