
[00:00:00.000 --> 00:00:03.480]   [MUSIC PLAYING]
[00:00:03.480 --> 00:00:10.840]   OK, good afternoon.
[00:00:10.840 --> 00:00:12.560]   First announcement next week.
[00:00:12.560 --> 00:00:14.360]   I will not be here.
[00:00:14.360 --> 00:00:18.240]   And one of my postdocs will teach instead of me, Zuri
[00:00:18.240 --> 00:00:19.880]   Abaur.
[00:00:19.880 --> 00:00:23.160]   So she will be teaching.
[00:00:23.160 --> 00:00:26.880]   OK, so we continue on segmentation.
[00:00:26.880 --> 00:00:28.760]   This is one of the main concepts we looked at.
[00:00:28.760 --> 00:00:34.280]   If we have segmentation, we try to tune a system
[00:00:34.280 --> 00:00:36.280]   to make the right decisions.
[00:00:36.280 --> 00:00:40.280]   In this case, the decision is segmenting a pixel in or out
[00:00:40.280 --> 00:00:43.320]   foreground or background.
[00:00:43.320 --> 00:00:48.760]   Typically, in most scenarios, we would want to operate
[00:00:48.760 --> 00:00:52.880]   in a situation where we label some images with ground truth.
[00:00:52.880 --> 00:00:56.160]   And so we have the answers for some data.
[00:00:56.160 --> 00:01:00.440]   And then we hope that by tuning parameters on that set of data,
[00:01:00.440 --> 00:01:04.760]   we will get good results on other incoming data,
[00:01:04.760 --> 00:01:07.040]   on new images.
[00:01:07.040 --> 00:01:10.280]   But hopefully, that our kind of have the same properties
[00:01:10.280 --> 00:01:13.720]   as the ones where we go through the effort of actually
[00:01:13.720 --> 00:01:19.040]   generating ground truth segmentations, for example.
[00:01:19.040 --> 00:01:25.240]   So key thing is we have ground truth, so positives and negative.
[00:01:25.240 --> 00:01:29.720]   And then we have our labelings, positive or negative,
[00:01:29.720 --> 00:01:32.440]   and a combination of a positive that
[00:01:32.440 --> 00:01:33.680]   should actually have been positive.
[00:01:33.680 --> 00:01:35.440]   That's a true positive.
[00:01:35.440 --> 00:01:38.680]   A positive that actually gets labeled negative.
[00:01:38.680 --> 00:01:41.320]   That's a false negative.
[00:01:41.320 --> 00:01:48.440]   And then same thing for false positives and true negatives.
[00:01:48.440 --> 00:01:49.760]   If you looked at the histograms here,
[00:01:49.760 --> 00:01:53.440]   we looked at it if we have overlapping distributions
[00:01:53.440 --> 00:01:57.320]   in our single feature we use for segmentation,
[00:01:57.320 --> 00:02:01.520]   then we will not be able to have a perfect system.
[00:02:01.520 --> 00:02:03.520]   We'll have to take errors into account.
[00:02:03.520 --> 00:02:07.360]   Our goal is somehow to choose our parameter in a way
[00:02:07.360 --> 00:02:10.440]   each of those crosses is one setting of our parameters
[00:02:10.440 --> 00:02:14.120]   to choose it such that we have the best possible result.
[00:02:14.120 --> 00:02:16.360]   And this was essentially clearly--
[00:02:16.360 --> 00:02:19.720]   as long as we go straight up--
[00:02:19.720 --> 00:02:21.160]   there's my cursor here.
[00:02:22.160 --> 00:02:23.160]   OK.
[00:02:23.160 --> 00:02:26.080]   I can find-- there it is.
[00:02:26.080 --> 00:02:28.240]   As long as we go straight up, of course, it's pure wind,
[00:02:28.240 --> 00:02:29.480]   so we do better.
[00:02:29.480 --> 00:02:32.200]   But at some point, we start making a trade-off here.
[00:02:32.200 --> 00:02:36.560]   And there it depends on the value of decisions on both sides,
[00:02:36.560 --> 00:02:38.560]   false positives and false negatives,
[00:02:38.560 --> 00:02:40.800]   the relative cost of those.
[00:02:40.800 --> 00:02:45.960]   Which operating points you would want to choose?
[00:02:45.960 --> 00:02:46.520]   OK.
[00:02:46.520 --> 00:02:51.400]   So now we'll start taking into account a little bit
[00:02:51.400 --> 00:02:52.680]   connectivity between pixels.
[00:02:52.680 --> 00:02:59.760]   So again, pixels are samples, they're not squares.
[00:02:59.760 --> 00:03:01.200]   So we often draw them as squares,
[00:03:01.200 --> 00:03:05.640]   but remember them as sampling points of this function.
[00:03:05.640 --> 00:03:10.600]   But essentially, we want to define what are neighbors--
[00:03:10.600 --> 00:03:13.680]   what are neighboring pixels--
[00:03:13.680 --> 00:03:15.680]   so that we can do neighboring operations
[00:03:15.680 --> 00:03:19.120]   decide, hey, this pixel should maybe look at its neighbors
[00:03:19.120 --> 00:03:19.920]   to make a decision.
[00:03:19.920 --> 00:03:24.520]   So we need to formally define what neighborhoods are.
[00:03:24.520 --> 00:03:27.800]   For example, one question would be,
[00:03:27.800 --> 00:03:33.240]   are dark pixels in this plot or in this picture here,
[00:03:33.240 --> 00:03:36.040]   are they connected or are they not connected?
[00:03:36.040 --> 00:03:39.560]   Clearly, the kind of complicated situation is this here.
[00:03:39.560 --> 00:03:41.960]   Do we consider this connected or not?
[00:03:41.960 --> 00:03:43.920]   So we want a formal definition.
[00:03:43.920 --> 00:03:47.600]   In particular, we can define four neighborhoods
[00:03:47.600 --> 00:03:48.520]   or eight neighborhoods.
[00:03:48.520 --> 00:03:50.600]   So we define which are the pixels that
[00:03:50.600 --> 00:03:54.040]   are neighbors of a particular pixel.
[00:03:54.040 --> 00:03:56.120]   And depending on the choice, it's a choice.
[00:03:56.120 --> 00:03:59.360]   Depending on the choice, the previous image here
[00:03:59.360 --> 00:04:01.920]   would be considered fully connected.
[00:04:01.920 --> 00:04:05.960]   So all the black pixels would be considered all connected,
[00:04:05.960 --> 00:04:10.080]   all forming one region, one connected region or not.
[00:04:11.080 --> 00:04:11.580]   OK?
[00:04:11.580 --> 00:04:18.360]   So we'll define also formally a pixel path.
[00:04:18.360 --> 00:04:21.760]   As a four connected path between pixels p1 and pn
[00:04:21.760 --> 00:04:25.200]   is a set of pixels p1, p2, and pn,
[00:04:25.200 --> 00:04:31.640]   such that pi is a four neighbor of pi plus 1.
[00:04:31.640 --> 00:04:32.400]   So that's a path.
[00:04:32.400 --> 00:04:34.280]   And then, of course, the four eight connected path
[00:04:34.280 --> 00:04:38.040]   is the same definition, but now with the eight neighborhood.
[00:04:38.040 --> 00:04:40.920]   And in that context, we can define connected regions
[00:04:40.920 --> 00:04:44.120]   as long as a region is four connected
[00:04:44.120 --> 00:04:47.840]   if it contains a connected path between any two pixels
[00:04:47.840 --> 00:04:48.880]   in the region.
[00:04:48.880 --> 00:04:55.240]   Then it's a connected region and the same four eight connected.
[00:04:55.240 --> 00:05:02.720]   So coming back to this, with the four neighborhood,
[00:05:02.720 --> 00:05:05.840]   this would be two regions.
[00:05:05.840 --> 00:05:07.440]   With the eight neighborhood, this
[00:05:07.440 --> 00:05:08.360]   would be one region.
[00:05:08.360 --> 00:05:14.760]   Maybe a question, what about the white pixels?
[00:05:14.760 --> 00:05:18.120]   How many regions do we have for white pixels?
[00:05:18.120 --> 00:05:20.320]   It's one region in both cases, right?
[00:05:20.320 --> 00:05:21.720]   Because we can go all around also.
[00:05:21.720 --> 00:05:33.920]   We can label each connected component of a binary image
[00:05:33.920 --> 00:05:36.080]   with a separate number.
[00:05:36.080 --> 00:05:38.880]   So for example, here, we have all the white pixels.
[00:05:38.880 --> 00:05:43.680]   So we label separately the white and the black pixels.
[00:05:43.680 --> 00:05:48.520]   And so essentially, if we label all the white pixels,
[00:05:48.520 --> 00:05:50.600]   we can go everywhere.
[00:05:50.600 --> 00:05:52.280]   We cannot reach these guys.
[00:05:52.280 --> 00:05:55.320]   This will have to be a separate region.
[00:05:55.320 --> 00:05:57.320]   But all the rest is labeled as one.
[00:05:57.320 --> 00:05:59.640]   The next region we encounter, if we just go through the image,
[00:05:59.640 --> 00:06:00.920]   will be-- now it's a black pixel,
[00:06:00.920 --> 00:06:05.000]   so different pixels that belongs to a different group.
[00:06:05.000 --> 00:06:06.040]   So we start from that one.
[00:06:06.040 --> 00:06:11.920]   So this one would be what we're doing the exercise with,
[00:06:11.920 --> 00:06:15.400]   what, four or eight connected, if you look at this.
[00:06:15.400 --> 00:06:20.440]   Four connected, right?
[00:06:20.440 --> 00:06:21.800]   Because we see that over there.
[00:06:21.800 --> 00:06:23.840]   If it was eight connected, region two and three
[00:06:23.840 --> 00:06:24.880]   would be one single region.
[00:06:24.880 --> 00:06:30.440]   And so we can see also here, this is here
[00:06:30.440 --> 00:06:32.640]   considered two regions.
[00:06:32.640 --> 00:06:34.600]   And then of course, here, we have this one
[00:06:34.600 --> 00:06:37.880]   is separate from the other white pixels.
[00:06:37.880 --> 00:06:38.480]   All make sense?
[00:06:38.480 --> 00:06:44.480]   If we just care about the foreground, for example,
[00:06:44.480 --> 00:06:47.720]   here, the white pixels, we'd only care about two regions.
[00:06:47.720 --> 00:06:50.480]   In this case, all the rest would be ignore set to zero.
[00:06:50.480 --> 00:06:57.160]   So now, if we have an image like this one here,
[00:06:57.160 --> 00:07:00.800]   we could essentially do a segmentation, something
[00:07:00.800 --> 00:07:02.960]   like this, would leave this.
[00:07:02.960 --> 00:07:06.360]   And then we could essentially look at connected regions
[00:07:06.360 --> 00:07:10.000]   and count the number of keys that are flying here
[00:07:10.000 --> 00:07:15.200]   or that are visible in the picture by counting regions.
[00:07:15.200 --> 00:07:19.960]   If we look a little bit more at these regions,
[00:07:19.960 --> 00:07:24.960]   they typically start from a seed region, point or region.
[00:07:24.960 --> 00:07:27.920]   And then you can actually--
[00:07:27.920 --> 00:07:30.000]   if we had a binary image, it was all easy.
[00:07:30.000 --> 00:07:33.360]   We could just then make a few basic decisions
[00:07:33.360 --> 00:07:35.120]   and then just count.
[00:07:35.120 --> 00:07:38.320]   And it would all be well posed.
[00:07:38.320 --> 00:07:40.560]   But if we start directly from an image,
[00:07:40.560 --> 00:07:42.480]   it might be a little bit more complicated.
[00:07:42.480 --> 00:07:46.520]   In particular, we could start from a certain point
[00:07:46.520 --> 00:07:50.960]   and then not just look if you're connected as we did before,
[00:07:50.960 --> 00:07:55.680]   but essentially decide to include neighboring pixels based
[00:07:55.680 --> 00:08:00.240]   on them satisfying a certain criteria that
[00:08:00.240 --> 00:08:02.560]   is defined for the region.
[00:08:02.560 --> 00:08:04.720]   This criteria can also be adaptive.
[00:08:04.720 --> 00:08:06.920]   It can be adjusted once you include more pixels.
[00:08:06.920 --> 00:08:09.240]   You can adjust your criteria and then potentially include
[00:08:09.240 --> 00:08:11.160]   even more pixels and things like this.
[00:08:11.160 --> 00:08:13.840]   So all of those are options.
[00:08:13.840 --> 00:08:15.880]   And so you would repeat this until you cannot include more
[00:08:15.880 --> 00:08:16.380]   pixels.
[00:08:16.380 --> 00:08:22.920]   So essentially, here's some code or some set of code.
[00:08:22.920 --> 00:08:25.360]   And so essentially, here's the decision point
[00:08:25.360 --> 00:08:30.080]   where if you can include another pixel next point given
[00:08:30.080 --> 00:08:35.800]   the seed, then you can do that.
[00:08:35.800 --> 00:08:40.200]   I leave that for you to look at by yourself.
[00:08:40.200 --> 00:08:44.720]   So let's say we start here.
[00:08:44.720 --> 00:08:47.040]   So let's try that on our duck example here.
[00:08:47.040 --> 00:08:52.600]   So how would we set this up here?
[00:08:52.600 --> 00:08:56.760]   Let's say the seed region could be a safe threshold.
[00:08:56.760 --> 00:08:58.960]   So one where you say, OK, we know that everything
[00:08:58.960 --> 00:09:01.240]   above this threshold is definitely part of the duck.
[00:09:01.240 --> 00:09:04.880]   So we'll start with this as a start region.
[00:09:04.880 --> 00:09:07.800]   T150, for example.
[00:09:07.800 --> 00:09:11.200]   So that would be the seed selection as an example,
[00:09:11.200 --> 00:09:12.800]   a very safe threshold.
[00:09:12.800 --> 00:09:14.640]   We've seen that if we take a safe threshold,
[00:09:14.640 --> 00:09:16.000]   then we're probably really good.
[00:09:16.000 --> 00:09:18.120]   It's just that once we try to go all the way with just
[00:09:18.120 --> 00:09:21.440]   a single threshold, then it becomes challenging.
[00:09:21.440 --> 00:09:23.760]   So here, instead of just doing a seed
[00:09:23.760 --> 00:09:25.760]   and taking one fixed threshold, we'll
[00:09:25.760 --> 00:09:30.040]   start there with a conservative estimate for threshold.
[00:09:30.040 --> 00:09:35.840]   And then we look at a more refined and based on connectivity
[00:09:35.840 --> 00:09:37.520]   to include more pixels.
[00:09:37.520 --> 00:09:42.080]   This can both happen at the level of the region.
[00:09:42.080 --> 00:09:46.800]   Sometimes we'll see you can also actually look at the boundary.
[00:09:46.800 --> 00:09:48.880]   Because sometimes you might say that, well,
[00:09:48.880 --> 00:09:52.400]   I'll decide to add a pixel or not based on my boundary
[00:09:52.400 --> 00:09:55.480]   following some being relatively smooth, for example,
[00:09:55.480 --> 00:09:58.760]   not making these kind of strange excursions
[00:09:58.760 --> 00:10:03.440]   along a single path and add a number of pixels that way.
[00:10:03.440 --> 00:10:06.520]   So for seed selection, you could do point and click.
[00:10:06.520 --> 00:10:07.600]   Just selecting a point.
[00:10:07.600 --> 00:10:11.360]   As we said, we can, for example, do it automatically
[00:10:11.360 --> 00:10:14.200]   based on a very conservative threshold.
[00:10:14.200 --> 00:10:17.880]   You could also indicate it by hand, multiple options there.
[00:10:17.880 --> 00:10:22.720]   You could also start from multiple seeds if you wanted to.
[00:10:22.720 --> 00:10:29.080]   OK, inclusion criteria, of course, simple gray level
[00:10:29.080 --> 00:10:32.040]   thresholding.
[00:10:32.040 --> 00:10:34.040]   You're going to say, well, we did thresholding before.
[00:10:34.040 --> 00:10:35.120]   What's different then?
[00:10:35.120 --> 00:10:38.360]   Here, we would only consider two pixels that are directly
[00:10:38.360 --> 00:10:40.600]   connected to previously included pixel.
[00:10:40.600 --> 00:10:42.560]   So this is actually a difference.
[00:10:42.560 --> 00:10:44.520]   You had another region, a small region
[00:10:44.520 --> 00:10:46.120]   somewhere else in the image.
[00:10:46.120 --> 00:10:49.240]   Remember, on the duck, all of these small regions all over,
[00:10:49.240 --> 00:10:51.080]   we would not include those this way.
[00:10:51.080 --> 00:10:52.800]   We would start from the big region,
[00:10:52.800 --> 00:10:55.800]   and then we would take maybe a weaker threshold,
[00:10:55.800 --> 00:10:58.160]   but only at pixels that are directly connected
[00:10:58.160 --> 00:10:59.800]   to the main duck region, for example.
[00:10:59.800 --> 00:11:02.720]   So this is not the same as just taking a weaker threshold all
[00:11:02.720 --> 00:11:03.560]   up for the whole image.
[00:11:03.560 --> 00:11:12.440]   And then as you see here, sometimes, beyond thresholding,
[00:11:12.440 --> 00:11:16.360]   you could also look at a color or grayscale or color
[00:11:16.360 --> 00:11:22.520]   distribution of the region, and then gradually adjust that.
[00:11:22.520 --> 00:11:24.680]   You have the option to update this.
[00:11:24.680 --> 00:11:26.760]   You add pixels, and then you say, OK, let
[00:11:26.760 --> 00:11:31.240]   me re-estimate my variance, my distribution of what
[00:11:31.240 --> 00:11:37.400]   I expect to see in the region, and then I can iterate on this.
[00:11:37.400 --> 00:11:40.720]   And so beyond gray level, of course, you can do color.
[00:11:40.720 --> 00:11:42.680]   You can also do texture.
[00:11:42.680 --> 00:11:45.640]   Now, we haven't seen yet how to characterize texture,
[00:11:45.640 --> 00:11:49.000]   how to choose that, and so on.
[00:11:49.000 --> 00:11:52.920]   In the coming weeks, we learn how you can also not only
[00:11:52.920 --> 00:11:56.000]   characterize a fixed color, but also variations, essentially.
[00:11:56.000 --> 00:11:58.480]   This will be when we'll start talking or looking
[00:11:58.480 --> 00:12:01.400]   at the Fourier transformation, which
[00:12:01.400 --> 00:12:04.160]   is essentially expressing instead of expressing things
[00:12:04.160 --> 00:12:08.160]   in individual pixels, expressing them in patterns.
[00:12:08.160 --> 00:12:12.080]   And those patterns are the basis of describing textures.
[00:12:12.080 --> 00:12:18.880]   OK, so here's an example.
[00:12:18.880 --> 00:12:21.960]   So let's say we have an image like this here.
[00:12:21.960 --> 00:12:25.720]   How could we do an inclusion criteria?
[00:12:25.720 --> 00:12:29.080]   Well, you could start from--
[00:12:29.080 --> 00:12:31.840]   let's say you started from somewhere in the image here,
[00:12:31.840 --> 00:12:34.000]   very--
[00:12:34.000 --> 00:12:37.000]   for example, a safe threshold here.
[00:12:37.000 --> 00:12:39.640]   Although there's-- you see actually a little bit here
[00:12:39.640 --> 00:12:42.840]   also included, but let's say you have something like this.
[00:12:42.840 --> 00:12:46.320]   So essentially, thresholds won't work very well here.
[00:12:46.320 --> 00:12:50.480]   In general, there's no threshold that actually works
[00:12:50.480 --> 00:12:52.120]   if you just do thresholds.
[00:12:52.120 --> 00:12:56.520]   However, if you somehow start from the middle of the region
[00:12:56.520 --> 00:12:59.040]   and over some set of neighboring pixels,
[00:12:59.040 --> 00:13:05.520]   you would fit a model that's not only looking
[00:13:05.520 --> 00:13:11.000]   at the grayscale value, but looks at the combination here
[00:13:11.000 --> 00:13:15.680]   of the grayscale value that actually expresses
[00:13:15.680 --> 00:13:18.880]   the grayscale value not purely as a constant,
[00:13:18.880 --> 00:13:21.440]   but actually as something that depends on the x and y
[00:13:21.440 --> 00:13:23.120]   coordinates.
[00:13:23.120 --> 00:13:27.160]   So this is something here that depends on the x and y
[00:13:27.160 --> 00:13:28.240]   coordinate also.
[00:13:28.240 --> 00:13:30.400]   So you have a model that combines intensity and x
[00:13:30.400 --> 00:13:31.800]   and y coordinates.
[00:13:31.800 --> 00:13:33.760]   So you can see this as--
[00:13:33.760 --> 00:13:36.680]   you can solve this for the intensity.
[00:13:36.680 --> 00:13:39.720]   And then you have this expression divided by a
[00:13:39.720 --> 00:13:41.240]   is equal to the intensity.
[00:13:41.240 --> 00:13:44.000]   So there's a linear relationship between intensity, x,
[00:13:44.000 --> 00:13:45.320]   and y coordinates.
[00:13:45.320 --> 00:13:47.160]   There's a constant here.
[00:13:47.160 --> 00:13:49.040]   Does that make sense?
[00:13:49.040 --> 00:13:50.560]   So we have now expressed--
[00:13:50.560 --> 00:13:52.280]   in some sense, you can look at this model
[00:13:52.280 --> 00:13:55.920]   as expressing the intensity as a linear combination
[00:13:55.920 --> 00:13:58.360]   of x and y coordinates.
[00:13:58.360 --> 00:14:02.960]   We're saying that essentially intensity and x and y
[00:14:02.960 --> 00:14:07.680]   coordinates all are related through a linear equation.
[00:14:07.680 --> 00:14:10.200]   And so this is this linear equation.
[00:14:10.200 --> 00:14:11.760]   We squared that.
[00:14:11.760 --> 00:14:13.720]   So we're saying the absolute value, in a sense,
[00:14:13.720 --> 00:14:16.160]   of what comes out of that equation.
[00:14:16.160 --> 00:14:18.120]   If I exactly follow this linear equation,
[00:14:18.120 --> 00:14:21.040]   I have a 0 here.
[00:14:21.040 --> 00:14:23.680]   If it's different from 0, here I square it.
[00:14:23.680 --> 00:14:25.960]   So if it's different from 0, both positive or negative.
[00:14:25.960 --> 00:14:29.120]   If I'm not on that linear constraint,
[00:14:29.120 --> 00:14:34.200]   that tells me how much I deviate from this linear model,
[00:14:34.200 --> 00:14:38.400]   I will essentially say, OK, I will threshold how close
[00:14:38.400 --> 00:14:43.120]   or not close I am to that linear model.
[00:14:43.120 --> 00:14:50.480]   The simple model was just without x, y dependency.
[00:14:50.480 --> 00:14:53.560]   We just have the intensity with--
[00:14:53.560 --> 00:14:56.040]   this expression would be 0.
[00:14:56.040 --> 00:14:59.080]   If we take those two terms away here, the x and y term,
[00:14:59.080 --> 00:15:01.280]   then we have the intensity would be--
[00:15:01.280 --> 00:15:05.400]   when the intensity is equal to d divided by a,
[00:15:05.400 --> 00:15:06.360]   this would be satisfied.
[00:15:06.360 --> 00:15:07.600]   This would be 0.
[00:15:07.600 --> 00:15:10.840]   So that's essentially just a constant.
[00:15:10.840 --> 00:15:14.320]   In this case, we add this dependency on x and y.
[00:15:14.320 --> 00:15:16.280]   If we do that, you can kind of see
[00:15:16.280 --> 00:15:19.280]   that there seems to be a linear gradient here.
[00:15:19.280 --> 00:15:20.400]   So this is brighter.
[00:15:20.400 --> 00:15:21.680]   This is darker.
[00:15:21.680 --> 00:15:26.880]   And along the way, it seems to vary kind of linearly.
[00:15:26.880 --> 00:15:30.960]   So as you move, every time you move a little bit to the left,
[00:15:30.960 --> 00:15:32.160]   it gets a little bit brighter.
[00:15:32.160 --> 00:15:34.760]   And it seems to behave kind of linear.
[00:15:34.760 --> 00:15:36.440]   So we're going to try that model.
[00:15:36.440 --> 00:15:38.760]   In a sense, we're kind of seeing,
[00:15:38.760 --> 00:15:43.840]   if you look at it at that image as a height map,
[00:15:43.840 --> 00:15:44.960]   it looks like this.
[00:15:44.960 --> 00:15:47.280]   And you kind of see that in 3D here,
[00:15:47.280 --> 00:15:50.280]   you can kind of hit a plane.
[00:15:50.280 --> 00:15:52.440]   There's some noise, but it's kind of a plane.
[00:15:52.440 --> 00:15:55.440]   The general behavior is a planar behavior.
[00:15:55.440 --> 00:16:00.360]   A planar behavior, a plane is a linear equation in 3D.
[00:16:00.360 --> 00:16:05.160]   This is a three-dimensional I, x, y, a three-dimensional equation.
[00:16:05.160 --> 00:16:07.880]   It's a linear equation in a three-dimensional space,
[00:16:07.880 --> 00:16:10.960]   the space being I, x, and y.
[00:16:10.960 --> 00:16:16.400]   This is x, y, and the vertical is I.
[00:16:16.400 --> 00:16:18.960]   Does that all make sense to everyone?
[00:16:18.960 --> 00:16:19.460]   OK.
[00:16:22.600 --> 00:16:23.100]   OK.
[00:16:23.100 --> 00:16:27.720]   So essentially, we decided to use a little bit more complicated
[00:16:27.720 --> 00:16:31.800]   inclusion criterion than just taking a threshold and saying,
[00:16:31.800 --> 00:16:34.480]   above it's in and below it's out.
[00:16:34.480 --> 00:16:37.520]   Here we say we want to be close to that relationship.
[00:16:37.520 --> 00:16:39.560]   And if it's close, it's in.
[00:16:39.560 --> 00:16:41.840]   If it's far, it's out.
[00:16:41.840 --> 00:16:43.200]   And now if we have a seed--
[00:16:43.200 --> 00:16:45.800]   let's say we have a seed over here somewhere--
[00:16:45.800 --> 00:16:49.240]   and we say, OK, we'll take a bunch of neighbors here.
[00:16:49.240 --> 00:16:51.840]   We'll kind of do an approximation.
[00:16:51.840 --> 00:16:56.160]   So we'll fit to a few points around here.
[00:16:56.160 --> 00:16:59.600]   We'll fit a linear plane here.
[00:16:59.600 --> 00:17:03.720]   We'll solve the linear equation for all of those points.
[00:17:03.720 --> 00:17:06.040]   We'll approximately solve it because they will not
[00:17:06.040 --> 00:17:07.640]   be an exact solution.
[00:17:07.640 --> 00:17:08.920]   It's not exactly a plane.
[00:17:08.920 --> 00:17:10.600]   It's approximately a plane.
[00:17:10.600 --> 00:17:13.680]   So we'll solve this in a least square sense.
[00:17:13.680 --> 00:17:15.880]   Best solution in least squares.
[00:17:15.880 --> 00:17:18.720]   You've all seen that in the algebra normally.
[00:17:18.720 --> 00:17:22.200]   So we'll solve this for some pixels.
[00:17:22.200 --> 00:17:24.600]   We'll get a model.
[00:17:24.600 --> 00:17:29.360]   And then what we do is we now use essentially that model.
[00:17:29.360 --> 00:17:32.640]   That will be our inclusion model.
[00:17:32.640 --> 00:17:33.920]   This guy.
[00:17:33.920 --> 00:17:37.000]   We essentially-- what we do is we do the difference between this
[00:17:37.000 --> 00:17:38.800]   and this.
[00:17:38.800 --> 00:17:44.240]   And where we close, it's in, where we far it's out.
[00:17:44.240 --> 00:17:46.880]   And so in this case, we will kind of in one go
[00:17:46.880 --> 00:17:48.520]   have the full segmentation.
[00:17:48.520 --> 00:17:50.560]   I mean, in one go, iteratively.
[00:17:50.560 --> 00:17:53.480]   So we take a few pixels, fit the plane,
[00:17:53.480 --> 00:17:56.040]   and then say everything that agrees with this, we take in.
[00:17:56.040 --> 00:17:58.120]   Everything that disagrees is out.
[00:17:58.120 --> 00:18:01.200]   Potentially, you might have to run this a few times.
[00:18:01.200 --> 00:18:03.560]   If, let's say, the first time around, you almost had the plane,
[00:18:03.560 --> 00:18:06.520]   but it was still a little bit tilted the wrong way,
[00:18:06.520 --> 00:18:08.080]   in the middle, it will be good enough.
[00:18:08.080 --> 00:18:11.880]   You will add a bunch of pixels, grow the region.
[00:18:11.880 --> 00:18:14.080]   But it might be that the edges, you were still
[00:18:14.080 --> 00:18:15.840]   a little bit too far off.
[00:18:15.840 --> 00:18:17.400]   Because we have a threshold here,
[00:18:17.400 --> 00:18:21.320]   it might be that the model is not great yet
[00:18:21.320 --> 00:18:24.000]   at fitting the corners further away,
[00:18:24.000 --> 00:18:25.640]   because the plane is a little bit tilted.
[00:18:25.640 --> 00:18:28.920]   So the absolute distance is larger, further away
[00:18:28.920 --> 00:18:31.200]   from the middle where you fitted it.
[00:18:31.200 --> 00:18:33.120]   And so maybe you do an iteration.
[00:18:33.120 --> 00:18:34.360]   You rerun it.
[00:18:34.360 --> 00:18:35.400]   You include more pixels.
[00:18:35.400 --> 00:18:36.280]   You rerun it.
[00:18:36.280 --> 00:18:39.160]   You fit the plane better, because now you have more pixels included.
[00:18:39.160 --> 00:18:41.280]   And then after a few iterations, you
[00:18:41.280 --> 00:18:43.120]   have the whole plane, essentially.
[00:18:43.120 --> 00:18:46.280]   That's how it would work.
[00:18:46.280 --> 00:18:55.560]   And I think this is after--
[00:18:55.560 --> 00:18:56.280]   I'm not really sure.
[00:18:56.280 --> 00:18:58.120]   Anyways, it looks already quite separated.
[00:18:58.120 --> 00:18:59.520]   So I think it's after.
[00:18:59.520 --> 00:19:01.760]   But I'm not sure if it's the histogram before after.
[00:19:01.760 --> 00:19:04.160]   Anyways, once you've done this, you can actually properly
[00:19:04.160 --> 00:19:06.080]   separate.
[00:19:06.080 --> 00:19:08.920]   You see also that there might be a few pixels here
[00:19:08.920 --> 00:19:12.280]   that get close to inclusion.
[00:19:12.280 --> 00:19:15.600]   So that's kind of what you see here.
[00:19:15.600 --> 00:19:18.120]   So you see if you fit the plane here,
[00:19:18.120 --> 00:19:22.000]   it's probably going to be not too far from those edge points.
[00:19:22.000 --> 00:19:22.800]   The edge points are here.
[00:19:22.800 --> 00:19:23.920]   The plane is going like this.
[00:19:23.920 --> 00:19:33.680]   Now we look a little bit at the boundary.
[00:19:33.680 --> 00:19:39.800]   Are there things that one could do there?
[00:19:39.800 --> 00:19:42.680]   In particular, one example is snakes.
[00:19:42.680 --> 00:19:45.560]   This is a type of active contour.
[00:19:45.560 --> 00:19:49.520]   It's essentially a polygon, which is an ordered set of points
[00:19:49.520 --> 00:19:51.720]   joined by lines.
[00:19:51.720 --> 00:19:53.120]   Each of those points on the contour
[00:19:53.120 --> 00:19:57.160]   moves away from the seed while its image neighborhood
[00:19:57.160 --> 00:20:00.840]   satisfies an inclusion criterion.
[00:20:00.840 --> 00:20:04.600]   So here instead of growing pixel by pixel arbitrarily,
[00:20:04.600 --> 00:20:07.440]   as long as it's satisfied, we keep adding pixels.
[00:20:07.440 --> 00:20:08.400]   So we add pixels.
[00:20:08.400 --> 00:20:08.720]   We look.
[00:20:08.720 --> 00:20:11.400]   Is there another-- all of my neighboring pixels.
[00:20:11.400 --> 00:20:13.720]   Does any of them satisfy the criterion?
[00:20:13.720 --> 00:20:15.160]   We keep adding them.
[00:20:15.160 --> 00:20:16.640]   And as soon as we add a pixel, that
[00:20:16.640 --> 00:20:18.360]   means there's new neighboring pixels.
[00:20:18.360 --> 00:20:20.440]   So we keep going at it.
[00:20:20.440 --> 00:20:23.360]   Here we do that in a slightly more controlled way.
[00:20:23.360 --> 00:20:25.160]   We actually move a neighborhood at a time.
[00:20:25.160 --> 00:20:26.760]   So we cannot just include one pixel.
[00:20:26.760 --> 00:20:28.760]   If we move the boundary, we include a whole bunch
[00:20:28.760 --> 00:20:30.480]   of pixels at the same time.
[00:20:30.480 --> 00:20:32.400]   So we do it in a more structured way.
[00:20:32.400 --> 00:20:35.360]   And we want to keep control of the shape of this boundary.
[00:20:35.360 --> 00:20:42.320]   And often the contour also has to satisfy a smoothness
[00:20:42.320 --> 00:20:43.560]   constraint.
[00:20:43.560 --> 00:20:46.720]   So we're not going to allow it to somehow make a really long
[00:20:46.720 --> 00:20:49.200]   extension out, but we'll want to keep
[00:20:49.200 --> 00:20:55.520]   the bending of this contour to also satisfy some constraints.
[00:20:55.520 --> 00:21:01.640]   For example, this paper here was a seminal paper in that space.
[00:21:01.640 --> 00:21:04.440]   Like Casvid, Kylian, Tezopoulos, it combined.
[00:21:04.440 --> 00:21:10.240]   It essentially expressed that shape,
[00:21:10.240 --> 00:21:14.080]   or it expressed that fit of that boundary
[00:21:14.080 --> 00:21:17.320]   as a combination of three terms.
[00:21:17.320 --> 00:21:22.280]   We'll actually, in image processing computer vision,
[00:21:22.280 --> 00:21:27.160]   often express regularization problems
[00:21:27.160 --> 00:21:31.240]   or optimization problems as an energy minimization problem.
[00:21:31.240 --> 00:21:32.960]   We'll try to optimize the problem.
[00:21:32.960 --> 00:21:35.160]   We'll formulate the problem as one that
[00:21:35.160 --> 00:21:37.640]   combines different energy terms.
[00:21:37.640 --> 00:21:41.760]   For example, one typically will have at least one
[00:21:41.760 --> 00:21:44.560]   that expresses the relation to the data.
[00:21:44.560 --> 00:21:47.600]   How well does our model fit the data?
[00:21:47.600 --> 00:21:50.360]   On the one hand, how close are we to explain the data
[00:21:50.360 --> 00:21:51.200]   that we observe?
[00:21:51.200 --> 00:21:53.840]   On the one hand, so a data term.
[00:21:53.840 --> 00:21:58.400]   And then another term is actually one or multiple terms
[00:21:58.400 --> 00:22:04.160]   are expressing how close our solution satisfies
[00:22:04.160 --> 00:22:06.040]   or prior assumptions.
[00:22:06.040 --> 00:22:10.840]   Prior assumptions might be we want a smooth boundary.
[00:22:10.840 --> 00:22:13.640]   We don't want too large of a boundary and so on.
[00:22:13.640 --> 00:22:16.160]   So in this case, you have one energy term
[00:22:16.160 --> 00:22:20.920]   that expresses the tension and one the stiffness.
[00:22:20.920 --> 00:22:23.960]   And so it will evolve the boundary only in a way
[00:22:23.960 --> 00:22:26.760]   that optimizes those terms of what
[00:22:26.760 --> 00:22:29.640]   you expect of how the boundary should behave
[00:22:29.640 --> 00:22:32.720]   and tries to, at the same time, look at the image
[00:22:32.720 --> 00:22:37.360]   and choose a boundary where the inside satisfies
[00:22:37.360 --> 00:22:40.400]   the criterion as much as-- but all of the pixels you know
[00:22:40.400 --> 00:22:44.040]   as you move this boundary that you label inside actually
[00:22:44.040 --> 00:22:45.400]   do look like inside pixels.
[00:22:45.400 --> 00:22:51.360]   So for example, in this example here,
[00:22:51.360 --> 00:22:56.040]   you minimize this would be the energy then.
[00:22:56.040 --> 00:23:00.440]   For all the pixels inside, you want this to be small.
[00:23:00.440 --> 00:23:05.040]   So this quadratic term here would, for example,
[00:23:05.040 --> 00:23:07.560]   could be that E image here.
[00:23:07.560 --> 00:23:10.680]   So for every pixel that you include,
[00:23:10.680 --> 00:23:16.600]   you could essentially do the quadratic function of the inclusion.
[00:23:16.600 --> 00:23:18.680]   So now instead of strictly thresholding,
[00:23:18.680 --> 00:23:20.840]   you might include a few pixels that don't look
[00:23:20.840 --> 00:23:22.360]   like they would be inside.
[00:23:22.360 --> 00:23:24.280]   But if it helps having a nice boundary,
[00:23:24.280 --> 00:23:25.760]   you might still include them.
[00:23:25.760 --> 00:23:28.800]   So now you trade off having a nice boundary,
[00:23:28.800 --> 00:23:31.160]   having your solution satisfy your prior assumptions
[00:23:31.160 --> 00:23:33.400]   of how the solution should look like,
[00:23:33.400 --> 00:23:35.520]   like being smooth and things like this,
[00:23:35.520 --> 00:23:40.040]   versus the strict things that come from the data.
[00:23:40.040 --> 00:23:41.640]   That's what you get here.
[00:23:41.640 --> 00:23:45.360]   So here's an example of this.
[00:23:45.360 --> 00:23:47.320]   So this is the start.
[00:23:47.320 --> 00:23:51.160]   So you have here this polygon with-- what is it here?
[00:23:51.160 --> 00:23:53.440]   Five points.
[00:23:53.440 --> 00:23:56.000]   And so you say, OK, this is inside.
[00:23:56.000 --> 00:23:59.560]   And so what you would actually do here, in a case like this,
[00:23:59.560 --> 00:24:02.760]   is you would say, I will somehow try
[00:24:02.760 --> 00:24:07.320]   to estimate a model for how these pixels look like.
[00:24:07.320 --> 00:24:09.240]   So first thing is you can look at this and say, OK,
[00:24:09.240 --> 00:24:12.760]   what's the average color here?
[00:24:12.760 --> 00:24:14.920]   That's the simplest model.
[00:24:14.920 --> 00:24:16.040]   And if you're closer to that color,
[00:24:16.040 --> 00:24:16.400]   it's in.
[00:24:16.400 --> 00:24:18.960]   If it's far from that color, it's out, for example.
[00:24:18.960 --> 00:24:21.160]   But you could also say, well, this is clearly not
[00:24:21.160 --> 00:24:22.760]   just a single color.
[00:24:22.760 --> 00:24:26.280]   So maybe I'll fit a distribution to all of these colors.
[00:24:26.280 --> 00:24:29.720]   So in that case, instead of just a point with a sphere around it,
[00:24:29.720 --> 00:24:32.280]   a distance criterion in the color space,
[00:24:32.280 --> 00:24:34.840]   you could actually say, let me actually look at all those points.
[00:24:34.840 --> 00:24:37.640]   Maybe they're like they form a distribution.
[00:24:37.640 --> 00:24:39.120]   So you fit a distribution to that.
[00:24:39.120 --> 00:24:43.240]   And you say, now, if I'm inside this ellipsoid,
[00:24:43.240 --> 00:24:43.760]   it's in.
[00:24:43.760 --> 00:24:47.200]   And if it's outside, it's out, stuff like that.
[00:24:47.200 --> 00:24:50.120]   You could also say, well, just a color
[00:24:50.120 --> 00:24:53.760]   is not really a great description of this.
[00:24:53.760 --> 00:24:55.560]   What I really want is a kind of--
[00:24:55.560 --> 00:24:58.600]   I want these kind of patterns here, these type of variations.
[00:24:58.600 --> 00:25:01.960]   So you could kind of look at, OK, what type of variations?
[00:25:01.960 --> 00:25:03.720]   For one pixel versus another pixel,
[00:25:03.720 --> 00:25:07.080]   how much do they differ for a certain distance between them?
[00:25:07.080 --> 00:25:08.840]   Like you could start, and again, we'll
[00:25:08.840 --> 00:25:10.520]   look at that in the coming weeks.
[00:25:10.520 --> 00:25:12.200]   You could also do more advanced way
[00:25:12.200 --> 00:25:16.080]   to describe what's going on in this part of the image.
[00:25:16.080 --> 00:25:20.440]   Eventually, you have a model that allows you to say,
[00:25:20.440 --> 00:25:25.560]   a pixel here looks a lot like these pixels or doesn't.
[00:25:25.560 --> 00:25:27.000]   So we'll have a model.
[00:25:27.000 --> 00:25:32.720]   So we apply that model on a per pixel basis, and we get this.
[00:25:32.720 --> 00:25:35.440]   So you see that actually even some of the pixels inside here
[00:25:35.440 --> 00:25:37.640]   are actually not labeled as being--
[00:25:37.640 --> 00:25:40.320]   like by themselves, they're not actually
[00:25:40.320 --> 00:25:43.920]   being labeled as looking a lot like the pixels in there.
[00:25:43.920 --> 00:25:44.720]   And that's normal.
[00:25:44.720 --> 00:25:46.520]   And of course, you see a lot of pixels outside,
[00:25:46.520 --> 00:25:49.360]   but you see also that not all of the pixels are--
[00:25:49.360 --> 00:25:53.080]   it's not a uniform continuous region.
[00:25:53.080 --> 00:25:57.720]   On a per pixel basis, you might have quite some random choices.
[00:25:57.720 --> 00:26:00.160]   And you see, of course, that there's a bunch of things here
[00:26:00.160 --> 00:26:02.080]   a bit all over the place that kind of randomly
[00:26:02.080 --> 00:26:06.120]   happen to satisfy, to look a lot like the pixels in the middle.
[00:26:06.120 --> 00:26:08.000]   They're at least based on the few features
[00:26:08.000 --> 00:26:09.560]   that we would have computed and fitted.
[00:26:09.560 --> 00:26:10.060]   OK.
[00:26:10.060 --> 00:26:21.480]   This is actually with some very simple morphologic operations,
[00:26:21.480 --> 00:26:23.480]   kind of starting growing the region from here
[00:26:23.480 --> 00:26:25.400]   and looking at connected pixels.
[00:26:25.400 --> 00:26:27.560]   And maybe-- and we'll talk a little bit more
[00:26:27.560 --> 00:26:29.640]   about that towards the end of the lecture--
[00:26:29.640 --> 00:26:33.160]   maybe also doing simple operations where from here,
[00:26:33.160 --> 00:26:35.280]   if there's a single pixel, we just say, OK,
[00:26:35.280 --> 00:26:37.040]   this single pixel is clearly--
[00:26:37.040 --> 00:26:39.680]   if all of my neighbors say they're inside,
[00:26:39.680 --> 00:26:40.680]   I will just join them.
[00:26:40.680 --> 00:26:42.600]   And then you flip the color.
[00:26:42.600 --> 00:26:46.080]   So it's a few operations like that, purely on a local level,
[00:26:46.080 --> 00:26:48.320]   purely based on connectivity, forgetting
[00:26:48.320 --> 00:26:50.200]   what the data actually says at this point
[00:26:50.200 --> 00:26:54.000]   and just kind of overrule based on those things.
[00:26:54.000 --> 00:26:58.560]   You can get something like this here, which is interesting,
[00:26:58.560 --> 00:27:01.400]   which is a good thing you could do.
[00:27:01.400 --> 00:27:05.240]   This is what comes out of the--
[00:27:05.240 --> 00:27:08.000]   by evolving doing these snakes.
[00:27:08.000 --> 00:27:09.880]   So the thing that we were talking about here,
[00:27:09.880 --> 00:27:11.200]   we start from here.
[00:27:11.200 --> 00:27:14.440]   And if we evolve this, and then if these points get too far
[00:27:14.440 --> 00:27:17.000]   apart, you can insert another point, for example.
[00:27:17.000 --> 00:27:19.520]   So you can evolve the boundary.
[00:27:19.520 --> 00:27:23.400]   Then this is the type of thing that comes out of this,
[00:27:23.400 --> 00:27:26.560]   out of the snakes.
[00:27:26.560 --> 00:27:30.960]   Again, this is applying it back to the image.
[00:27:30.960 --> 00:27:32.760]   So notice here, we have one nice--
[00:27:32.760 --> 00:27:34.440]   all of the points inside the boundaries
[00:27:34.440 --> 00:27:35.720]   are labeled inside.
[00:27:35.720 --> 00:27:39.560]   All of the points outside are labeled background.
[00:27:39.560 --> 00:27:42.640]   So inside, foreground, outside, background,
[00:27:42.640 --> 00:27:45.080]   which we didn't fully achieve with these simple morphological
[00:27:45.080 --> 00:27:48.680]   operations here, for example.
[00:27:48.680 --> 00:27:50.040]   But also, what else do you see?
[00:27:50.040 --> 00:27:51.840]   So do you see some things that are actually
[00:27:51.840 --> 00:27:52.680]   not very satisfying here?
[00:27:52.680 --> 00:27:59.640]   OK, indeed.
[00:27:59.640 --> 00:28:01.360]   Bottom right corner here.
[00:28:01.360 --> 00:28:02.120]   So what's the issue?
[00:28:02.120 --> 00:28:04.440]   [INAUDIBLE]
[00:28:04.440 --> 00:28:06.720]   Like-- OK, so this region should probably
[00:28:06.720 --> 00:28:07.880]   have been labeled inside.
[00:28:07.880 --> 00:28:10.560]   And a little bit-- not so much, a little bit here,
[00:28:10.560 --> 00:28:15.880]   but it's obvious there's a few things here.
[00:28:15.880 --> 00:28:18.560]   So anybody has an idea what the problem is here?
[00:28:18.560 --> 00:28:22.680]   Why this happens?
[00:28:22.680 --> 00:28:24.680]   [INAUDIBLE]
[00:28:24.680 --> 00:28:26.440]   Sorry?
[00:28:26.440 --> 00:28:28.840]   If you just pick up a bit, I just couldn't hear it.
[00:28:28.840 --> 00:28:36.640]   [INAUDIBLE]
[00:28:36.640 --> 00:28:39.120]   Actually, let me--
[00:28:39.120 --> 00:28:40.480]   if you look at this, so you're right,
[00:28:40.480 --> 00:28:42.720]   it's a little bit less obvious.
[00:28:42.720 --> 00:28:45.680]   Clearly, just the data driven--
[00:28:45.680 --> 00:28:48.840]   oh, actually, let me go even one further back.
[00:28:48.840 --> 00:28:50.200]   If we just look at the data, it's
[00:28:50.200 --> 00:28:52.760]   clear that this is more white on average than here.
[00:28:52.760 --> 00:28:54.440]   So there's less peaks.
[00:28:54.440 --> 00:28:56.680]   The motor is a bit hesitating.
[00:28:56.680 --> 00:29:03.000]   But still, like we're clearly cutting a lot away here.
[00:29:03.000 --> 00:29:05.520]   The reason is that our model is just saying in general--
[00:29:05.520 --> 00:29:07.680]   oh, yes, go ahead.
[00:29:07.680 --> 00:29:15.680]   [INAUDIBLE]
[00:29:15.680 --> 00:29:17.040]   Exactly.
[00:29:17.040 --> 00:29:25.040]   [INAUDIBLE]
[00:29:25.040 --> 00:29:26.400]   Exactly.
[00:29:26.400 --> 00:29:28.760]   So what is happening here is essentially
[00:29:28.760 --> 00:29:31.440]   that we have this very simple geometric model that
[00:29:31.440 --> 00:29:33.040]   treats the whole image as kind of--
[00:29:33.040 --> 00:29:34.320]   we just want one region.
[00:29:34.320 --> 00:29:37.000]   It doesn't do anything special at the edge, for example, here.
[00:29:37.000 --> 00:29:42.480]   It doesn't interpret this as a three dimensional representation.
[00:29:42.480 --> 00:29:46.080]   So this here, for example, we could probably--
[00:29:46.080 --> 00:29:49.000]   both this and this here--
[00:29:49.000 --> 00:29:53.920]   we could probably solve by doing something different
[00:29:53.920 --> 00:29:57.160]   at the boundary and saying, OK, if I connect straight
[00:29:57.160 --> 00:30:01.000]   to the boundary at whatever angle,
[00:30:01.000 --> 00:30:02.440]   there's no cost to that.
[00:30:02.440 --> 00:30:05.520]   Here, there's actually cost to go here and then go back,
[00:30:05.520 --> 00:30:07.400]   have the boundary, go all the way back.
[00:30:07.400 --> 00:30:13.840]   And so if we actually put zero cost to reach the boundary here,
[00:30:13.840 --> 00:30:16.040]   then it is likely to go further.
[00:30:16.040 --> 00:30:18.640]   Although it's still going to prefer going straight
[00:30:18.640 --> 00:30:20.480]   to the boundary.
[00:30:20.480 --> 00:30:23.480]   But essentially, we could try to normalize it and address that.
[00:30:23.480 --> 00:30:24.520]   Here we have a simple model.
[00:30:24.520 --> 00:30:25.280]   It's not addressed.
[00:30:25.280 --> 00:30:27.080]   It does what we ask it.
[00:30:27.080 --> 00:30:28.440]   There's actually something in general
[00:30:28.440 --> 00:30:30.640]   when you do those regularizations.
[00:30:30.640 --> 00:30:33.560]   It will just literally minimize what you ask it
[00:30:33.560 --> 00:30:36.040]   and quite literally.
[00:30:36.040 --> 00:30:38.240]   Everything with computers, you ask it something it will literally
[00:30:38.240 --> 00:30:38.740]   do.
[00:30:38.740 --> 00:30:41.200]   It will not use good judgment to somehow interpret
[00:30:41.200 --> 00:30:44.120]   or this or that.
[00:30:44.120 --> 00:30:47.760]   Also towards the top, indeed, you see data actually
[00:30:47.760 --> 00:30:49.440]   sees the road further.
[00:30:49.440 --> 00:30:52.680]   But here we cut it off.
[00:30:52.680 --> 00:30:55.440]   Although it's actually maybe not that bad actually here.
[00:30:55.440 --> 00:30:58.240]   It's a bit unclear what's happening there.
[00:30:58.240 --> 00:31:00.640]   But it's right that essentially the 3D nature
[00:31:00.640 --> 00:31:03.240]   could allow us to do things slightly differently that
[00:31:03.240 --> 00:31:05.480]   are far away because of perspective
[00:31:05.480 --> 00:31:07.880]   or assumptions of smoothness could actually
[00:31:07.880 --> 00:31:11.600]   be different close or far.
[00:31:11.600 --> 00:31:16.280]   But this is a very simple algorithm.
[00:31:16.280 --> 00:31:18.960]   OK, so inter-insummary segmentation is hard.
[00:31:18.960 --> 00:31:22.480]   It's easier if you define the task carefully.
[00:31:22.480 --> 00:31:25.480]   Is the segmentation task binary or continuous?
[00:31:25.480 --> 00:31:28.080]   This was this mixed pixels and blurred boundaries
[00:31:28.080 --> 00:31:29.600]   and things like this.
[00:31:29.600 --> 00:31:30.960]   What are the regions of interest?
[00:31:30.960 --> 00:31:33.320]   How accurate are the algorithms?
[00:31:33.320 --> 00:31:35.960]   Locate the region boundaries?
[00:31:35.960 --> 00:31:38.280]   Actually still lots of--
[00:31:38.280 --> 00:31:39.720]   in some-- in many ways, there's still
[00:31:39.720 --> 00:31:44.960]   an open research problem still today.
[00:31:44.960 --> 00:31:46.880]   Here's showing a little bit in application.
[00:31:46.880 --> 00:31:50.720]   This is background segmentation.
[00:31:50.720 --> 00:31:58.640]   In this case, separating a static background of the foreground.
[00:31:58.640 --> 00:32:01.080]   So we are looking for something like this.
[00:32:01.080 --> 00:32:03.440]   How do we do it?
[00:32:03.440 --> 00:32:06.400]   What we'll actually do is we'll try to estimate
[00:32:06.400 --> 00:32:08.160]   a background image.
[00:32:08.160 --> 00:32:09.480]   We'll actually do this by--
[00:32:09.480 --> 00:32:12.840]   this is a static camera.
[00:32:12.840 --> 00:32:16.720]   So you keep recording it and then cars drive by.
[00:32:16.720 --> 00:32:19.520]   But if you take the average over a long period of time,
[00:32:19.520 --> 00:32:22.960]   or the median, let's say, the median values,
[00:32:22.960 --> 00:32:25.120]   then you can essentially have an image
[00:32:25.120 --> 00:32:29.200]   with no dynamic objects in, a background image.
[00:32:29.200 --> 00:32:32.560]   So once you form that background image, which now
[00:32:32.560 --> 00:32:35.840]   means that we don't have like we had with the green,
[00:32:35.840 --> 00:32:38.200]   one green value that is applied to all the image,
[00:32:38.200 --> 00:32:41.320]   to do the chroma keying, for example.
[00:32:41.320 --> 00:32:46.400]   In this case, every point here has its own background model.
[00:32:46.400 --> 00:32:50.280]   Because this one has a gray background model.
[00:32:50.280 --> 00:32:52.800]   This one has a blue background model, like a sky background
[00:32:52.800 --> 00:32:53.360]   model, et cetera.
[00:32:53.360 --> 00:32:55.840]   So everyone has just its own pixel color.
[00:32:55.840 --> 00:32:59.200]   It's the background model.
[00:32:59.200 --> 00:33:01.880]   If you actually do that as an average of many images,
[00:33:01.880 --> 00:33:03.680]   you can actually do something a little bit better.
[00:33:03.680 --> 00:33:07.880]   So you can have a median here or a mean value,
[00:33:07.880 --> 00:33:11.120]   and also a distribution, a varying distribution.
[00:33:11.120 --> 00:33:12.120]   Yes?
[00:33:12.120 --> 00:33:15.360]   Did neural networks overtake these methods that we looked at,
[00:33:15.360 --> 00:33:18.360]   or are they used in tandem?
[00:33:18.360 --> 00:33:26.280]   So nowadays, you would use neural networks.
[00:33:26.280 --> 00:33:30.440]   I'll actually show one later, segment anything.
[00:33:30.440 --> 00:33:34.960]   The neural networks don't allow a lot of introspection.
[00:33:34.960 --> 00:33:35.960]   It's not clear.
[00:33:35.960 --> 00:33:37.440]   If you just look at a neural network,
[00:33:37.440 --> 00:33:39.480]   I can show you here's a big neural network.
[00:33:39.480 --> 00:33:41.440]   Look at a nice end result.
[00:33:41.440 --> 00:33:42.080]   That's it.
[00:33:42.080 --> 00:33:43.680]   You wouldn't actually know what's going on.
[00:33:43.680 --> 00:33:44.880]   So the people that design--
[00:33:44.880 --> 00:33:46.560]   if you want to design those neural networks,
[00:33:46.560 --> 00:33:48.520]   if you want to try to improve them, isn't that?
[00:33:48.520 --> 00:33:51.640]   You actually need to understand the concepts we discuss here.
[00:33:51.640 --> 00:33:54.400]   All of those ideas get translated in neural networks,
[00:33:54.400 --> 00:33:57.560]   but in a typically pretty opaque way.
[00:33:57.560 --> 00:34:00.400]   You need to make sure that the structure in the neural network
[00:34:00.400 --> 00:34:03.960]   can represent some of the main concepts we discuss here.
[00:34:03.960 --> 00:34:05.320]   So here, they explicit.
[00:34:05.320 --> 00:34:05.960]   You can learn them.
[00:34:05.960 --> 00:34:07.080]   You can get intuition for them.
[00:34:07.080 --> 00:34:09.680]   You can understand when they work and when they fail.
[00:34:09.680 --> 00:34:11.000]   And now if you do a neural network,
[00:34:11.000 --> 00:34:13.520]   and you see it fail in certain ways,
[00:34:13.520 --> 00:34:17.000]   because it's-- we'll also have similar kind of failure cases
[00:34:17.000 --> 00:34:20.240]   and behaviors, you can kind of see like, oh, OK,
[00:34:20.240 --> 00:34:21.120]   this is going wrong.
[00:34:21.120 --> 00:34:23.760]   So I should actually put something in my neural network
[00:34:23.760 --> 00:34:26.960]   that allows it to pick up or take better into account
[00:34:26.960 --> 00:34:29.560]   these aspects and so on.
[00:34:29.560 --> 00:34:31.680]   So that's why it's actually really important to understand
[00:34:31.680 --> 00:34:34.600]   the fundamentals, the principles, essentially,
[00:34:34.600 --> 00:34:36.960]   the trade-offs that are happening in all those automatic
[00:34:36.960 --> 00:34:38.000]   decisions.
[00:34:38.000 --> 00:34:40.440]   And yes, then once all of this is clear,
[00:34:40.440 --> 00:34:42.840]   then you can actually-- so a neural network
[00:34:42.840 --> 00:34:44.280]   works as follows, right?
[00:34:44.280 --> 00:34:45.440]   You don't have any principles.
[00:34:45.440 --> 00:34:47.120]   You don't have any-- this or that.
[00:34:47.120 --> 00:34:48.760]   You provide a certain architecture.
[00:34:48.760 --> 00:34:51.440]   How you do that, you actually need
[00:34:51.440 --> 00:34:53.200]   to understand all of this to know what makes sense
[00:34:53.200 --> 00:34:54.280]   in terms of architecture.
[00:34:54.280 --> 00:34:57.640]   But in the end, you just--
[00:34:57.640 --> 00:35:00.080]   if somebody tells you this neural network,
[00:35:00.080 --> 00:35:04.240]   this neural architecture should do well on that problem,
[00:35:04.240 --> 00:35:05.640]   then at that point, you'd really just
[00:35:05.640 --> 00:35:11.640]   need to feed enough examples of data with solution
[00:35:11.640 --> 00:35:13.840]   and many thousands of it.
[00:35:13.840 --> 00:35:17.280]   And then you can train the network,
[00:35:17.280 --> 00:35:19.960]   and then the network would essentially reproduce
[00:35:19.960 --> 00:35:23.040]   and be able to generate answers.
[00:35:23.040 --> 00:35:25.920]   But you don't actually learn a lot from that.
[00:35:25.920 --> 00:35:30.040]   And you wouldn't necessarily be able to design a network that
[00:35:30.040 --> 00:35:32.720]   would do it properly.
[00:35:32.720 --> 00:35:34.920]   But given the network knowing that this network will give
[00:35:34.920 --> 00:35:37.880]   the result and then having a lot of labeled data,
[00:35:37.880 --> 00:35:40.160]   yes, you can then solve the problem quite well
[00:35:40.160 --> 00:35:42.120]   with a neural network.
[00:35:42.120 --> 00:35:45.040]   But that's not the purpose of this lecture.
[00:35:45.040 --> 00:35:48.240]   That would be very easy and very hard in the sense
[00:35:48.240 --> 00:35:50.040]   you need to label a lot of data.
[00:35:50.040 --> 00:35:52.920]   But if you somehow can get your hands on labeled data
[00:35:52.920 --> 00:35:55.800]   and you know what architecture could solve the problem,
[00:35:55.800 --> 00:35:58.880]   then it's pressing a button and letting the computer figure it out.
[00:35:58.880 --> 00:36:04.520]   But OK.
[00:36:04.520 --> 00:36:05.160]   So let's see.
[00:36:05.160 --> 00:36:17.120]   So here, also as an example, you need to make sure,
[00:36:17.120 --> 00:36:19.120]   also with neural networks, it will
[00:36:19.120 --> 00:36:22.960]   be really important to make sure that you provide
[00:36:22.960 --> 00:36:25.320]   the right information to the neural network
[00:36:25.320 --> 00:36:28.400]   to be able to solve the problem.
[00:36:28.400 --> 00:36:31.360]   I've done projects with students where the students were coming
[00:36:31.360 --> 00:36:33.520]   to me and said, hey, I'm trying really
[00:36:33.520 --> 00:36:36.200]   hard to make this thing work with a neural network
[00:36:36.200 --> 00:36:37.800]   and it doesn't work.
[00:36:37.800 --> 00:36:39.800]   But then if you actually think through the problem
[00:36:39.800 --> 00:36:44.240]   and the principles that are like what the neural network kind
[00:36:44.240 --> 00:36:48.800]   of needs under the hood to be able to make a decision,
[00:36:48.800 --> 00:36:52.160]   to be able to actually solve the problem in a sense,
[00:36:52.160 --> 00:36:56.200]   it can fit a function to stuff to an input-output relationship.
[00:36:56.200 --> 00:36:58.520]   So it can learn an input-output relationship.
[00:36:58.520 --> 00:37:00.960]   Like given this input, this is the output.
[00:37:00.960 --> 00:37:01.960]   It can do that.
[00:37:01.960 --> 00:37:04.040]   But if you feed it the wrong information,
[00:37:04.040 --> 00:37:06.480]   or if along the way you do something to the information
[00:37:06.480 --> 00:37:08.880]   so that you kind of lost the information that is actually
[00:37:08.880 --> 00:37:12.120]   relevant to solve the problem, then
[00:37:12.120 --> 00:37:13.280]   those things don't do magic.
[00:37:13.280 --> 00:37:17.160]   If you don't provide the information you need
[00:37:17.160 --> 00:37:19.800]   to actually allow to solve the information,
[00:37:19.800 --> 00:37:23.200]   so if you don't give the information that's
[00:37:23.200 --> 00:37:25.440]   relevant to solve the problem, it's somehow not there anymore
[00:37:25.440 --> 00:37:28.080]   in the input because you didn't understand what
[00:37:28.080 --> 00:37:30.920]   was needed to solve the problem.
[00:37:30.920 --> 00:37:32.800]   Then it doesn't work, of course.
[00:37:32.800 --> 00:37:36.160]   So it is really important to have some understanding of how
[00:37:36.160 --> 00:37:39.880]   problems are solved, what is relevant, what's not relevant,
[00:37:39.880 --> 00:37:42.880]   et cetera.
[00:37:42.880 --> 00:37:48.000]   And of course, also you could try to play it safe and feed it
[00:37:48.000 --> 00:37:51.240]   every possible information, but that's also typically not
[00:37:51.240 --> 00:37:54.120]   a great idea that requires a ton more data of labeled data,
[00:37:54.120 --> 00:37:56.200]   et cetera, et cetera.
[00:37:56.200 --> 00:38:00.800]   OK, so here, foreground and background,
[00:38:00.800 --> 00:38:03.280]   we've seen before, so the background color here
[00:38:03.280 --> 00:38:05.400]   could be a per pixel background color.
[00:38:05.400 --> 00:38:07.560]   The threshold could be also a threshold.
[00:38:07.560 --> 00:38:12.000]   In this case, you could have an ellipsoid,
[00:38:12.000 --> 00:38:15.840]   you could have something simple like just a fixed threshold,
[00:38:15.840 --> 00:38:20.360]   spherical, you could have a kind of a cuboid kind of threshold.
[00:38:20.360 --> 00:38:24.160]   2020-10, that would be more of a cuboid kind of around the point.
[00:38:24.160 --> 00:38:27.280]   If you know that in R and G, there's more variation than in B,
[00:38:27.280 --> 00:38:33.520]   for example, and so indeed, this is per pixel,
[00:38:33.520 --> 00:38:36.160]   this really based on the background image.
[00:38:36.160 --> 00:38:37.960]   Ideally, you have more something like this.
[00:38:37.960 --> 00:38:39.520]   This represents covariance.
[00:38:39.520 --> 00:38:42.360]   This represents essentially an ellipsoid,
[00:38:42.360 --> 00:38:45.680]   a threshold that has the shape of an ellipsoid.
[00:38:45.680 --> 00:38:49.840]   And then this is kind of the generalized radius or distance
[00:38:49.840 --> 00:38:54.360]   from the center from this point here.
[00:38:54.360 --> 00:38:55.520]   That's generalized in a sense.
[00:38:55.520 --> 00:38:58.960]   It's not a sphere, but it's an ellipsoid.
[00:38:58.960 --> 00:39:00.560]   And if you're above a threshold, so that
[00:39:00.560 --> 00:39:02.120]   draws this elliptic boundary.
[00:39:02.120 --> 00:39:07.600]   And so this is something you can easily fit to data,
[00:39:07.600 --> 00:39:08.200]   this thing here.
[00:39:08.200 --> 00:39:11.880]   That's the variance of that data.
[00:39:11.880 --> 00:39:14.440]   Of all this, for example, background pixels
[00:39:14.440 --> 00:39:17.040]   at a certain location.
[00:39:17.040 --> 00:39:19.160]   So for example, here the segmentation
[00:39:19.160 --> 00:39:21.720]   would give something like this.
[00:39:21.720 --> 00:39:24.000]   There's something interesting is shadows.
[00:39:24.000 --> 00:39:27.000]   Are they part of the object or not?
[00:39:27.000 --> 00:39:28.880]   So that's something to kind of decide again.
[00:39:28.880 --> 00:39:31.000]   Like, do you care about the shadows?
[00:39:31.000 --> 00:39:33.520]   Do you want them-- do we part of your segmentation mask?
[00:39:33.520 --> 00:39:36.080]   Or do you actually want to exclude them?
[00:39:36.080 --> 00:39:38.120]   Again, it's a decision that can depend.
[00:39:38.120 --> 00:39:44.960]   It's asymmetric because it's really always darker.
[00:39:44.960 --> 00:39:46.960]   So a Gaussian can get confused.
[00:39:46.960 --> 00:39:50.160]   Gaussian is fully symmetric around the average.
[00:39:50.160 --> 00:39:52.400]   Clearly, shadows are asymmetric.
[00:39:52.400 --> 00:39:54.640]   It only makes pixels darker.
[00:39:54.640 --> 00:39:59.160]   And so on.
[00:39:59.160 --> 00:40:03.480]   Now we'll pivot to adding spatial relations.
[00:40:03.480 --> 00:40:08.360]   So we've already seen that a little bit with connectivity.
[00:40:08.360 --> 00:40:13.280]   We've seen that with the snake.
[00:40:13.280 --> 00:40:17.160]   That was actually explicitly the boundary itself.
[00:40:17.160 --> 00:40:24.280]   Here we'll see a way to express that
[00:40:24.280 --> 00:40:28.760]   in-- with an optimization algorithm.
[00:40:28.760 --> 00:40:31.680]   We'll formulate this as a mark of random field.
[00:40:31.680 --> 00:40:33.920]   Mark of chains are 1D structures on which you
[00:40:33.920 --> 00:40:36.040]   can do dynamic programming and get exact solutions
[00:40:36.040 --> 00:40:38.480]   to influence problems, et cetera.
[00:40:38.480 --> 00:40:41.520]   Mark of random fields are a generalization
[00:40:41.520 --> 00:40:43.720]   to two-dimension or high dimensional,
[00:40:43.720 --> 00:40:46.400]   but to two-dimensional structures in this particular case.
[00:40:46.400 --> 00:40:51.680]   Let me actually go here.
[00:40:51.680 --> 00:40:54.720]   So they represent an image like this here with connectivities
[00:40:54.720 --> 00:40:57.280]   between all neighboring pixels.
[00:40:57.280 --> 00:40:59.880]   In this case, a four neighborhood.
[00:40:59.880 --> 00:41:05.680]   And we'll essentially now express
[00:41:05.680 --> 00:41:08.640]   the problem we want to solve, the segmentation problem,
[00:41:08.640 --> 00:41:11.680]   as explicitly an energy minimization, which
[00:41:11.680 --> 00:41:16.560]   is also related in physics to ising models and other things.
[00:41:16.560 --> 00:41:18.320]   That's also where it's actually--
[00:41:18.320 --> 00:41:22.840]   because of the relation to problems in physics,
[00:41:22.840 --> 00:41:25.240]   that we talk about energy minimization,
[00:41:25.240 --> 00:41:27.520]   because in physics it's actually about solving
[00:41:27.520 --> 00:41:30.760]   energy minimization problems.
[00:41:30.760 --> 00:41:34.640]   And so we will both have a preference
[00:41:34.640 --> 00:41:39.320]   for each of those pixels to be either foreground or background
[00:41:39.320 --> 00:41:42.400]   based on the data, as we've seen before.
[00:41:42.400 --> 00:41:47.120]   And we'll have also-- we'll express a preference for neighbors
[00:41:47.120 --> 00:41:51.720]   with those that are connected to have the same label.
[00:41:51.720 --> 00:41:55.160]   So we'll put a cost for this label
[00:41:55.160 --> 00:41:59.320]   to deviate from what the data is telling us.
[00:41:59.320 --> 00:42:03.720]   And we'll also put a cost for neighbors to be different.
[00:42:03.720 --> 00:42:07.120]   And so we'll have two sets of things.
[00:42:07.120 --> 00:42:11.000]   We'll have a sum of all of the cost per pixel
[00:42:11.000 --> 00:42:16.400]   of having a labeling follow the data.
[00:42:16.400 --> 00:42:19.160]   And so this is a unary cost.
[00:42:19.160 --> 00:42:22.360]   It's called unary because it's per pixel, single pixel.
[00:42:22.360 --> 00:42:26.640]   And then we'll have binary cost, which essentially combines
[00:42:26.640 --> 00:42:30.400]   two sides, two sides that are connected.
[00:42:30.400 --> 00:42:32.760]   So only neighbors.
[00:42:32.760 --> 00:42:35.840]   And so this is for these edges.
[00:42:35.840 --> 00:42:40.840]   And essentially, it will be what we'll choose is actually
[00:42:40.840 --> 00:42:44.120]   to have them-- I think I have it here--
[00:42:44.120 --> 00:42:48.480]   we'll put a cost of 0 if both have the same label, 0, 0,
[00:42:48.480 --> 00:42:52.320]   or 1, 1, and a fixed cost, k, if they have a different label.
[00:42:52.320 --> 00:42:58.800]   So this cost will either be 0 or k for each of the weights.
[00:42:58.800 --> 00:43:00.160]   And this one will be something that
[00:43:00.160 --> 00:43:02.120]   can be more complicated that's based on the data.
[00:43:02.880 --> 00:43:03.380]   OK.
[00:43:03.380 --> 00:43:08.600]   So it's essentially a label smoothing on the grid.
[00:43:08.600 --> 00:43:10.160]   Oh, actually, here's the cost.
[00:43:10.160 --> 00:43:19.640]   So this is the negative log likelihood of the label given
[00:43:19.640 --> 00:43:21.080]   the data.
[00:43:21.080 --> 00:43:24.280]   So given the measurement you have,
[00:43:24.280 --> 00:43:27.920]   what does it cost to assign it label 0?
[00:43:27.920 --> 00:43:31.360]   How likely is it to assign it label 0?
[00:43:31.360 --> 00:43:33.800]   What is it if you assign it label 1?
[00:43:33.800 --> 00:43:34.300]   Yes?
[00:43:34.300 --> 00:43:36.120]   What is the meaning of the good time of sign?
[00:43:36.120 --> 00:43:41.520]   Wait.
[00:43:41.520 --> 00:43:43.160]   Which one?
[00:43:43.160 --> 00:43:45.760]   Good time of sign.
[00:43:45.760 --> 00:43:48.720]   Yes, so this here--
[00:43:48.720 --> 00:43:52.840]   so this is just this function, this unary cost function.
[00:43:52.840 --> 00:43:54.480]   So this is just a function.
[00:43:54.480 --> 00:43:57.960]   The function is given there.
[00:43:57.960 --> 00:43:59.240]   And that's just a parameter.
[00:44:00.240 --> 00:44:05.160]   So this is meant to represent parameters and data.
[00:44:05.160 --> 00:44:14.440]   So essentially, the way we will solve this--
[00:44:14.440 --> 00:44:17.920]   I will discuss it a bit more in detail after the break--
[00:44:17.920 --> 00:44:20.320]   is essentially to represent all of this
[00:44:20.320 --> 00:44:22.840]   as a discrete optimization problem.
[00:44:22.840 --> 00:44:24.520]   So it turns out that this corresponds to--
[00:44:24.520 --> 00:44:26.520]   it can be solved--
[00:44:26.520 --> 00:44:28.320]   the binary problem actually exactly.
[00:44:28.320 --> 00:44:34.000]   And there's some conditions on both those functions here.
[00:44:34.000 --> 00:44:40.640]   You can actually solve the problem exactly
[00:44:40.640 --> 00:44:42.760]   through a graph cut problem.
[00:44:42.760 --> 00:44:50.800]   Well, essentially, we have these weights here,
[00:44:50.800 --> 00:44:53.560]   represent the unary terms.
[00:44:53.560 --> 00:44:55.960]   These connections here represent--
[00:44:55.960 --> 00:44:59.360]   so we have now a fully connected graph that
[00:44:59.360 --> 00:45:03.640]   connects the source to the sink, which
[00:45:03.640 --> 00:45:06.720]   corresponds to both labels.
[00:45:06.720 --> 00:45:08.680]   And so in the end, we'll do a cut.
[00:45:08.680 --> 00:45:11.840]   And this cut will decide what is assigned to the one label,
[00:45:11.840 --> 00:45:13.320]   what is assigned to the other label.
[00:45:13.320 --> 00:45:16.320]   What you're connected to is what you're assigned to.
[00:45:16.320 --> 00:45:18.480]   We'll discuss this more in detail after the break.
[00:45:18.480 --> 00:45:23.880]   OK, so we'll use Markov-Ranon fields.
[00:45:24.880 --> 00:45:27.440]   We'll solve them with a graph cut.
[00:45:27.440 --> 00:45:34.040]   So essentially, typically, a max flow algorithm.
[00:45:34.040 --> 00:45:42.600]   So essentially, we'll try to estimate
[00:45:42.600 --> 00:45:44.240]   how to get the maximum flow through,
[00:45:44.240 --> 00:45:46.360]   and then the main cut.
[00:45:46.360 --> 00:45:50.160]   So all the places that are saturated
[00:45:50.160 --> 00:45:52.920]   are the ones that get cut.
[00:45:52.920 --> 00:45:54.640]   That's just the algorithms that you
[00:45:54.640 --> 00:45:57.440]   might have seen in some of the theory courses
[00:45:57.440 --> 00:46:00.840]   that have been used for this.
[00:46:00.840 --> 00:46:02.920]   And then you would essentially determine that, OK,
[00:46:02.920 --> 00:46:05.280]   all of those edges are saturated edges.
[00:46:05.280 --> 00:46:06.840]   So those are the ones that are cut.
[00:46:06.840 --> 00:46:10.000]   So essentially, the principle, if you
[00:46:10.000 --> 00:46:12.840]   want to determine the maximum flow,
[00:46:12.840 --> 00:46:15.000]   you just keep pushing more through the network
[00:46:15.000 --> 00:46:17.000]   until a bunch of edges are saturated.
[00:46:17.000 --> 00:46:20.480]   At some point, there must not be a single path
[00:46:20.480 --> 00:46:23.240]   from source to sink.
[00:46:23.240 --> 00:46:25.440]   All the possible paths need to at least somewhere
[00:46:25.440 --> 00:46:28.520]   be saturated, because if not, then along that path,
[00:46:28.520 --> 00:46:31.440]   you could push a little bit more through.
[00:46:31.440 --> 00:46:34.200]   So once everything is saturated, the main cut
[00:46:34.200 --> 00:46:37.880]   is essentially the place of this kind of one connected region.
[00:46:37.880 --> 00:46:39.600]   There could be other random saturated edges,
[00:46:39.600 --> 00:46:43.120]   but there's at least one connected separating cut
[00:46:43.120 --> 00:46:46.160]   that would separate the source from the sink
[00:46:46.160 --> 00:46:50.080]   at that point of saturated edges.
[00:46:50.080 --> 00:46:51.400]   That happens to be the algorithm.
[00:46:51.400 --> 00:46:57.760]   Or that's the problem that can be solved in discrete
[00:46:57.760 --> 00:47:02.480]   optimization that actually solves the optimal solution.
[00:47:02.480 --> 00:47:04.360]   As I said, under some conditions, in particular,
[00:47:04.360 --> 00:47:07.600]   someone was asking, can we have this case negative?
[00:47:07.600 --> 00:47:11.440]   So can we say it's better if neighbors are different?
[00:47:11.440 --> 00:47:12.200]   No, we cannot.
[00:47:12.200 --> 00:47:16.440]   In that case, then you cannot optimize this anymore
[00:47:16.440 --> 00:47:20.720]   with a guaranteed optimal solution at the exit.
[00:47:20.720 --> 00:47:30.240]   So if we essentially find this as the main cut,
[00:47:30.240 --> 00:47:31.800]   we'd cut all of those.
[00:47:31.800 --> 00:47:33.320]   And then essentially, what we have
[00:47:33.320 --> 00:47:37.400]   is that now all of those guys would be labeled with this label.
[00:47:37.400 --> 00:47:39.960]   All of those guys would be labeled with that label.
[00:47:39.960 --> 00:47:44.000]   And that would be the optimal solution for the joint problem
[00:47:44.000 --> 00:47:48.480]   of optimizing all of this energy that
[00:47:48.480 --> 00:47:52.320]   has both unary and pairwise terms, so data terms
[00:47:52.320 --> 00:47:57.320]   and smoothness terms.
[00:47:57.320 --> 00:47:58.600]   This is a smoothness term.
[00:47:58.600 --> 00:48:00.160]   If you have the same--
[00:48:00.160 --> 00:48:02.400]   again, this was here.
[00:48:02.400 --> 00:48:04.160]   If the label is the same, there's no cost.
[00:48:04.160 --> 00:48:07.120]   If two neighbors have the same label, they're both 0.
[00:48:07.120 --> 00:48:07.880]   They're both 1.
[00:48:07.880 --> 00:48:09.080]   No cost.
[00:48:09.080 --> 00:48:11.800]   If they're different, then there's a boundary in your--
[00:48:11.800 --> 00:48:13.920]   that means really, literally, if they're different,
[00:48:13.920 --> 00:48:17.280]   one element of the boundary between your foreground
[00:48:17.280 --> 00:48:19.840]   and your background, then you pay a cost for that.
[00:48:19.840 --> 00:48:22.800]   So in other words, you were saying,
[00:48:22.800 --> 00:48:27.160]   what I'm minimizing is how many boundary connections--
[00:48:27.160 --> 00:48:33.200]   what is the length of my boundary in this four neighborhood.
[00:48:33.200 --> 00:48:35.360]   That's literally discussed here.
[00:48:35.360 --> 00:48:36.720]   k times the length of the boundary.
[00:48:36.720 --> 00:48:42.200]   So also realize that this in a way
[00:48:42.200 --> 00:48:43.640]   is a different formulation when we looked
[00:48:43.640 --> 00:48:45.640]   at the snakes, we also wanted to minimize
[00:48:45.640 --> 00:48:49.880]   how long the boundary was and how bent it was.
[00:48:49.880 --> 00:48:54.800]   It's the same thing expressed in a different way, in a sense.
[00:48:54.800 --> 00:48:56.960]   Again, all those concepts always come back.
[00:48:56.960 --> 00:48:59.800]   If you want to now use modern deep learning and some methods,
[00:48:59.800 --> 00:49:02.920]   you do want to have those terms somehow expressed in there.
[00:49:02.920 --> 00:49:06.320]   This is about choosing your loss function, for example.
[00:49:06.320 --> 00:49:08.560]   That's what you minimize when you train your network.
[00:49:12.400 --> 00:49:15.680]   Again, in a sense, the loss function in a network
[00:49:15.680 --> 00:49:19.520]   is again, you can never solve a problem exactly perfectly,
[00:49:19.520 --> 00:49:20.840]   only if you totally overfit.
[00:49:20.840 --> 00:49:22.800]   So you always have to do trade-offs.
[00:49:22.800 --> 00:49:26.520]   And then the question is, how do you do that trade-off?
[00:49:26.520 --> 00:49:29.160]   How much do you care about these properties versus those properties,
[00:49:29.160 --> 00:49:29.660]   et cetera?
[00:49:29.660 --> 00:49:35.840]   OK, so here just showing a few examples.
[00:49:35.840 --> 00:49:37.680]   This by itself, you don't really need to know.
[00:49:37.680 --> 00:49:39.640]   It's more to illustrate.
[00:49:39.640 --> 00:49:43.240]   This was a foreground label's kind of basics.
[00:49:43.240 --> 00:49:45.200]   And then here, this is actually a model that
[00:49:45.200 --> 00:49:46.920]   tries to look for shadows.
[00:49:46.920 --> 00:49:51.760]   And then somehow, you can unlabel as foreground the things that
[00:49:51.760 --> 00:49:55.880]   actually seem to come from shadow, for example.
[00:49:55.880 --> 00:49:57.600]   So here's a bit an example.
[00:49:57.600 --> 00:50:02.640]   Background image, one of the random images of the live video.
[00:50:02.640 --> 00:50:05.680]   The initial background weight, then here,
[00:50:05.680 --> 00:50:07.360]   a shadow weight that essentially says,
[00:50:07.360 --> 00:50:09.480]   this looks a lot like shadow.
[00:50:09.480 --> 00:50:11.960]   The combination of both gives you this here
[00:50:11.960 --> 00:50:18.360]   as the foreground result that takes the shadow region into account.
[00:50:18.360 --> 00:50:21.000]   And then applying a graph cut to this,
[00:50:21.000 --> 00:50:24.080]   so what we just saw before, could give you something like this,
[00:50:24.080 --> 00:50:27.000]   which regularizes a lot of the small issues.
[00:50:27.000 --> 00:50:31.040]   But if a few too many pixels are labeled the wrong way,
[00:50:31.040 --> 00:50:32.960]   then it can certainly actually increase that,
[00:50:32.960 --> 00:50:36.840]   because by smoothing also the error essentially, in a sense.
[00:50:36.840 --> 00:50:38.560]   So it's not perfect, but it kind of shows you
[00:50:38.560 --> 00:50:41.920]   what you would get a few more examples of this.
[00:50:41.920 --> 00:50:47.640]   I forgot why I was--
[00:50:47.640 --> 00:50:50.000]   I think I mixed this up somehow.
[00:50:50.000 --> 00:50:54.040]   OK, let me switch this.
[00:50:54.040 --> 00:50:54.800]   Here's an example.
[00:50:54.800 --> 00:50:57.840]   This was a paper that was based on graph cuts
[00:50:57.840 --> 00:51:01.600]   and also really placed with the inclusion region
[00:51:01.600 --> 00:51:04.560]   and was iterating between a graph cut, solving the problem,
[00:51:04.560 --> 00:51:09.240]   and then adjusting the inlier distribution,
[00:51:09.240 --> 00:51:12.920]   so both the foreground and background distributions.
[00:51:12.920 --> 00:51:16.160]   So it would use a graph cut to adjust,
[00:51:16.160 --> 00:51:20.280]   to solve the problem based on an inclusion criterion.
[00:51:20.280 --> 00:51:22.440]   Then it would change the inclusion criterion based
[00:51:22.440 --> 00:51:26.160]   on the result of the graph cut, and it would iterate between those two.
[00:51:26.160 --> 00:51:28.440]   This is a very interesting paper published
[00:51:28.440 --> 00:51:34.080]   that Microsoft Research does in years ago or so,
[00:51:34.080 --> 00:51:34.880]   or even a bit more.
[00:51:34.880 --> 00:51:41.680]   So you would start by giving a bounding box, for example,
[00:51:41.680 --> 00:51:43.240]   like this.
[00:51:43.240 --> 00:51:45.000]   And then it would actually-- what it would do
[00:51:45.000 --> 00:51:47.120]   is it would train a model on the foreground.
[00:51:47.120 --> 00:51:49.000]   It would train a model on the background.
[00:51:49.000 --> 00:51:50.760]   So the bounding box is only saying what's inside.
[00:51:50.760 --> 00:51:54.240]   It's also saying what's outside is definitely background.
[00:51:54.240 --> 00:51:56.680]   And what's inside could be both foreground and background.
[00:51:59.440 --> 00:52:04.840]   And here's kind of them playing around for this.
[00:52:04.840 --> 00:52:06.720]   This-- I mean, it should still be-- I
[00:52:06.720 --> 00:52:08.320]   don't know what algorithms they use now,
[00:52:08.320 --> 00:52:12.000]   but up to a few years ago, this was the actual algorithm
[00:52:12.000 --> 00:52:16.600]   that they was put in office and would allow you to cut out
[00:52:16.600 --> 00:52:20.040]   the foreground from an image and do this type of thing.
[00:52:20.040 --> 00:52:25.040]   So this was one of the guys working on this.
[00:52:25.040 --> 00:52:27.000]   These are some of the slides from their presentation
[00:52:27.000 --> 00:52:27.500]   at the time.
[00:52:27.500 --> 00:52:35.080]   In some of the Photoshop and stuff like that,
[00:52:35.080 --> 00:52:39.360]   they had some of these tools that required
[00:52:39.360 --> 00:52:41.440]   you to label a whole bunch of foreground pixels,
[00:52:41.440 --> 00:52:43.520]   and it would do something like this.
[00:52:43.520 --> 00:52:47.240]   Then people did things like intelligent scissors.
[00:52:47.240 --> 00:52:51.960]   The idea here is to-- you label what's definitely inside.
[00:52:51.960 --> 00:52:53.760]   You label what's definitely outside.
[00:52:53.760 --> 00:52:57.400]   And then-- so you can do that very coarsely and fast,
[00:52:57.400 --> 00:52:59.080]   manually.
[00:52:59.080 --> 00:53:02.360]   And then there's-- the algorithm will refine the decision
[00:53:02.360 --> 00:53:04.080]   boundary in the middle.
[00:53:04.080 --> 00:53:06.880]   And how does it do it?
[00:53:06.880 --> 00:53:08.920]   You can actually do a-- essentially,
[00:53:08.920 --> 00:53:11.560]   you can solve this with dynamic programming that
[00:53:11.560 --> 00:53:16.120]   will kind of optimally determine a 1D solution that
[00:53:16.120 --> 00:53:19.280]   closes the loop there.
[00:53:19.280 --> 00:53:24.280]   Anyway, so that would be the kind of result they got.
[00:53:24.280 --> 00:53:27.080]   You could also apply snakes and so on to this.
[00:53:27.080 --> 00:53:30.360]   And then GraphCut required a lot less interaction, just
[00:53:30.360 --> 00:53:33.440]   a box, and would do this.
[00:53:33.440 --> 00:53:35.840]   Again, actually, another illustration.
[00:53:35.840 --> 00:53:37.640]   It's kind of nice in some sense.
[00:53:37.640 --> 00:53:42.800]   So you'll see here, GraphCut, here 1D line in the image.
[00:53:42.800 --> 00:53:45.400]   That's then that kind of illustrated
[00:53:45.400 --> 00:53:47.560]   for that one line, the source and the sync.
[00:53:47.560 --> 00:53:50.160]   And now you kind of see the connections.
[00:53:50.160 --> 00:53:55.280]   This kind of nicely illustrates how the data term, when
[00:53:55.280 --> 00:53:58.040]   it is very likely to be labeled a certain way,
[00:53:58.040 --> 00:54:00.800]   if you're very likely to be labeled foreground,
[00:54:00.800 --> 00:54:03.520]   you actually make a very strong connection between you
[00:54:03.520 --> 00:54:07.200]   and the pixel and the foreground label,
[00:54:07.200 --> 00:54:09.640]   which is the source in this case.
[00:54:09.640 --> 00:54:13.160]   So if you make a very strong connection here,
[00:54:13.160 --> 00:54:16.520]   it means that you're very unlikely to cut that connection
[00:54:16.520 --> 00:54:18.600]   with all the rest being the same in the network,
[00:54:18.600 --> 00:54:20.800]   you're very unlikely to go cut that connection.
[00:54:20.800 --> 00:54:25.720]   It's much more likely that, for this one, for example,
[00:54:25.720 --> 00:54:27.920]   it's much more likely that you end up
[00:54:27.920 --> 00:54:30.200]   with your cut saturating this edge
[00:54:30.200 --> 00:54:32.800]   versus saturating that connection, obviously.
[00:54:32.800 --> 00:54:35.120]   Because the other connection is a lot thicker pipes,
[00:54:35.120 --> 00:54:38.600]   so you're unlikely to end up saturating that one.
[00:54:38.600 --> 00:54:39.840]   This is a pure data term.
[00:54:39.840 --> 00:54:41.360]   This also means if you want to do a GraphCut
[00:54:41.360 --> 00:54:43.080]   and you only have data terms, it's trivial.
[00:54:43.080 --> 00:54:44.560]   It's just the best--
[00:54:44.560 --> 00:54:48.160]   just choose a label individually, one by one.
[00:54:48.160 --> 00:54:50.200]   There's nothing will change.
[00:54:50.200 --> 00:54:53.080]   But if you add those sideways connections,
[00:54:53.080 --> 00:54:54.600]   these are the smoothness connections
[00:54:54.600 --> 00:54:57.360]   that say I prefer neighbors to have the same label,
[00:54:57.360 --> 00:54:59.320]   then that could influence the solution.
[00:54:59.320 --> 00:55:01.440]   In this case, it will not really--
[00:55:01.440 --> 00:55:04.600]   in this case, the min cut will end up actually doing this,
[00:55:04.600 --> 00:55:07.400]   having this shape, because essentially the data
[00:55:07.400 --> 00:55:09.640]   term is very clear.
[00:55:09.640 --> 00:55:12.640]   And so the small additional connection,
[00:55:12.640 --> 00:55:15.040]   you pay the price here to cut the connection here
[00:55:15.040 --> 00:55:16.480]   and the cut the connection there.
[00:55:16.480 --> 00:55:18.440]   So in this particular example, our boundary
[00:55:18.440 --> 00:55:20.880]   has a length of 2 in some sense.
[00:55:20.880 --> 00:55:23.040]   It cuts two connections.
[00:55:23.040 --> 00:55:25.800]   And for the rest, it follows the data very, very nicely.
[00:55:25.800 --> 00:55:26.600]   So great solution.
[00:55:26.600 --> 00:55:31.160]   And by the way, that's the thing.
[00:55:31.160 --> 00:55:35.120]   You can find a global minimum energy in polynomial time.
[00:55:35.120 --> 00:55:38.880]   So it's not an NP-compete problem.
[00:55:38.880 --> 00:55:40.000]   OK, so how did they do that?
[00:55:40.000 --> 00:55:41.800]   As I said, they will do actually two things.
[00:55:41.800 --> 00:55:43.440]   They will solve this problem, and they
[00:55:43.440 --> 00:55:46.200]   will solve it multiple times, the graph cut problem.
[00:55:46.200 --> 00:55:47.760]   But they will iterate on it also.
[00:55:47.760 --> 00:55:50.960]   So initially, you pay, for example, in this example,
[00:55:50.960 --> 00:55:53.520]   this as the box, the bonding box.
[00:55:53.520 --> 00:55:57.520]   So the meaning of the bonding box is everything I care about
[00:55:57.520 --> 00:55:59.440]   is inside the box.
[00:55:59.440 --> 00:56:01.840]   Therefore, everything that's outside the box
[00:56:01.840 --> 00:56:03.960]   is something I definitely don't care about.
[00:56:03.960 --> 00:56:08.640]   There might be stuff I don't care about inside the box also.
[00:56:08.640 --> 00:56:11.680]   And then what they do is a k-means
[00:56:11.680 --> 00:56:14.960]   for learning the color distribution.
[00:56:14.960 --> 00:56:18.840]   We're not going to discuss what k-means is here.
[00:56:18.840 --> 00:56:23.240]   I'll just briefly explain it.
[00:56:23.240 --> 00:56:29.120]   But essentially, k-means essentially
[00:56:29.120 --> 00:56:31.720]   means that you have a bunch of data,
[00:56:31.720 --> 00:56:38.240]   and you will typically randomly initialize k different seeds.
[00:56:39.200 --> 00:56:45.160]   And then you will determine essentially which values are
[00:56:45.160 --> 00:56:47.800]   closest to each of those k centers.
[00:56:47.800 --> 00:56:51.280]   So for every data point, you will look at which of those k
[00:56:51.280 --> 00:56:52.880]   centers is closest to.
[00:56:52.880 --> 00:56:55.520]   You will assign it to that center,
[00:56:55.520 --> 00:56:57.880]   and then you will fit an average to all of the points
[00:56:57.880 --> 00:56:58.800]   assigned to that center.
[00:56:58.800 --> 00:57:01.320]   You will fit a distribution in ellipsoid
[00:57:01.320 --> 00:57:04.240]   to the data closest to that center.
[00:57:04.240 --> 00:57:06.880]   And so you'll have these k distributions, essentially,
[00:57:06.880 --> 00:57:11.080]   that will approximately model your data distribution.
[00:57:11.080 --> 00:57:13.320]   So that's what k-means is.
[00:57:13.320 --> 00:57:17.000]   And so you iterate, so you fit this.
[00:57:17.000 --> 00:57:18.920]   And then once you fit this, you say, OK, now
[00:57:18.920 --> 00:57:22.280]   given this distribution, all of these different distributions,
[00:57:22.280 --> 00:57:23.200]   you can reassign.
[00:57:23.200 --> 00:57:25.280]   And say, oh, now that I fit this here,
[00:57:25.280 --> 00:57:26.680]   it turns out this pixel is actually
[00:57:26.680 --> 00:57:29.240]   a better fit to this other cluster.
[00:57:29.240 --> 00:57:32.360]   So you reassign to the better cluster,
[00:57:32.360 --> 00:57:33.560]   and then you again refit.
[00:57:33.560 --> 00:57:35.920]   And you do that until you converge.
[00:57:35.920 --> 00:57:39.000]   You converge once you don't flip any assignment anymore.
[00:57:39.000 --> 00:57:40.800]   As soon as you don't fit any assignment anymore,
[00:57:40.800 --> 00:57:43.400]   you haven't changed your data, so you would refit exactly
[00:57:43.400 --> 00:57:46.920]   the same distribution.
[00:57:46.920 --> 00:57:48.240]   Anyway, so that's k-means.
[00:57:48.240 --> 00:57:50.920]   It's a typical way of data-driven way
[00:57:50.920 --> 00:57:57.920]   to fit kind of a multimodal distribution.
[00:57:57.920 --> 00:57:58.880]   OK, so we do that.
[00:57:58.880 --> 00:58:02.840]   We fit that to these pixels, to all these colors there.
[00:58:05.600 --> 00:58:08.840]   So the way it works is you fit that,
[00:58:08.840 --> 00:58:11.480]   and you have now a distribution based on these pixels here
[00:58:11.480 --> 00:58:12.280]   for the background.
[00:58:12.280 --> 00:58:14.000]   You have a distribution based on all the pixels
[00:58:14.000 --> 00:58:15.920]   there for the foreground.
[00:58:15.920 --> 00:58:20.800]   And now you apply this graph cut, the one we described before.
[00:58:20.800 --> 00:58:24.080]   You do that, and you get something like this.
[00:58:24.080 --> 00:58:26.520]   It clearly wants really to keep definitely
[00:58:26.520 --> 00:58:27.520]   all of those red pixels.
[00:58:27.520 --> 00:58:30.040]   There were no red pixels outside, no yellow pixels outside,
[00:58:30.040 --> 00:58:31.200]   so those are clearly inside.
[00:58:31.200 --> 00:58:32.880]   They kept.
[00:58:32.880 --> 00:58:35.480]   The other ones, the green ones, were a bit more of a mix.
[00:58:35.480 --> 00:58:38.240]   They were kind of both in the inside distribution
[00:58:38.240 --> 00:58:40.440]   but also in the outside distribution.
[00:58:40.440 --> 00:58:43.120]   They ended up being cut.
[00:58:43.120 --> 00:58:46.960]   Your total energy goes down because what they did here
[00:58:46.960 --> 00:58:53.640]   was to have a common energy, a consistent energy description
[00:58:53.640 --> 00:58:55.040]   that both covers the--
[00:58:55.040 --> 00:59:02.680]   that contains how the data is fitted with these k-means,
[00:59:02.680 --> 00:59:04.360]   as well as the graph cut problem.
[00:59:04.360 --> 00:59:07.640]   So the two are in one energy formulation,
[00:59:07.640 --> 00:59:12.680]   meaning that they can consistently optimize both steps
[00:59:12.680 --> 00:59:15.320]   separately.
[00:59:15.320 --> 00:59:19.800]   So after one iteration of fitting and doing graph cut,
[00:59:19.800 --> 00:59:22.520]   the combined energy goes down.
[00:59:22.520 --> 00:59:26.920]   And then a second, third, fourth, and then they can stop,
[00:59:26.920 --> 00:59:27.800]   essentially.
[00:59:27.800 --> 00:59:29.960]   This is the segmentation.
[00:59:29.960 --> 00:59:32.480]   This is guaranteed to converge.
[00:59:32.480 --> 00:59:34.840]   That means it's guaranteed to not end up oscillating
[00:59:34.840 --> 00:59:38.440]   because both steps minimize the same energy.
[00:59:38.440 --> 00:59:40.440]   Therefore, you're bound to converge.
[00:59:40.440 --> 00:59:44.440]   It doesn't say that it has to converge to a minimum.
[00:59:44.440 --> 00:59:45.800]   We're not saying that.
[00:59:45.800 --> 00:59:48.520]   Also, we're certainly not saying that it has to converge
[00:59:48.520 --> 00:59:49.800]   to the global minimum.
[00:59:49.800 --> 00:59:56.320]   But it is bound to converge.
[00:59:56.320 --> 01:00:00.200]   So it's bound to stop somewhere and not oscillate.
[01:00:00.200 --> 01:00:02.280]   OK, so here's actually more interesting in a sense.
[01:00:02.280 --> 01:00:04.400]   You can kind of see what's happening.
[01:00:04.400 --> 01:00:09.120]   Initially, you have these k-means.
[01:00:09.120 --> 01:00:11.440]   k in this case would have been 1, 2, 3, 4, 5.
[01:00:11.440 --> 01:00:14.560]   So 5, k was 5 here.
[01:00:14.560 --> 01:00:16.680]   You have the foreground and the background distribution.
[01:00:16.680 --> 01:00:20.200]   Or in a sense, initially, it's foreground and background
[01:00:20.200 --> 01:00:21.960]   together for the red distribution.
[01:00:21.960 --> 01:00:25.680]   And it's only background for the blue distribution.
[01:00:25.680 --> 01:00:27.840]   And things that are well modeled by both,
[01:00:27.840 --> 01:00:30.040]   I kind of, because of normalization,
[01:00:30.040 --> 01:00:34.240]   they're kind of more likely to be background, for example.
[01:00:34.240 --> 01:00:36.400]   Anyway, so what you see is it starts
[01:00:36.400 --> 01:00:38.920]   with both distributions really overlapping.
[01:00:38.920 --> 01:00:41.720]   But then as you refit and you get something that's
[01:00:41.720 --> 01:00:44.760]   much closer as we had here, after one iteration,
[01:00:44.760 --> 01:00:46.400]   you have this.
[01:00:46.400 --> 01:00:49.640]   After this happens and you refit your distributions,
[01:00:49.640 --> 01:00:51.360]   you see all that green stuff, it's
[01:00:51.360 --> 01:00:55.000]   much more likely to be background at this point.
[01:00:55.000 --> 01:00:56.600]   And therefore, in your second iteration,
[01:00:56.600 --> 01:01:01.200]   you can further refine and help make the decision.
[01:01:01.200 --> 01:01:02.160]   So that's what you see here.
[01:01:02.160 --> 01:01:03.400]   And after a while, you can actually
[01:01:03.400 --> 01:01:05.520]   separate those distributions.
[01:01:05.520 --> 01:01:07.840]   Initially, the foreground and the background
[01:01:07.840 --> 01:01:09.880]   were very much overlapping.
[01:01:09.880 --> 01:01:12.320]   Here, they've actually been separated into distributions.
[01:01:12.320 --> 01:01:18.520]   Some more examples.
[01:01:18.520 --> 01:01:19.960]   Of course, it doesn't always work.
[01:01:19.960 --> 01:01:22.920]   You might have to refine and do some more interactions
[01:01:22.920 --> 01:01:23.880]   to solve the problem.
[01:01:26.480 --> 01:01:29.960]   Here's some further-- some database
[01:01:29.960 --> 01:01:33.880]   that they used to tune parameters.
[01:01:33.880 --> 01:01:35.400]   Again, some comparisons.
[01:01:35.400 --> 01:01:37.120]   I'll skip through most of this.
[01:01:37.120 --> 01:01:39.880]   You have these in the slides.
[01:01:39.880 --> 01:01:41.720]   But what I want to show was this here.
[01:01:41.720 --> 01:01:44.240]   If you actually want to refine--
[01:01:44.240 --> 01:01:45.680]   and again, you saw that.
[01:01:45.680 --> 01:01:48.440]   And I think there might have been some of related things
[01:01:48.440 --> 01:01:49.040]   in the exercise.
[01:01:49.040 --> 01:01:52.080]   But definitely, we saw it last time with blurred frames
[01:01:52.080 --> 01:01:53.760]   and things like this.
[01:01:53.760 --> 01:01:58.080]   You might not want to have a binary mask that's like,
[01:01:58.080 --> 01:02:02.360]   this pixel is 100% inside and the next pixel is 100% outside.
[01:02:02.360 --> 01:02:03.880]   Because as you can see here, it's
[01:02:03.880 --> 01:02:06.640]   more likely to be a bit of a smooth transition.
[01:02:06.640 --> 01:02:09.240]   And you will have mixed pixels.
[01:02:09.240 --> 01:02:11.280]   Because some pixels, because of blurring and so on,
[01:02:11.280 --> 01:02:12.920]   they will actually integrate a little bit of light
[01:02:12.920 --> 01:02:15.680]   coming from the foreground and a little bit from the background.
[01:02:15.680 --> 01:02:17.360]   Definitely with hair and things like that.
[01:02:17.360 --> 01:02:19.680]   Same transparent things, but even just
[01:02:19.680 --> 01:02:21.040]   at the edge of a surface.
[01:02:21.800 --> 01:02:27.160]   So what they do is they instantiate the region of interest
[01:02:27.160 --> 01:02:27.920]   around it.
[01:02:27.920 --> 01:02:29.640]   And then they will fit a model to foreground,
[01:02:29.640 --> 01:02:31.200]   fit a model to background, and then
[01:02:31.200 --> 01:02:36.160]   find the right continuous transition between the two.
[01:02:36.160 --> 01:02:40.440]   See here, foreground, background fit.
[01:02:40.440 --> 01:02:47.760]   And then you actually fit a curve there and smooth that.
[01:02:47.760 --> 01:02:49.680]   And essentially have that as a model.
[01:02:49.680 --> 01:02:55.520]   And so now you get essentially this kind of known integer
[01:02:55.520 --> 01:02:59.520]   transition, where this is this alpha mask.
[01:02:59.520 --> 01:03:01.680]   So it means the alpha mask says, how much percentage
[01:03:01.680 --> 01:03:03.360]   do you take of the foreground?
[01:03:03.360 --> 01:03:05.520]   And then one minus that you take from the background.
[01:03:05.520 --> 01:03:07.400]   So that together it's like a full pixel.
[01:03:07.400 --> 01:03:12.480]   And so DP means dynamic programming.
[01:03:12.480 --> 01:03:16.240]   So use dynamic programming to find that line.
[01:03:16.240 --> 01:03:19.440]   And then you have a smooth transition.
[01:03:19.440 --> 01:03:24.040]   Skip through that.
[01:03:24.040 --> 01:03:28.840]   I wanted to show you segment anything.
[01:03:28.840 --> 01:03:30.800]   So if we're talking about neural networks,
[01:03:30.800 --> 01:03:31.960]   this is actually quite recent.
[01:03:31.960 --> 01:03:33.800]   It's a few months old.
[01:03:33.800 --> 01:03:36.840]   This was published by Meta.
[01:03:36.840 --> 01:03:40.480]   It has a lot of press.
[01:03:40.480 --> 01:03:44.800]   And if you look at it, I think there's a demo here.
[01:03:44.800 --> 01:03:47.560]   You'll kind of recognize a number of things from others.
[01:03:47.560 --> 01:03:50.200]   So let's click on this one, for example.
[01:03:50.200 --> 01:03:53.080]   So you kind of see what happens here.
[01:03:53.080 --> 01:03:56.200]   My cursor is the seed.
[01:03:56.200 --> 01:03:58.120]   So we're still using the same concepts.
[01:03:58.120 --> 01:04:00.440]   It's not doing things that differently.
[01:04:00.440 --> 01:04:02.800]   So the cursor is the seed.
[01:04:02.800 --> 01:04:04.520]   Even I'm here, it's all pre-segment, of course.
[01:04:04.520 --> 01:04:06.960]   They don't compute this on the fly here in the demo.
[01:04:06.960 --> 01:04:08.120]   They pre-computed all of this.
[01:04:08.120 --> 01:04:10.560]   But essentially, if I move the seed on the dog,
[01:04:10.560 --> 01:04:11.720]   it kind of finds the dog.
[01:04:11.720 --> 01:04:12.720]   I didn't have to tell it.
[01:04:12.720 --> 01:04:14.520]   I didn't have to draw a bonding box.
[01:04:14.520 --> 01:04:16.560]   So I have two corners.
[01:04:16.560 --> 01:04:18.800]   Just one point here is enough.
[01:04:18.800 --> 01:04:21.680]   This triggers the kind of inclusion region and so on.
[01:04:21.680 --> 01:04:25.640]   And it kind of finds this.
[01:04:25.640 --> 01:04:28.080]   You can also see here they have essentially
[01:04:28.080 --> 01:04:29.240]   different versions.
[01:04:29.240 --> 01:04:31.840]   You can upload your own images or gallery.
[01:04:31.840 --> 01:04:34.280]   And then it will compute these things.
[01:04:34.280 --> 01:04:36.520]   You can also do a box.
[01:04:36.520 --> 01:04:40.040]   If I do this, I don't know what's going to happen.
[01:04:40.040 --> 01:04:42.760]   It's what is doing something.
[01:04:42.760 --> 01:04:45.360]   It determines that this is the best foreground.
[01:04:45.360 --> 01:04:49.520]   Obviously, if I do this, then it's
[01:04:49.520 --> 01:04:52.760]   kind of redoing what I expect.
[01:04:52.760 --> 01:04:57.080]   But essentially, this is all using quite advanced deep nets
[01:04:57.080 --> 01:04:58.280]   to do all of this here.
[01:04:58.280 --> 01:05:01.360]   But it kind of solved the same problem.
[01:05:01.360 --> 01:05:03.920]   And they trained it on lots of examples.
[01:05:03.920 --> 01:05:06.560]   Remember last lecture, we showed a few examples
[01:05:06.560 --> 01:05:10.240]   of people having manually segmented things.
[01:05:10.240 --> 01:05:12.800]   So they train on lots and lots and lots of data
[01:05:12.800 --> 01:05:15.840]   that has ground truth segmentations
[01:05:15.840 --> 01:05:17.160]   for these type of problems.
[01:05:17.160 --> 01:05:19.040]   And then essentially, given that, they
[01:05:19.040 --> 01:05:23.360]   can now predict segmentations on new images.
[01:05:23.360 --> 01:05:25.560]   As this one-- let's try another one.
[01:05:25.560 --> 01:05:31.760]   Where was it here?
[01:05:31.760 --> 01:05:33.680]   Actually, you can do everything.
[01:05:33.680 --> 01:05:35.000]   So this will segment everything.
[01:05:35.000 --> 01:05:40.080]   And it will actually just determine
[01:05:40.080 --> 01:05:43.280]   kind of a reasonable set of segmentations.
[01:05:43.280 --> 01:05:45.880]   And so you see a bit of funny stuff.
[01:05:45.880 --> 01:05:50.000]   But overall, doing a quite decent job at--
[01:05:50.000 --> 01:05:52.080]   if you don't tell it what you care about,
[01:05:52.080 --> 01:05:55.320]   it will just do a generic segmentation.
[01:05:55.320 --> 01:05:58.000]   And you see it in actually-- also, a little bit
[01:05:58.000 --> 01:05:59.560]   is a hierarchical thing.
[01:05:59.560 --> 01:06:03.800]   You can kind of see that this tree is part of the tree region
[01:06:03.800 --> 01:06:05.400]   in the back and so on and so on.
[01:06:05.400 --> 01:06:09.600]   But it finds the relevant segmentations here.
[01:06:09.600 --> 01:06:18.480]   Where is-- OK.
[01:06:18.480 --> 01:06:21.400]   Any preference which image we should try?
[01:06:21.400 --> 01:06:21.900]   Next?
[01:06:21.900 --> 01:06:26.880]   Which one?
[01:06:26.880 --> 01:06:27.840]   This one?
[01:06:27.840 --> 01:06:28.440]   OK.
[01:06:28.440 --> 01:06:29.960]   Let's try this one.
[01:06:29.960 --> 01:06:32.680]   OK.
[01:06:32.680 --> 01:06:33.960]   Yes, let's see.
[01:06:33.960 --> 01:06:37.760]   So this is interesting, right?
[01:06:37.760 --> 01:06:42.920]   Sometimes it actually figures out it's one cat, sometimes not.
[01:06:42.920 --> 01:06:45.640]   It's kind of really interesting.
[01:06:45.640 --> 01:06:51.560]   It does kind of give it enough data.
[01:06:51.560 --> 01:06:53.560]   And it actually does really interesting stuff.
[01:06:53.560 --> 01:07:04.560]   OK.
[01:07:04.560 --> 01:07:06.440]   It didn't figure out it's a tripod.
[01:07:06.440 --> 01:07:11.160]   I don't know if there's another-- no.
[01:07:11.160 --> 01:07:17.480]   So you see, right?
[01:07:17.480 --> 01:07:21.720]   So these methods can do a lot.
[01:07:21.720 --> 01:07:26.160]   They're not necessarily fully at holistic interpretation
[01:07:26.160 --> 01:07:27.480]   of the image yet.
[01:07:27.480 --> 01:07:30.360]   It does have some signs of getting there, right?
[01:07:30.360 --> 01:07:33.320]   So being able to associate this region with this region
[01:07:33.320 --> 01:07:35.280]   means that you're definitely going beyond the region.
[01:07:35.280 --> 01:07:38.240]   You're actually interpreting this as kind of one unit
[01:07:38.240 --> 01:07:41.160]   that has some occlusion.
[01:07:41.160 --> 01:07:43.240]   The tripod, it didn't figure out.
[01:07:43.240 --> 01:07:45.560]   Probably if it was-- if you saw the whole tripod,
[01:07:45.560 --> 01:07:48.120]   it would probably figure it out.
[01:07:48.120 --> 01:07:48.620]   OK.
[01:07:49.380 --> 01:07:53.140]   I encourage you to try this yourself, right?
[01:07:53.140 --> 01:07:55.140]   Just look for a segment, anything.
[01:07:55.140 --> 01:07:57.900]   You'll find this, play with it around with it.
[01:07:57.900 --> 01:08:01.740]   Get some idea of how it works and where it doesn't work.
[01:08:01.740 --> 01:08:03.540]   And you saw you can upload your own images,
[01:08:03.540 --> 01:08:04.700]   so just play around with it.
[01:08:04.700 --> 01:08:07.600]   OK.
[01:08:07.600 --> 01:08:09.700]   So now we'll switch from--
[01:08:09.700 --> 01:08:13.860]   first, we look purely at the data.
[01:08:13.860 --> 01:08:14.360]   Right?
[01:08:14.360 --> 01:08:16.060]   So we purely look at the data.
[01:08:16.060 --> 01:08:18.060]   OK.
[01:08:18.060 --> 01:08:18.560]   Right?
[01:08:18.560 --> 01:08:20.220]   So we purely looked at the images
[01:08:20.220 --> 01:08:22.820]   and decided inclusion criteria purely
[01:08:22.820 --> 01:08:25.260]   based on the pixel value, for example,
[01:08:25.260 --> 01:08:27.580]   or the color or whatever.
[01:08:27.580 --> 01:08:30.100]   Then we included the spatial component,
[01:08:30.100 --> 01:08:33.420]   and we were trading off spatial components
[01:08:33.420 --> 01:08:34.900]   with data components, right?
[01:08:34.900 --> 01:08:37.220]   What we see in the image, but traded off
[01:08:37.220 --> 01:08:39.780]   with what we expect in terms of how the segmentation should
[01:08:39.780 --> 01:08:40.900]   look like.
[01:08:40.900 --> 01:08:42.860]   Now we'll pivot a little bit even further,
[01:08:42.860 --> 01:08:47.780]   and we look purely at the spatial component.
[01:08:47.780 --> 01:08:50.300]   And so we'll do operations that just kind of relabeled
[01:08:50.300 --> 01:08:55.500]   based on how the binary mask looks like independently
[01:08:55.500 --> 01:08:58.660]   of data labeling.
[01:08:58.660 --> 01:09:04.140]   This part, you won't need to study this in detail
[01:09:04.140 --> 01:09:06.900]   for the exam or so.
[01:09:06.900 --> 01:09:09.060]   So I'll just go briefly over it.
[01:09:09.060 --> 01:09:11.500]   There's a lot of slides, and I won't cover probably all of it
[01:09:11.500 --> 01:09:13.060]   in the next 20 minutes.
[01:09:13.060 --> 01:09:18.820]   So we'll define them or operations.
[01:09:18.820 --> 01:09:22.620]   For example, here, the eight neighbor erode,
[01:09:22.620 --> 01:09:26.660]   or which is also called the Minkowski subtraction,
[01:09:26.660 --> 01:09:29.020]   it will erase any foreground pixel
[01:09:29.020 --> 01:09:31.220]   that has one of its eight connected neighbors
[01:09:31.220 --> 01:09:32.300]   that is background.
[01:09:32.300 --> 01:09:33.620]   OK?
[01:09:33.620 --> 01:09:36.540]   So let's say you have an image, an image segment like this.
[01:09:36.540 --> 01:09:37.900]   You threshold it.
[01:09:37.900 --> 01:09:39.940]   You get something like this.
[01:09:39.940 --> 01:09:45.860]   One time running that erosion means that every white pixel
[01:09:45.860 --> 01:09:48.380]   here, it only affects white pixels.
[01:09:48.380 --> 01:09:51.180]   Every white pixel here, you look at all its neighbors.
[01:09:51.180 --> 01:09:58.060]   If one of them is black, boom, you erase that pixel.
[01:09:58.060 --> 01:10:02.260]   You actually, at the bottom here, you see which pixels flipped.
[01:10:02.260 --> 01:10:04.100]   So each of those are at least one neighbor,
[01:10:04.100 --> 01:10:05.740]   so you kind of get rid of them.
[01:10:05.740 --> 01:10:07.780]   You get that image.
[01:10:07.780 --> 01:10:10.100]   Given that image, you can run it again if you want.
[01:10:10.100 --> 01:10:13.420]   The same process.
[01:10:13.420 --> 01:10:17.660]   Now, the next ones, these now have a neighbor that's black,
[01:10:17.660 --> 01:10:19.700]   and so they get erased.
[01:10:19.700 --> 01:10:22.460]   And you can keep running that until there's nothing left,
[01:10:22.460 --> 01:10:23.580]   for example.
[01:10:23.580 --> 01:10:27.860]   Then it stops, because it only affects foreground pixels.
[01:10:27.860 --> 01:10:30.460]   You can do also the inverse of this.
[01:10:30.460 --> 01:10:32.140]   Eight neighbor dilate.
[01:10:32.140 --> 01:10:35.620]   Again, remember, it's important to actually always check what
[01:10:35.620 --> 01:10:36.940]   is the neighborhood structure here.
[01:10:36.940 --> 01:10:39.380]   It would behave differently if it was a four neighborhood.
[01:10:39.380 --> 01:10:41.540]   You can also do this with a four neighborhood, of course,
[01:10:41.540 --> 01:10:44.700]   but it would just behave differently.
[01:10:44.700 --> 01:10:47.100]   This is called Minkowski addition.
[01:10:47.100 --> 01:10:49.540]   Also, so essentially, it's the reverse.
[01:10:49.540 --> 01:10:53.700]   So paint any background pixel that
[01:10:53.700 --> 01:10:58.700]   has at least one eight connected neighbor that is four broad.
[01:10:58.700 --> 01:11:00.140]   So it's kind of the reverse.
[01:11:00.140 --> 01:11:02.860]   You start from the same picture, but now it gets essentially
[01:11:02.860 --> 01:11:04.340]   fatter and fatter, essentially.
[01:11:04.340 --> 01:11:07.700]   So like this until all the pixels are white.
[01:11:07.700 --> 01:11:11.420]   Why would you do this?
[01:11:11.420 --> 01:11:14.940]   Well, it can be a simple way to clean up an image,
[01:11:14.940 --> 01:11:19.700]   to do some boundary shape analysis,
[01:11:19.700 --> 01:11:23.180]   remove noise and artifacts from imperfect segmentations
[01:11:23.180 --> 01:11:24.820]   in a kind of straightforward way.
[01:11:24.820 --> 01:11:30.300]   So those take two arguments, these operators.
[01:11:30.300 --> 01:11:34.180]   They take a binary image and a structuring element.
[01:11:34.180 --> 01:11:35.380]   Now, you're going to want to-- what's
[01:11:35.380 --> 01:11:36.380]   this structuring element?
[01:11:36.380 --> 01:11:37.980]   Well, that's actually the neighborhood
[01:11:37.980 --> 01:11:39.300]   we were talking about earlier.
[01:11:39.300 --> 01:11:41.500]   You can actually do also different things.
[01:11:41.500 --> 01:11:43.580]   So we looked at eight neighborhood, four neighborhood.
[01:11:43.580 --> 01:11:44.820]   You could actually choose any shape
[01:11:44.820 --> 01:11:47.020]   you want as a structuring element.
[01:11:47.020 --> 01:11:51.780]   Those two together determine the output.
[01:11:51.780 --> 01:11:56.060]   These are examples of structuring elements.
[01:11:56.060 --> 01:11:58.500]   So this is clearly an eight neighborhood, right?
[01:11:58.500 --> 01:12:01.340]   Given this pixel, all of the surrounding ones
[01:12:01.340 --> 01:12:05.180]   are the neighborhood.
[01:12:05.180 --> 01:12:08.940]   Given this pixel, this is the four neighborhood,
[01:12:08.940 --> 01:12:13.020]   but you could also define one like this.
[01:12:13.020 --> 01:12:15.300]   That says given this pixel, this pixel actually is not
[01:12:15.300 --> 01:12:20.500]   included, but you have more pixels on this side included,
[01:12:20.500 --> 01:12:20.980]   for example.
[01:12:25.180 --> 01:12:29.220]   We can actually represent--
[01:12:29.220 --> 01:12:31.260]   one way to represent these binary images,
[01:12:31.260 --> 01:12:32.700]   that makes sense in this context,
[01:12:32.700 --> 01:12:38.980]   is really just as a list of pixels that are one.
[01:12:38.980 --> 01:12:42.780]   So this image here corresponds to this list here.
[01:12:42.780 --> 01:12:47.340]   It's just a different way to represent that binary image.
[01:12:47.340 --> 01:12:49.380]   And then you can essentially--
[01:12:49.380 --> 01:12:52.460]   but I leave this to those of you that are interested.
[01:12:52.460 --> 01:12:54.100]   This will not be asked at the exam or so.
[01:12:54.100 --> 01:12:59.060]   You can define, essentially, or you
[01:12:59.060 --> 01:13:00.700]   can use all these set notations here,
[01:13:00.700 --> 01:13:05.020]   unions and intersections, complements and differences.
[01:13:05.020 --> 01:13:08.500]   Those are the definitions here as a refresher.
[01:13:08.500 --> 01:13:13.820]   Then you can define these operations based on that.
[01:13:13.820 --> 01:13:15.460]   Fitting, hitting, and missing.
[01:13:15.460 --> 01:13:21.420]   And you see the definitions are a little bit complicated.
[01:13:21.420 --> 01:13:24.260]   You can look at this quietly.
[01:13:24.260 --> 01:13:30.780]   If you're interested, conceptually, it works as follow.
[01:13:30.780 --> 01:13:41.940]   So here, we have this element is fitting here.
[01:13:41.940 --> 01:13:47.980]   It's hitting here, and it's missing here.
[01:13:47.980 --> 01:13:52.180]   So here, it's this element here.
[01:13:52.180 --> 01:13:55.460]   If you apply it to this pixel here,
[01:13:55.460 --> 01:13:59.860]   wherever it has a one here, it also has a one here.
[01:13:59.860 --> 01:14:00.700]   So center it here.
[01:14:00.700 --> 01:14:03.420]   It has a one here, a one here, one here, one here,
[01:14:03.420 --> 01:14:04.580]   and one here.
[01:14:04.580 --> 01:14:06.420]   So that's a fitting.
[01:14:06.420 --> 01:14:09.820]   That is-- you can go through this here,
[01:14:09.820 --> 01:14:12.820]   through this definition for fitting and verify this yourself,
[01:14:12.820 --> 01:14:14.500]   if you're interested.
[01:14:14.500 --> 01:14:18.700]   The missing, the hitting, you see that actually,
[01:14:18.700 --> 01:14:21.820]   if you apply this over here, it's missing here.
[01:14:21.820 --> 01:14:25.340]   It's not a hit here, not a hit here, not a hit here,
[01:14:25.340 --> 01:14:27.100]   not a hit here, but here it's actually hit.
[01:14:27.100 --> 01:14:29.740]   So at least one of the pixels hits,
[01:14:29.740 --> 01:14:32.620]   overlaps with an existing pixel in the image.
[01:14:32.620 --> 01:14:34.060]   So we have a hit there.
[01:14:34.060 --> 01:14:36.900]   And then a miss means that from here,
[01:14:36.900 --> 01:14:39.340]   there's nothing here, here, here, here, or here.
[01:14:39.340 --> 01:14:40.620]   So it's a miss.
[01:14:40.620 --> 01:14:43.660]   So none of those pixels that are on there are actually
[01:14:43.660 --> 01:14:45.940]   on here for that location.
[01:14:45.940 --> 01:14:57.580]   So erosion can be also defined in the context of fitting,
[01:14:57.580 --> 01:14:58.020]   et cetera.
[01:14:58.020 --> 01:15:04.220]   Here's some examples of how you could apply this
[01:15:04.220 --> 01:15:11.260]   to our ever recurrent segmentation example here.
[01:15:11.260 --> 01:15:14.380]   So you see here, you have this region.
[01:15:14.380 --> 01:15:17.780]   You can kind of apply a structuring element that's much
[01:15:17.780 --> 01:15:19.980]   more than an 8 neighborhood.
[01:15:19.980 --> 01:15:21.420]   It's much bigger.
[01:15:21.420 --> 01:15:26.420]   Let's see, you could call this a 25 neighborhood, if you want.
[01:15:26.420 --> 01:15:29.260]   If you apply that to this image, that's what would result.
[01:15:29.260 --> 01:15:36.740]   So you see, so this is applying erosion.
[01:15:36.740 --> 01:15:38.900]   And then this is applying actually
[01:15:38.900 --> 01:15:40.860]   a different structuring element to one of those diagonal
[01:15:40.860 --> 01:15:41.360]   elements.
[01:15:41.360 --> 01:15:44.020]   So you see that it behaves differently.
[01:15:44.020 --> 01:15:45.940]   So you can choose different structuring elements.
[01:15:45.940 --> 01:15:49.220]   They will actually make the thing look different.
[01:15:49.220 --> 01:15:52.620]   You can also do dilation.
[01:15:52.620 --> 01:15:56.780]   Again, here, defined with these set principles,
[01:15:56.780 --> 01:15:57.820]   that's how it looks like.
[01:15:57.820 --> 01:15:59.940]   So you see now with this structuring element,
[01:15:59.940 --> 01:16:03.820]   every little dot here, a single dot that occurred,
[01:16:03.820 --> 01:16:07.260]   now becomes essentially-- each of those dot
[01:16:07.260 --> 01:16:09.700]   becomes after the dilation, becomes a big blob.
[01:16:09.700 --> 01:16:16.300]   And again, every dot here becomes a stripe
[01:16:16.300 --> 01:16:19.140]   with that structuring element.
[01:16:19.140 --> 01:16:22.620]   Then you can actually define, opening and closing,
[01:16:22.620 --> 01:16:26.580]   what are those where they're a sequence of doing first--
[01:16:26.580 --> 01:16:31.660]   opening is first erosion, then dilation.
[01:16:31.660 --> 01:16:34.260]   So they, of course, are a little bit each other's inverse.
[01:16:34.260 --> 01:16:41.940]   So by doing them in that order, first eroding, then dilating,
[01:16:41.940 --> 01:16:43.460]   in most places, nothing will happen.
[01:16:43.460 --> 01:16:45.700]   You will just cancel out.
[01:16:45.700 --> 01:16:48.020]   But in places where you had a single dot,
[01:16:48.020 --> 01:16:49.620]   that dot is not gone.
[01:16:49.620 --> 01:16:51.020]   And so now when you do dilation, well,
[01:16:51.020 --> 01:16:51.940]   there's nothing coming back.
[01:16:51.940 --> 01:16:53.540]   It's gone.
[01:16:53.540 --> 01:16:56.140]   So you're getting that effect.
[01:16:56.140 --> 01:17:00.860]   And vice versa, closing means you're going to close up stuff.
[01:17:00.860 --> 01:17:02.860]   A small hole will be closed up.
[01:17:02.860 --> 01:17:04.300]   Then you will not reopen it.
[01:17:04.300 --> 01:17:06.140]   So then that's the closing.
[01:17:06.140 --> 01:17:09.940]   So here you see that applied to the duck here.
[01:17:09.940 --> 01:17:15.420]   Original closing means that all the small holes, like here
[01:17:15.420 --> 01:17:19.820]   and here and so on, those are all nicely closed now.
[01:17:19.820 --> 01:17:21.860]   And then vice versa here, the opening
[01:17:21.860 --> 01:17:25.740]   gets rid of all of this mess that was randomly spread around.
[01:17:25.740 --> 01:17:30.860]   Meaning you can actually also do both after each other,
[01:17:30.860 --> 01:17:31.980]   if you want in a sense.
[01:17:31.980 --> 01:17:38.660]   So these type of filters are typically
[01:17:38.660 --> 01:17:40.820]   used for removing holes and foreground
[01:17:40.820 --> 01:17:42.700]   and islands in the background.
[01:17:42.700 --> 01:17:45.100]   You can do both opening and closing.
[01:17:45.100 --> 01:17:46.780]   Size and shape of destructive elements
[01:17:46.780 --> 01:17:49.020]   will determine what size of things survive.
[01:17:49.020 --> 01:17:54.300]   And so if you don't know better, you
[01:17:54.300 --> 01:17:58.700]   could use a circular structure element.
[01:17:58.700 --> 01:18:04.420]   You know, a big blob or a square or a circle is even better.
[01:18:04.420 --> 01:18:06.540]   Here's kind of an example of how this could be applied
[01:18:06.540 --> 01:18:10.820]   to counting these red blood cells.
[01:18:13.580 --> 01:18:15.820]   This is kind of basic image processing.
[01:18:15.820 --> 01:18:20.980]   Let me actually skip through this here.
[01:18:20.980 --> 01:18:26.300]   But essentially, the idea is to threshold and then label.
[01:18:26.300 --> 01:18:33.180]   And then here it does an opening with a disk of size 11.
[01:18:33.180 --> 01:18:36.940]   Meaning that all of the small things, like here,
[01:18:36.940 --> 01:18:40.700]   these small things that are smaller than a size 11 disk,
[01:18:40.700 --> 01:18:44.380]   they would actually disappear.
[01:18:44.380 --> 01:18:49.180]   And the bigger you make it, the size 19, still most things
[01:18:49.180 --> 01:18:53.420]   are here, size 59, boom, now, certainly most of the blobs
[01:18:53.420 --> 01:18:57.460]   are gone because they were too small to survive an opening
[01:18:57.460 --> 01:19:00.620]   with a disk of 59.
[01:19:00.620 --> 01:19:03.540]   You can kind of keep track of this, of how this behaves.
[01:19:03.540 --> 01:19:05.420]   So initially, you have 400 blobs.
[01:19:05.420 --> 01:19:08.900]   But very quickly, you get at about here 200 or a bit
[01:19:08.900 --> 01:19:12.260]   below 200 blobs, red blood cells.
[01:19:12.260 --> 01:19:13.780]   There's a nice plateau.
[01:19:13.780 --> 01:19:17.100]   And then at some point, you kind of start losing all of them.
[01:19:17.100 --> 01:19:19.380]   You clearly were looking for two big blobs that are bigger
[01:19:19.380 --> 01:19:21.180]   than your typical red blood cell.
[01:19:21.180 --> 01:19:26.460]   So this could be one way to count for these things.
[01:19:26.460 --> 01:19:33.020]   Here, there's hidden mistransformations.
[01:19:36.180 --> 01:19:38.820]   This one essentially wants to have an exact match.
[01:19:38.820 --> 01:19:43.660]   Or it's kind of combining-- essentially,
[01:19:43.660 --> 01:19:47.500]   it wants to hit those two places,
[01:19:47.500 --> 01:19:48.780]   and it wants to miss here.
[01:19:48.780 --> 01:19:54.420]   So essentially, if you apply that,
[01:19:54.420 --> 01:19:56.700]   this pattern shows up here.
[01:19:56.700 --> 01:19:58.540]   Therefore, we'll have a one here.
[01:19:58.540 --> 01:20:00.220]   So that's what you see here.
[01:20:00.220 --> 01:20:01.940]   It also shows up here.
[01:20:01.940 --> 01:20:03.220]   So that gives a one here.
[01:20:03.220 --> 01:20:05.020]   So it's only when you have the exact pattern
[01:20:05.020 --> 01:20:07.620]   that it actually says, OK, good.
[01:20:07.620 --> 01:20:09.060]   I put a one here.
[01:20:09.060 --> 01:20:11.100]   If you don't have the exact pattern, both the hit and the
[01:20:11.100 --> 01:20:13.180]   miss together, then it doesn't work.
[01:20:13.180 --> 01:20:13.660]   Yes?
[01:20:13.660 --> 01:20:16.780]   Isn't that basically building a cell or automaton?
[01:20:16.780 --> 01:20:19.140]   These are all things that you build with cell or automaton.
[01:20:19.140 --> 01:20:19.640]   Yes.
[01:20:19.640 --> 01:20:26.460]   You can also just leave one and define, for example, as well.
[01:20:26.460 --> 01:20:30.180]   OK, so this would be one way to find corners.
[01:20:30.180 --> 01:20:31.660]   For example, a simple way.
[01:20:31.660 --> 01:20:34.820]   You say, I want to hit this.
[01:20:34.820 --> 01:20:37.500]   And I want to miss this.
[01:20:37.500 --> 01:20:40.140]   That's a way to say I want an upper right corner.
[01:20:40.140 --> 01:20:43.980]   I want ones with this pattern and zeros with that pattern.
[01:20:43.980 --> 01:20:46.140]   So that essentially corresponds to a pattern like this here,
[01:20:46.140 --> 01:20:48.420]   where you don't really care what happens at the excess.
[01:20:48.420 --> 01:20:55.660]   People have done things like where they use this.
[01:20:55.660 --> 01:20:59.420]   This fitting and this thickening with these patterns,
[01:20:59.420 --> 01:21:02.820]   something that you see there, applied also here.
[01:21:02.820 --> 01:21:05.940]   But now it's kind of more directional.
[01:21:05.940 --> 01:21:08.300]   So they can apply all these different orientations,
[01:21:08.300 --> 01:21:11.940]   finning and thickening, et cetera, with something like
[01:21:11.940 --> 01:21:16.580]   this here, so from all sides.
[01:21:16.580 --> 01:21:20.500]   And as you sequentially apply this, it will lead to this.
[01:21:20.500 --> 01:21:24.420]   But because of the hit and miss combination,
[01:21:24.420 --> 01:21:27.740]   this requires things to still be there.
[01:21:27.740 --> 01:21:30.620]   It cannot really fully erase pixels because then you don't
[01:21:30.620 --> 01:21:31.660]   have on pixels anymore.
[01:21:31.660 --> 01:21:36.380]   You need a combination of some pixels on and some pixels off.
[01:21:36.380 --> 01:21:41.500]   So if you look for a pattern that has this is off and this is on,
[01:21:41.500 --> 01:21:42.980]   and then you can move it inside.
[01:21:42.980 --> 01:21:44.300]   And so you can keep doing that.
[01:21:44.300 --> 01:21:46.620]   But at some point, there's nothing on the other side anymore.
[01:21:46.620 --> 01:21:47.700]   There's no inside anymore.
[01:21:47.700 --> 01:21:49.100]   Then you have to stop.
[01:21:49.100 --> 01:21:51.540]   So in a sense, what does it do?
[01:21:51.540 --> 01:21:53.660]   It kind of finds you a skeleton, in a sense.
[01:21:53.660 --> 01:21:57.060]   It just shrinks the thing until there's just one line left.
[01:22:00.420 --> 01:22:04.140]   By the way, you can find this and play around with this in Python.
[01:22:04.140 --> 01:22:06.460]   You can also do the same sequential thickening,
[01:22:06.460 --> 01:22:08.860]   going through the whole alphabet of all orientations
[01:22:08.860 --> 01:22:11.980]   of boundaries, and just thicken things.
[01:22:11.980 --> 01:22:17.540]   But you can also not get rid of these regions here, for example.
[01:22:17.540 --> 01:22:20.220]   So in the end, you end up with an image like this here,
[01:22:20.220 --> 01:22:20.820]   for example.
[01:22:20.820 --> 01:22:26.460]   So people have used this in image processing and medical image
[01:22:26.460 --> 01:22:29.380]   processing in particular.
[01:22:29.380 --> 01:22:32.340]   They introduced something that's called a medial axis transform.
[01:22:32.340 --> 01:22:39.900]   So this is essentially-- they kind of represent this kind
[01:22:39.900 --> 01:22:41.860]   of stick figure type stuff.
[01:22:41.860 --> 01:22:45.020]   Conceptually, what it does is you could kind of think of it
[01:22:45.020 --> 01:22:48.940]   as start a grass fire at the boundary,
[01:22:48.940 --> 01:22:50.940]   and it starts burning inside.
[01:22:50.940 --> 01:22:52.500]   Let's say like this here.
[01:22:52.500 --> 01:22:54.860]   So if you start a fire there, in the end,
[01:22:54.860 --> 01:22:58.500]   you're going to end up with just one--
[01:22:58.500 --> 01:23:01.500]   where the fire will meet will be at the one point in the middle.
[01:23:01.500 --> 01:23:03.780]   So the fire goes, and it collapses in the middle.
[01:23:03.780 --> 01:23:06.660]   That's where it stops to burn.
[01:23:06.660 --> 01:23:11.380]   But if you do it like this here, then this will move this way.
[01:23:11.380 --> 01:23:13.580]   This boundary will move this way.
[01:23:13.580 --> 01:23:16.020]   Along this boundary, the two fronts
[01:23:16.020 --> 01:23:20.020]   will always end up meeting at that location.
[01:23:20.020 --> 01:23:22.220]   So in this case, this kind of skeleton
[01:23:22.220 --> 01:23:23.980]   would go like this, until, of course,
[01:23:23.980 --> 01:23:25.420]   the two boundaries here collapse,
[01:23:25.420 --> 01:23:26.860]   and then you have this whole boundary.
[01:23:26.860 --> 01:23:36.580]   So this is a way to determine a kind of skeleton.
[01:23:36.580 --> 01:23:38.940]   And you can see this as--
[01:23:38.940 --> 01:23:41.380]   you can actually define this properly
[01:23:41.380 --> 01:23:45.820]   as the union of the centers of all the maximal disks
[01:23:45.820 --> 01:23:48.100]   within the shape.
[01:23:48.100 --> 01:23:51.580]   Where a maximum disk is a circular subset of x
[01:23:51.580 --> 01:23:55.180]   that touches the boundary in at least two places.
[01:23:55.180 --> 01:24:01.340]   If you look back here, if I want a circle that touches here
[01:24:01.340 --> 01:24:04.940]   and here, these two boundaries, a circle here,
[01:24:04.940 --> 01:24:06.140]   it will touch here and here.
[01:24:06.140 --> 01:24:08.900]   The center of it will be on this line.
[01:24:08.900 --> 01:24:10.140]   And I can do a smaller circle.
[01:24:10.140 --> 01:24:11.020]   It will be over here.
[01:24:11.020 --> 01:24:12.500]   A bigger circle will be over here.
[01:24:12.500 --> 01:24:15.020]   At some point, the bigger circle will have touch here, here,
[01:24:15.020 --> 01:24:16.340]   but also here.
[01:24:16.340 --> 01:24:17.620]   That's when I'm here.
[01:24:17.620 --> 01:24:21.020]   And that size circle, I can keep sliding in back and forth here.
[01:24:21.020 --> 01:24:24.340]   It touches here and here, and the midpoint is here.
[01:24:24.340 --> 01:24:25.780]   So essentially, and those are all the ones that
[01:24:25.780 --> 01:24:27.380]   are as big as possible.
[01:24:27.380 --> 01:24:31.540]   So when it touches two sides, so all of the ones
[01:24:31.540 --> 01:24:34.820]   that touch two sides, the union of all of them
[01:24:34.820 --> 01:24:37.620]   will give you this skeleton.
[01:24:37.620 --> 01:24:39.780]   This is the medial axis transform.
[01:24:39.780 --> 01:24:43.980]   Almost, actually.
[01:24:43.980 --> 01:24:45.300]   That's the skeleton.
[01:24:45.300 --> 01:24:47.380]   And then the medial axis transform
[01:24:47.380 --> 01:24:48.860]   is actually going to--
[01:24:48.860 --> 01:24:50.420]   it looks like this.
[01:24:50.420 --> 01:24:53.780]   It will actually remember, at each of those points,
[01:24:53.780 --> 01:24:55.580]   it will actually remember a value,
[01:24:55.580 --> 01:24:58.780]   which is how big was the circle.
[01:24:58.780 --> 01:25:00.420]   The interesting thing is, if you have that,
[01:25:00.420 --> 01:25:01.620]   you can actually reconstruct.
[01:25:01.620 --> 01:25:03.740]   So the medial axis transform allows
[01:25:03.740 --> 01:25:06.820]   you to reconstruct this binary shape.
[01:25:06.820 --> 01:25:10.700]   Because if I know here, I have this radius, the one I read
[01:25:10.700 --> 01:25:11.460]   off here.
[01:25:11.460 --> 01:25:14.100]   So this radius, I can do this.
[01:25:14.100 --> 01:25:16.300]   And then that one there has this radius.
[01:25:16.300 --> 01:25:19.140]   And if I take the union of all those circles,
[01:25:19.140 --> 01:25:23.100]   I actually can reconstruct the original shape.
[01:25:23.100 --> 01:25:24.220]   This works in 2D.
[01:25:24.220 --> 01:25:29.820]   Let's skip this.
[01:25:29.820 --> 01:25:31.860]   But it also works in 3D, for example.
[01:25:31.860 --> 01:25:36.300]   So in 3D, you will have the curves and shapes in 3D,
[01:25:36.300 --> 01:25:37.540]   like here.
[01:25:37.540 --> 01:25:41.260]   And the color, each of those points has a color that's
[01:25:41.260 --> 01:25:46.140]   the size now not of a disk, but the size of a sphere.
[01:25:46.140 --> 01:25:47.500]   And so you have essentially-- this
[01:25:47.500 --> 01:25:49.900]   is a collection of spheres that all
[01:25:49.900 --> 01:25:55.660]   lives on these surfaces here, these kind of strange surfaces.
[01:25:55.660 --> 01:25:58.180]   And if you take the union of all those spheres,
[01:25:58.180 --> 01:26:00.100]   you will have the original shape back.
[01:26:00.100 --> 01:26:02.620]   And of course, with a sphere, you need three points
[01:26:02.620 --> 01:26:03.500]   where you touch.
[01:26:03.500 --> 01:26:11.700]   Here's another example of this medial axis transform.
[01:26:11.700 --> 01:26:16.380]   In a way, again, on every point here,
[01:26:16.380 --> 01:26:20.060]   you have a sphere that is tangent to the surface
[01:26:20.060 --> 01:26:22.660]   of the object in at least three points.
[01:26:22.660 --> 01:26:34.860]   Yeah, and so essentially, you can get these kind of things.
[01:26:34.860 --> 01:26:38.980]   And so that's kind of the definition of us.
[01:26:38.980 --> 01:26:42.380]   Like the skeleton would look like this here,
[01:26:42.380 --> 01:26:44.220]   the ones with the medial axis transform, and so on,
[01:26:44.220 --> 01:26:45.700]   that you obtain with those concepts,
[01:26:45.700 --> 01:26:48.100]   with the maximal circles.
[01:26:48.100 --> 01:26:51.540]   This would be the finned, what is left
[01:26:51.540 --> 01:26:54.180]   after sequential finning.
[01:26:54.180 --> 01:26:57.220]   So they're very related, but there's
[01:26:57.220 --> 01:26:58.100]   a little bit of a difference.
[01:26:58.100 --> 01:27:01.740]   So how would you qualify the difference between the two?
[01:27:01.740 --> 01:27:09.340]   Between the skeletons, which are related to the medial axis
[01:27:09.340 --> 01:27:11.460]   transform, can be computed through them,
[01:27:11.460 --> 01:27:14.380]   and then the finned structures here.
[01:27:14.380 --> 01:27:22.140]   So how would you describe the difference or so?
[01:27:22.140 --> 01:27:39.900]   Yes, so essentially, the way they differ,
[01:27:39.900 --> 01:27:44.780]   it's mostly where also these guys are kind of unstable,
[01:27:44.780 --> 01:27:45.340]   in a sense.
[01:27:45.340 --> 01:27:50.740]   If you could actually slightly change the surface here,
[01:27:50.740 --> 01:27:54.380]   now it's like this, and then you change it a little bit in shape,
[01:27:54.380 --> 01:27:57.300]   and suddenly the skeleton would look completely different.
[01:27:57.300 --> 01:27:59.860]   But the stable part of the skeleton
[01:27:59.860 --> 01:28:03.900]   is kind of what you also see back in the fin structure,
[01:28:03.900 --> 01:28:04.300]   typically.
[01:28:04.300 --> 01:28:08.300]   So the common part between the two, or this thing here--
[01:28:08.300 --> 01:28:11.540]   so if you have strong edges, for example, like this here,
[01:28:11.540 --> 01:28:14.020]   then you have here this whole shape,
[01:28:14.020 --> 01:28:16.100]   then it's kind of the same, essentially.
[01:28:16.100 --> 01:28:20.060]   That's because it's also very stable.
[01:28:20.060 --> 01:28:25.740]   The circle in this example here, you fit the circle,
[01:28:25.740 --> 01:28:27.660]   and it's kind of tangent in multiple points,
[01:28:27.660 --> 01:28:30.100]   and it's kind of-- if you rounded this off a little bit
[01:28:30.100 --> 01:28:32.020]   different, instead of a little bit like this,
[01:28:32.020 --> 01:28:33.620]   you do a little bit more like that,
[01:28:33.620 --> 01:28:37.180]   you would certainly have a completely different skeleton.
[01:28:37.180 --> 01:28:41.620]   While in place where it's sharp, this is stable,
[01:28:41.620 --> 01:28:43.260]   and you see things being the same.
[01:28:43.260 --> 01:28:48.940]   So in a sense, what this fin structure is,
[01:28:48.940 --> 01:28:52.100]   is really it gives you the stable part of the skeleton
[01:28:52.100 --> 01:28:54.940]   that would not be affected by small changes.
[01:28:54.940 --> 01:28:56.220]   When is it unstable?
[01:28:56.220 --> 01:28:59.300]   It's unstable when you have something that has roughly
[01:28:59.300 --> 01:29:02.580]   a circular shape, because then the smallest deviation will
[01:29:02.580 --> 01:29:05.620]   lead to a completely different skeleton.
[01:29:05.620 --> 01:29:06.300]   Does that make sense?
[01:29:06.820 --> 01:29:07.820]   [INAUDIBLE]
[01:29:07.820 --> 01:29:13.460]   The skeletons also have to go essentially kind of all the way
[01:29:13.460 --> 01:29:16.260]   to the surface, right?
[01:29:16.260 --> 01:29:18.780]   And branch out further and further
[01:29:18.780 --> 01:29:20.220]   until they touch the surface.
[01:29:20.220 --> 01:29:20.720]   Yes?
[01:29:20.720 --> 01:29:22.700]   So reconstruction is possible with the skeleton,
[01:29:22.700 --> 01:29:24.700]   but not with the fin?
[01:29:24.700 --> 01:29:25.700]   That's right.
[01:29:25.700 --> 01:29:26.200]   Yeah.
[01:29:26.200 --> 01:29:33.540]   You could still do an approximate reconstruction with this.
[01:29:33.540 --> 01:29:35.700]   Let's say you-- if you would encode the circles here,
[01:29:35.700 --> 01:29:37.940]   you would still be pretty close, and it would be
[01:29:37.940 --> 01:29:40.980]   qualitatively close, but in exact inverse,
[01:29:40.980 --> 01:29:43.940]   you only get with the other one.
[01:29:43.940 --> 01:29:45.020]   And we'll leave it at that.
[01:29:45.020 --> 01:29:49.060]   So here's a kind of segmentation exercise for you
[01:29:49.060 --> 01:29:51.060]   on ice.
[01:29:51.060 --> 01:29:54.300]   Next week, as I said, it will be image features.
[01:29:54.300 --> 01:29:56.140]   You'll start looking--
[01:29:56.140 --> 01:29:58.860]   you look at how to extract edges and how
[01:29:58.860 --> 01:30:02.220]   to extract corners and images and so on.
[01:30:02.220 --> 01:30:05.220]   And this will be Zuria that will do that for you.
[01:30:05.220 --> 01:30:08.500]   I will be at a conference in Paris.
[01:30:08.500 --> 01:30:10.060]   OK, see you in two weeks then.
[01:30:10.060 --> 01:30:13.100]   [APPLAUSE]
[01:30:14.060 --> 01:30:17.100]   [MUSIC PLAYING]
[01:30:17.100 --> 01:30:19.640]   [MUSIC PLAYING]

