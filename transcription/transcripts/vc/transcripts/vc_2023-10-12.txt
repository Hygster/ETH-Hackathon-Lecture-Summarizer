
[00:00:00.000 --> 00:00:03.440]   Okay, so good afternoon.
[00:00:03.440 --> 00:00:07.760]   So today we'll continue with the Fourier transform.
[00:00:07.760 --> 00:00:11.600]   So let me dive in there.
[00:00:11.600 --> 00:00:16.260]   Maybe first, any questions from last week?
[00:00:16.260 --> 00:00:21.520]   Otherwise, we'll go through, sorry, from Tuesday.
[00:00:21.520 --> 00:00:25.160]   So anyways, we'll briefly go over what we saw.
[00:00:25.160 --> 00:00:29.800]   So we saw the definition of the Fourier transform,
[00:00:29.800 --> 00:00:33.000]   in particular in the continuous domain.
[00:00:33.000 --> 00:00:37.720]   So we essentially will transform,
[00:00:37.720 --> 00:00:40.280]   or the Fourier transform will transform
[00:00:40.280 --> 00:00:44.520]   the in our case, the two dimensional image space,
[00:00:44.520 --> 00:00:48.080]   where we directly talk about image locations.
[00:00:48.080 --> 00:00:49.760]   So X and Y represent
[00:00:49.760 --> 00:00:54.200]   specific image locations in a 2D image plane.
[00:00:54.200 --> 00:00:57.720]   And we essentially apply transformation.
[00:00:57.720 --> 00:00:59.760]   In a sense, we eliminate,
[00:00:59.760 --> 00:01:03.200]   we integrate over both the X and the Y,
[00:01:03.200 --> 00:01:06.080]   over the full two dimensional plane.
[00:01:06.080 --> 00:01:15.840]   We multiply the function with basis functions of the Fourier transform.
[00:01:15.840 --> 00:01:20.720]   Those basis functions are essentially in the continuous domain.
[00:01:20.720 --> 00:01:24.520]   They are continuous set of functions that are
[00:01:24.520 --> 00:01:28.800]   parameterized with also two parameters, U and V.
[00:01:28.800 --> 00:01:30.720]   That you see there.
[00:01:30.720 --> 00:01:34.040]   These exponential functions are actually
[00:01:34.040 --> 00:01:37.720]   a combination of a cosine and a sine.
[00:01:37.720 --> 00:01:39.640]   They are complex.
[00:01:39.640 --> 00:01:50.720]   So essentially, we go from an image would be typically real.
[00:01:50.720 --> 00:01:53.040]   We would assume it's a real function,
[00:01:53.040 --> 00:01:57.480]   but we transform it in complex numbers.
[00:01:57.480 --> 00:01:59.360]   And the reason really being that we would need
[00:01:59.360 --> 00:02:01.280]   this linear combination between cosine and
[00:02:01.280 --> 00:02:03.880]   sine to be expressed in kind of with single numbers,
[00:02:03.880 --> 00:02:06.760]   and being able to shift the phase just as
[00:02:06.760 --> 00:02:10.960]   a linear combination in our basis functions and so on.
[00:02:10.960 --> 00:02:14.280]   Here's a few example in a discrete case.
[00:02:14.280 --> 00:02:21.280]   In this case, just four basis functions in every direction in U and V.
[00:02:21.280 --> 00:02:28.800]   Essentially, zero, zero corresponds to putting a one here, zero, there.
[00:02:28.800 --> 00:02:36.240]   Which means that essentially, we get zero and zero.
[00:02:36.240 --> 00:02:37.240]   So we get zero and zero.
[00:02:37.240 --> 00:02:39.760]   So we get just a zero here and a zero there.
[00:02:39.760 --> 00:02:46.920]   So this zero here cosine of essentially zero is of course one.
[00:02:46.920 --> 00:02:51.640]   And here sine of zero is of course zero.
[00:02:51.640 --> 00:02:55.440]   So essentially in that case, we just have a constant flat,
[00:02:55.440 --> 00:02:58.760]   bright picture as our basis function.
[00:02:58.760 --> 00:03:01.160]   And then again, if we multiply that with the image,
[00:03:01.160 --> 00:03:06.400]   we just get the average image intensity up to normalization.
[00:03:06.400 --> 00:03:13.440]   The other ones essentially will be also the product of
[00:03:13.440 --> 00:03:15.480]   those basis functions with the image.
[00:03:15.480 --> 00:03:19.280]   In this case, different signs and cosines and then notice
[00:03:19.280 --> 00:03:22.640]   the orientation that changes depending on things.
[00:03:22.640 --> 00:03:28.480]   So here, this has actually no vertical or is essentially constant
[00:03:28.480 --> 00:03:29.760]   over the vertical direction,
[00:03:29.760 --> 00:03:34.080]   only varies in the horizontal direction and so on.
[00:03:34.080 --> 00:03:41.760]   We looked at a few key properties of the Fourier transform
[00:03:41.760 --> 00:03:43.120]   and of the Fourier transform pair.
[00:03:43.120 --> 00:03:46.000]   So Fourier transforms are linear.
[00:03:46.000 --> 00:03:49.520]   That means that if you have a multiple of a function or
[00:03:49.520 --> 00:03:53.800]   a linear combination of images, for example,
[00:03:53.800 --> 00:03:58.360]   then the output will be the same linear combination of the Fourier
[00:03:58.360 --> 00:04:04.560]   transforms of the original functions or the original images.
[00:04:04.560 --> 00:04:09.600]   There is its invertible, which we mostly conceptually just showed
[00:04:09.600 --> 00:04:15.560]   in the, as these are basis, if we look in the discrete domain,
[00:04:15.560 --> 00:04:16.880]   it's discrete basis.
[00:04:16.880 --> 00:04:19.680]   So we've seen it's both fully defined.
[00:04:19.680 --> 00:04:21.280]   We've seen the definition in a continuous domain,
[00:04:21.280 --> 00:04:26.520]   but essentially there's an equivalent summation in the discrete domain.
[00:04:26.520 --> 00:04:32.200]   There is simpler to understand the invertibility, for example.
[00:04:32.200 --> 00:04:37.400]   A key thing is, key properties, if we have smaller details,
[00:04:37.400 --> 00:04:41.000]   that actually corresponds to a higher frequency and therefore
[00:04:41.000 --> 00:04:44.480]   actually to things being spaced further apart in the Fourier domain.
[00:04:44.480 --> 00:04:48.560]   So it is kind of inverse relationship between the spatial domain
[00:04:48.560 --> 00:04:51.080]   where if we shrink things, we actually increase things,
[00:04:51.080 --> 00:04:55.080]   we space things further out in the frequency domain.
[00:04:55.080 --> 00:04:56.200]   And vice versa.
[00:04:56.200 --> 00:04:59.000]   If we space things out, things vary more slowly,
[00:04:59.000 --> 00:05:06.160]   then we actually are moving things closer together in the frequency domain.
[00:05:06.160 --> 00:05:11.880]   A very important function here, as in many other areas, is the Gaussian.
[00:05:11.880 --> 00:05:18.080]   So double exponential falloff function, the Fourier transform of a Gaussian
[00:05:18.080 --> 00:05:20.400]   is also a Gaussian.
[00:05:20.400 --> 00:05:23.000]   Of course, the property we just described above,
[00:05:23.000 --> 00:05:27.360]   if we make a wider Gaussian in the spatial domain,
[00:05:27.360 --> 00:05:31.320]   that actually goes for a finer Gaussian in the frequency domain.
[00:05:31.320 --> 00:05:34.320]   And vice versa.
[00:05:34.320 --> 00:05:44.080]   We can also compare it to kind of the simple function in the spatial domain here.
[00:05:44.080 --> 00:05:50.440]   One that's constant, up to a certain extent, and then force to zero, exactly to zero.
[00:05:50.440 --> 00:05:53.520]   So it's essentially as compact as possible, so it's constant,
[00:05:53.520 --> 00:05:56.520]   and then it's exactly to zero, so it's as compact as possible.
[00:05:56.520 --> 00:06:02.040]   In the spatial domain, that results in an actually kind of very slowly dying out
[00:06:02.040 --> 00:06:05.040]   function in the frequency domain.
[00:06:05.040 --> 00:06:10.680]   So essentially, if we are very compact here, as a rule of thumb,
[00:06:10.680 --> 00:06:14.720]   if we're very compact here, then we'll kind of very slowly die out there,
[00:06:14.720 --> 00:06:16.080]   and vice versa.
[00:06:16.080 --> 00:06:20.680]   And so in that case, the best trade-off, and we'll look at this when we do
[00:06:20.680 --> 00:06:24.720]   reconstructions, for example, image reconstructions, after sampling and
[00:06:24.720 --> 00:06:28.920]   representing discretely, and then going back to the continuous domain,
[00:06:28.920 --> 00:06:35.720]   this function is kind of useful because it both is reasonably compact.
[00:06:35.720 --> 00:06:39.760]   It goes to zero quite fast with the double exponential.
[00:06:39.760 --> 00:06:44.080]   It's compact in the spatial domain, but it's also compact in the frequency domain.
[00:06:44.080 --> 00:06:46.800]   It's kind of the best trade-off of being compact in both.
[00:06:46.800 --> 00:06:50.280]   Here's a few more.
[00:06:50.280 --> 00:06:54.760]   We started also at the end of last lecture.
[00:06:54.760 --> 00:06:59.800]   Essentially, if we have just a sine function, we'll get essentially,
[00:06:59.800 --> 00:07:06.320]   in the frequency domain, just peaks at both positive and negative
[00:07:06.320 --> 00:07:10.440]   values in the frequency domain.
[00:07:10.440 --> 00:07:15.400]   So really only that frequency is then known zero, the frequency of that sine wave.
[00:07:20.520 --> 00:07:26.160]   We briefly discussed the delta function.
[00:07:26.160 --> 00:07:31.480]   So we'll discuss that more in detail a bit later, but essentially it's a function
[00:07:31.480 --> 00:07:34.760]   that's zero everywhere except at one point.
[00:07:34.760 --> 00:07:41.240]   And to essentially get such a function, and then at that point we'll somehow choose
[00:07:41.240 --> 00:07:45.520]   a value which essentially will be infinity, but chosen such that at least the
[00:07:45.520 --> 00:07:47.280]   integral is well defined.
[00:07:47.280 --> 00:07:49.040]   So we'll discuss that more in detail.
[00:07:50.120 --> 00:07:54.440]   A bit later, but the interesting part of that is it's infinitely compact
[00:07:54.440 --> 00:07:56.280]   in the spatial domain.
[00:07:56.280 --> 00:07:59.560]   And based on what I told you, if we make it very compact in a spatial domain,
[00:07:59.560 --> 00:08:04.960]   that means we kind of expect it to really be spread out in the frequency domain.
[00:08:04.960 --> 00:08:08.200]   And indeed, in the frequency domain, essentially all of the frequencies are
[00:08:08.200 --> 00:08:13.800]   needed, you have essentially a constant in the frequency domain for that.
[00:08:13.800 --> 00:08:15.800]   So all frequencies are actually needed there.
[00:08:17.960 --> 00:08:21.880]   And then the interesting thing is a combination of these delta functions.
[00:08:21.880 --> 00:08:29.120]   So essentially, delta functions repeated at a regular repetition of these delta
[00:08:29.120 --> 00:08:35.800]   functions, both essentially infinite repetition of those delta functions.
[00:08:35.800 --> 00:08:42.160]   The Fourier transform of that is actually the same function.
[00:08:42.160 --> 00:08:50.480]   But it's also an infinite repetition of this delta function in the Fourier domain.
[00:08:50.480 --> 00:08:56.520]   But of course, again, if it's spaced by distance t here,
[00:08:56.520 --> 00:09:00.680]   it's going to be spaced by the instance 1 over t in the frequency domain.
[00:09:00.680 --> 00:09:03.680]   We have frequencies expressed in hertz, for example.
[00:09:03.680 --> 00:09:08.560]   So now we're particularly talking in a single dimension.
[00:09:08.560 --> 00:09:10.240]   These are examples in a single dimension.
[00:09:12.000 --> 00:09:15.320]   So hertz, that cycles per second.
[00:09:15.320 --> 00:09:18.120]   So you have seconds on one side, cycles per second on the other side.
[00:09:18.120 --> 00:09:23.440]   In the image domain, let's say you have centimeters,
[00:09:23.440 --> 00:09:26.280]   then it's 1 over centimeter as a frequency.
[00:09:26.280 --> 00:09:29.440]   So how many periods do you have per centimeter, per unit of length?
[00:09:29.440 --> 00:09:33.280]   And so of course, inversely proportional, so
[00:09:33.280 --> 00:09:38.040]   you move these closer together here, then they would move further apart over there.
[00:09:38.040 --> 00:09:38.600]   And vice versa.
[00:09:38.600 --> 00:09:41.320]   This will be very, very important.
[00:09:41.320 --> 00:09:46.200]   This is how we'll mathematically model sampling.
[00:09:46.200 --> 00:09:50.080]   This function will exactly be able to measure things at exact locations,
[00:09:50.080 --> 00:09:53.520]   and not at all be influenced by things that are not at that location.
[00:09:53.520 --> 00:10:01.160]   We just saw this on the slide before, this one also, the Gaussian.
[00:10:01.160 --> 00:10:06.360]   And then what's interesting is actually the reverse of this one is that if you
[00:10:06.360 --> 00:10:11.720]   have essentially something that's flat, so constant frequency response
[00:10:11.720 --> 00:10:16.440]   for a certain extent, and then goes exactly to zero, so it's as compact as
[00:10:16.440 --> 00:10:22.400]   possible in the frequency domain, which we'll see is actually very useful for
[00:10:22.400 --> 00:10:23.120]   reconstruction.
[00:10:23.120 --> 00:10:29.120]   We see that sadly enough, this gives us a really large extent and
[00:10:29.120 --> 00:10:35.440]   slowly reducing function in the spatial domain.
[00:10:35.440 --> 00:10:40.400]   So that means that if we want to implement this reconstruction filter
[00:10:40.400 --> 00:10:44.720]   in the spatial domain, we'll need a very large convolution.
[00:10:44.720 --> 00:10:49.200]   A convolution with a very large filter to approximate this one.
[00:10:49.200 --> 00:10:51.840]   We'll get to that more in detail.
[00:10:51.840 --> 00:10:57.200]   Okay, so this is the last slide we saw last time.
[00:10:57.200 --> 00:11:00.800]   So this is really an important slide.
[00:11:02.680 --> 00:11:05.040]   It will essentially allow us to understand and model.
[00:11:05.040 --> 00:11:10.200]   It's the base of understanding and modeling two really important effects here.
[00:11:10.200 --> 00:11:16.920]   So the convolution theorem can be used in both directions here.
[00:11:16.920 --> 00:11:22.200]   So the first one is that the Fourier transform of the convolution of two
[00:11:22.200 --> 00:11:24.960]   functions is a product of the Fourier transforms.
[00:11:24.960 --> 00:11:32.360]   So you've seen that you can model filtering operations.
[00:11:32.880 --> 00:11:38.840]   As convolutions of let's say the image with kernels that represent the filter
[00:11:38.840 --> 00:11:41.600]   operation, like a blurring filter or other things.
[00:11:41.600 --> 00:11:48.400]   So that's the operation of convolving an image with a filter, for example.
[00:11:48.400 --> 00:11:52.600]   And you've seen these linear filters, then it's actually just a chain of those,
[00:11:52.600 --> 00:11:54.280]   and so on.
[00:11:54.280 --> 00:11:59.760]   Okay, now if we go, so here of course, the operations,
[00:11:59.760 --> 00:12:01.960]   the convolution operations are in a sense non-local.
[00:12:02.680 --> 00:12:06.200]   Right, a particular pixel doesn't only, in the output image,
[00:12:06.200 --> 00:12:08.920]   doesn't only depend on a single pixel in the input image,
[00:12:08.920 --> 00:12:12.120]   it depends on a whole bunch of pixels, and if you have a very large kernel,
[00:12:12.120 --> 00:12:14.760]   it's actually really many pixels, potentially the whole image.
[00:12:14.760 --> 00:12:18.760]   So you have to recombine pixels from the whole image, take all of them into account
[00:12:18.760 --> 00:12:22.920]   to determine how one pixel looks in the output image after convolution.
[00:12:22.920 --> 00:12:27.640]   What's nice is that in the frequency domain,
[00:12:27.640 --> 00:12:31.480]   whether we see, we have a component per component multiplication.
[00:12:32.040 --> 00:12:39.240]   Okay, so in other words, the effect of a filter is very, very simple
[00:12:39.240 --> 00:12:44.920]   in the frequency domain to represent and to understand in a frequency domain.
[00:12:44.920 --> 00:12:47.000]   It's really just frequency per frequency.
[00:12:47.000 --> 00:12:49.880]   The only question you have to ask is for this frequency, what does my filter do?
[00:12:49.880 --> 00:12:55.720]   Oh, it multiplies it by scaler, essentially, it multiplies it by one, for example.
[00:12:55.720 --> 00:12:57.800]   So it keeps exactly that frequency untouched.
[00:12:58.440 --> 00:13:02.360]   Or this other frequency, oh, that frequency goes by 0.5, you know,
[00:13:02.360 --> 00:13:06.440]   so it gets reduced, everything that's present at that frequency band
[00:13:06.440 --> 00:13:11.080]   will get reduced by, you know, a factor of 0.5, for example.
[00:13:11.080 --> 00:13:13.960]   And then other parts might just go to zero.
[00:13:13.960 --> 00:13:16.520]   So the filter might completely kill some frequencies, okay?
[00:13:16.520 --> 00:13:18.200]   So then those are going to zero.
[00:13:18.200 --> 00:13:21.240]   It means that those frequency, whatever you had in the image,
[00:13:21.240 --> 00:13:25.480]   if you do the Fourier transform, so you get, for example, gay,
[00:13:26.520 --> 00:13:30.280]   if you, if the filter would kill off those frequencies,
[00:13:30.280 --> 00:13:32.760]   then you take that component and multiply it by zero, okay?
[00:13:32.760 --> 00:13:35.080]   So it's really a frequency per frequency.
[00:13:35.080 --> 00:13:41.000]   So filtering in the spatial domain is something that involves, you know,
[00:13:41.000 --> 00:13:42.920]   impact on lots of pixels taking potential,
[00:13:42.920 --> 00:13:45.320]   all the pixels of the image into account to compute every single,
[00:13:45.320 --> 00:13:46.680]   the output on every single pixel.
[00:13:46.680 --> 00:13:50.760]   In the frequency domain, it's really separated frequency per frequency.
[00:13:50.760 --> 00:13:52.360]   You don't have to look at other frequencies.
[00:13:52.360 --> 00:13:54.440]   You only have to look at a single frequency at a time,
[00:13:54.440 --> 00:13:57.160]   and you get essentially a scalar of how much does, you know,
[00:13:57.160 --> 00:14:00.920]   how does this frequency get affected by this, right?
[00:14:00.920 --> 00:14:06.680]   Remember, it's a little bit like in, you know,
[00:14:06.680 --> 00:14:09.080]   on some music things where you're an equalizer
[00:14:09.080 --> 00:14:11.480]   and you can shift frequencies up and down and do stuff like that.
[00:14:11.480 --> 00:14:13.000]   That's really what we're talking about here.
[00:14:13.000 --> 00:14:15.000]   It's, that's what filters do, okay?
[00:14:15.000 --> 00:14:21.400]   The, and then the other side, the other direction,
[00:14:21.400 --> 00:14:24.840]   this is what will allow us to express a sampling,
[00:14:24.840 --> 00:14:29.400]   to model mathematically accurately what sampling is doing, okay?
[00:14:29.400 --> 00:14:31.960]   And again, like in a sense, the sampling, as I said,
[00:14:31.960 --> 00:14:33.960]   it will use essentially this representation,
[00:14:33.960 --> 00:14:39.400]   this, these kind of measuring at discrete locations here, okay?
[00:14:39.400 --> 00:14:45.880]   So we'll model that as a product of this, you know,
[00:14:45.880 --> 00:14:50.040]   function that expresses that is non-zero only at the final set,
[00:14:50.840 --> 00:14:53.320]   no, not final, infinite set of discrete locations,
[00:14:53.320 --> 00:14:57.960]   and we'll multiply that with the original function, okay?
[00:14:57.960 --> 00:15:00.600]   So that's how we'll model sampling is we'll say, okay,
[00:15:00.600 --> 00:15:03.400]   we only care about, you know, the point measurements
[00:15:03.400 --> 00:15:05.000]   at this discrete set of locations,
[00:15:05.000 --> 00:15:06.840]   and we have a function for that,
[00:15:06.840 --> 00:15:09.800]   a function that's zero everywhere except in those discrete locations,
[00:15:09.800 --> 00:15:12.120]   and we'll just multiply that function.
[00:15:12.120 --> 00:15:17.400]   That function will multiply with the original function, okay?
[00:15:17.400 --> 00:15:22.120]   And now we get a new function where we have these special functions
[00:15:22.120 --> 00:15:25.320]   rescaled essentially based on,
[00:15:25.320 --> 00:15:32.760]   rescaled based on the function we're interested in, okay?
[00:15:32.760 --> 00:15:33.960]   Initially they were all the same scale,
[00:15:33.960 --> 00:15:36.360]   and then after we multiply by j,
[00:15:36.360 --> 00:15:39.160]   it will essentially rescale that delta function
[00:15:39.160 --> 00:15:44.200]   so that the integral now corresponds to the function value
[00:15:44.200 --> 00:15:45.880]   at that exact location, okay?
[00:15:47.000 --> 00:15:49.000]   So here in this case it's just a product,
[00:15:49.000 --> 00:15:54.520]   but in the frequency domain it's a convolution now.
[00:15:54.520 --> 00:15:57.640]   So we get a convolution of the original function
[00:15:57.640 --> 00:16:03.800]   with the function, with the Fourier transform of this function,
[00:16:03.800 --> 00:16:05.240]   of our sampling function.
[00:16:05.240 --> 00:16:09.560]   Now we saw before this actually also a very simple function, okay?
[00:16:09.560 --> 00:16:11.720]   So we get these peaks that will be convolved
[00:16:11.720 --> 00:16:14.440]   with the original spectrum of our function, okay?
[00:16:15.720 --> 00:16:18.840]   We'll explain this in a lot more detail in the next few slides, okay?
[00:16:18.840 --> 00:16:23.480]   But essentially here we have something that explains us,
[00:16:23.480 --> 00:16:25.960]   that will show us what happens in the frequency domain
[00:16:25.960 --> 00:16:29.960]   given our modeling or functions.
[00:16:29.960 --> 00:16:32.040]   So we have a way to model in the spatial domain
[00:16:32.040 --> 00:16:33.080]   the sampling process.
[00:16:33.080 --> 00:16:37.560]   In particular we have a way to go from a continuous function
[00:16:37.560 --> 00:16:40.200]   in a mathematically accurate way,
[00:16:40.200 --> 00:16:42.760]   go from a continuous representation, a continuous function,
[00:16:43.320 --> 00:16:47.320]   to now something that only has measurements at discrete locations, okay?
[00:16:47.320 --> 00:16:48.840]   That's the key part here.
[00:16:48.840 --> 00:16:51.320]   And then we say, okay, if we model things this way,
[00:16:51.320 --> 00:16:53.000]   and this is a correct way to model it,
[00:16:53.000 --> 00:16:56.120]   then we can immediately understand what happens
[00:16:56.120 --> 00:16:59.000]   in the frequency domain thanks to this theorem here, okay?
[00:16:59.000 --> 00:17:00.440]   And we'll see and then we'll understand,
[00:17:00.440 --> 00:17:02.520]   that's where essentially when a few slides
[00:17:02.520 --> 00:17:05.000]   we'll understand how aliasing comes about
[00:17:05.000 --> 00:17:07.880]   and what we can do about it and really understand that phenomenon.
[00:17:07.880 --> 00:17:09.500]   Okay.
[00:17:10.600 --> 00:17:13.960]   So to go from the continuous world to the discrete world,
[00:17:13.960 --> 00:17:17.720]   so from function to vector in one dimension,
[00:17:17.720 --> 00:17:22.440]   or we'll see also in two dimension in examples in a second,
[00:17:22.440 --> 00:17:26.760]   we take those samples typically on a regular grid,
[00:17:26.760 --> 00:17:30.200]   so we just measure the function at discrete locations,
[00:17:30.200 --> 00:17:33.320]   as we said before, and get something like this, okay?
[00:17:33.320 --> 00:17:35.400]   In 2D we get something like this, right?
[00:17:35.400 --> 00:17:38.840]   2D function and we then get discrete samples.
[00:17:39.000 --> 00:17:45.400]   So we start from a continuous function,
[00:17:45.400 --> 00:17:54.360]   and we'd like to be able to essentially approximate these integrals
[00:17:54.360 --> 00:18:02.040]   in a sensible way because for the Fourier transform and so on,
[00:18:02.040 --> 00:18:03.960]   we'll need to be able to do integrals and so on.
[00:18:05.880 --> 00:18:08.840]   So this will lead us to the delta function.
[00:18:08.840 --> 00:18:12.840]   So that's essentially a function like this,
[00:18:12.840 --> 00:18:18.360]   and so the sampling function will just be a repetition of these delta functions
[00:18:18.360 --> 00:18:28.920]   that are shifted to a particular location and then essentially our xy, our original function.
[00:18:32.760 --> 00:18:37.400]   And because these shifted delta functions,
[00:18:37.400 --> 00:18:41.640]   so this is essentially the representation of I have my function,
[00:18:41.640 --> 00:18:45.000]   I shift my delta function, so my function at center of zero,
[00:18:45.000 --> 00:18:48.440]   I shift it to a particular location and that's the place where I measure.
[00:18:48.440 --> 00:18:51.320]   That's the discrete integer location, that's this function,
[00:18:51.320 --> 00:18:56.520]   and then that function that's now the shifted peak function
[00:18:56.520 --> 00:19:02.440]   will multiply it at that location, will multiply it with the function,
[00:19:03.000 --> 00:19:05.320]   so we essentially just read out this value here,
[00:19:05.320 --> 00:19:13.560]   and then we'll sum that up over all locations, from minus infinity to plus infinity,
[00:19:13.560 --> 00:19:18.120]   because this function is always the same one, it's always f of xy,
[00:19:18.120 --> 00:19:23.480]   this is the one that varies over the summation, this function we can move out,
[00:19:23.480 --> 00:19:26.840]   and we really have now these two functions, the original function,
[00:19:26.840 --> 00:19:29.640]   and then here this repetition of all these peaks.
[00:19:31.640 --> 00:19:35.480]   But if we want to be able to do a proper Fourier transform,
[00:19:35.480 --> 00:19:38.520]   we'll need those peaks to be able to go properly for an integral,
[00:19:38.520 --> 00:19:45.640]   that's what's written up there, because our Fourier transform is expressed as a double integral,
[00:19:45.640 --> 00:19:49.560]   so we need to have a function that we can properly, that will integrate properly.
[00:19:49.560 --> 00:19:54.600]   If you just have something that's a finite, that's zero everywhere,
[00:19:54.600 --> 00:20:00.520]   and then a finite, let's say, one value at a location, at the sampling location,
[00:20:00.520 --> 00:20:05.240]   then we have a problem, because that's a function with zero surface,
[00:20:05.240 --> 00:20:07.320]   so it will integrate to zero, essentially.
[00:20:07.320 --> 00:20:12.520]   So the simple function at zero everywhere, and then one at the particular location of interest,
[00:20:12.520 --> 00:20:15.800]   that function is not going to work, because it integrates to zero.
[00:20:15.800 --> 00:20:20.680]   So that's why we'll define something as a limit,
[00:20:20.680 --> 00:20:24.840]   so the key thing we want is that our integral is one,
[00:20:26.600 --> 00:20:31.800]   but it also needs to be infinitely thin, but we'll take it as a limit of essentially a function
[00:20:31.800 --> 00:20:36.920]   like this here, that's at a particular height, and then the width is essentially,
[00:20:36.920 --> 00:20:44.360]   from its start, minus one over two h, and it goes to one over two h, so the width is actually
[00:20:44.360 --> 00:20:49.560]   one over h, and the height is h, and therefore the integral is just one.
[00:20:51.160 --> 00:20:56.920]   And of course we can change h to make h higher and then the width smaller,
[00:20:56.920 --> 00:21:02.680]   and if essentially we go in the limit so that this has no extent anymore,
[00:21:02.680 --> 00:21:06.440]   so that it's really zero everywhere except at a particular given location,
[00:21:06.440 --> 00:21:15.240]   for the delta function except at zero, then essentially we have a function that now,
[00:21:15.240 --> 00:21:20.760]   in the limit also has an integral of one, but that has an infinitely small extent.
[00:21:21.640 --> 00:21:27.160]   Width, therefore it's also infinitely high, but it's infinitely high in a controlled fashion,
[00:21:27.160 --> 00:21:31.400]   it's infinitely high in a sense that when you do the integral it will give you exactly one,
[00:21:31.400 --> 00:21:36.360]   because that's the limit here of this function, h times one over h.
[00:21:36.360 --> 00:21:41.560]   Okay, does that make sense to everyone?
[00:21:41.560 --> 00:21:44.680]   Any questions?
[00:21:46.440 --> 00:21:50.760]   Okay, so this is kind of important, at least at a conceptual level, right?
[00:21:50.760 --> 00:21:54.120]   So you need to understand that, you're not going to have to derive that particularly.
[00:21:54.120 --> 00:22:02.920]   Okay, so we get back to this model, right? Now it's actually something we can do an integral from,
[00:22:02.920 --> 00:22:10.040]   so we can actually do the Fourier transform of this thing. In particular we can do the Fourier
[00:22:10.040 --> 00:22:17.240]   transform of this thing, which is the combination of the product, it speaks at all the locations of
[00:22:17.240 --> 00:22:22.440]   interest, all the sampling locations, and then multiplied with the function. So with a product
[00:22:22.440 --> 00:22:27.960]   of two functions of which we want to take the Fourier transform, we now apply our convolution
[00:22:27.960 --> 00:22:33.400]   theorem, which separates the function here, that's just the Fourier transform of that function,
[00:22:33.400 --> 00:22:39.480]   that's easy, and then the Fourier transform of this thing here. Okay, and because we've defined
[00:22:39.480 --> 00:22:43.480]   the delta function to be something we can actually integrate over properly and so on,
[00:22:43.480 --> 00:22:50.680]   this will actually work, and I will spare you the derivation, but essentially, as we've seen before,
[00:22:50.680 --> 00:22:58.520]   here, where was it, here, that if you actually do all the math you will essentially figure out
[00:22:58.520 --> 00:23:04.280]   that this is the output of it, right? We're not deriving that here, but this is something that
[00:23:04.280 --> 00:23:10.760]   you can assume, that if you do the math properly and we know, we just checked that it was something
[00:23:10.760 --> 00:23:17.000]   we would be able to actually pass through the integral, which was this integral here, right?
[00:23:17.000 --> 00:23:19.880]   That this would actually yield a meaningful result and not zeros.
[00:23:22.600 --> 00:23:27.880]   Then we get that function over there, t, one over t, and so,
[00:23:27.880 --> 00:23:40.440]   okay, so, sorry, one more, okay, so this will make sense, and so essentially,
[00:23:40.440 --> 00:23:47.800]   as we take this Fourier transform, the Fourier transform of this was also this peak,
[00:23:48.680 --> 00:23:54.840]   and then if you convolve a peak, remember what did I tell you? The convolution
[00:23:54.840 --> 00:24:01.080]   is essentially, you know, actually, does anybody remember what did I say the convolution was?
[00:24:01.080 --> 00:24:06.440]   We had these two things, convolution and correlation. Does anybody remember what?
[00:24:06.440 --> 00:24:13.000]   No, I meant like, before we discussed free space,
[00:24:15.160 --> 00:24:20.360]   there were essentially two effects. There's correlation is one thing and convolution was the other thing.
[00:24:20.360 --> 00:24:33.720]   Exactly, so I called it a point spread function, but essentially, it's exactly as you said,
[00:24:33.720 --> 00:24:39.000]   is that you have a value in one location and you kind of distribute it. The kernel describes
[00:24:39.000 --> 00:24:43.960]   how you take that value and how you distribute it, how you spread it out over the neighboring pixels,
[00:24:43.960 --> 00:24:46.840]   right? If you remember that, that was the concept there.
[00:24:46.840 --> 00:24:54.280]   This is essentially a concept from one pixel in the input image. You spread it to many pixels in
[00:24:54.280 --> 00:24:59.240]   the output image, which is not the way that computers typically are being used. Typically,
[00:24:59.240 --> 00:25:05.560]   you use, it's not the other way around, you say, okay, I want to write the output for this function,
[00:25:05.560 --> 00:25:11.720]   I want to compute the output value for this function, how do I compute it? Then we ended up
[00:25:11.720 --> 00:25:16.440]   reversing the kernel and essentially picking all the right pixels and so on to do that. But
[00:25:16.440 --> 00:25:21.240]   conceptually, and that's what I want you to remember, so it seems a lot of you have not
[00:25:21.240 --> 00:25:27.160]   remembered it, so you have time. The exam is not now, but do remember it by the time you get to
[00:25:27.160 --> 00:25:33.240]   the exam. It's this kind of spread, from a central pixel kind of deciding how you spread things out.
[00:25:33.240 --> 00:25:39.800]   That's a convolution. Again, as we said, in convolutional neural nets and other things,
[00:25:39.800 --> 00:25:45.320]   they actually mean correlations, so it's all a bit confusing. But the key is to really remember
[00:25:45.320 --> 00:25:51.320]   those two concepts. Here, for example, you can now, if you remember that, that is, I have a
[00:25:51.320 --> 00:25:56.920]   central pixel and I decide how that pixel gets distributed to the rest. Well, we have actually
[00:25:56.920 --> 00:26:03.160]   this very nice centralized function, which is a peak, this infinite peak. And so if you do the
[00:26:03.160 --> 00:26:08.520]   convolution of that peak, we're not doing convolution in the continuous domain, right? So we
[00:26:09.000 --> 00:26:15.320]   when we learn it, we learn it in the discrete domain. Here we do it in the continuous domain,
[00:26:15.320 --> 00:26:22.280]   but essentially from a single peak, here, I mean a single peak actually, many peaks,
[00:26:22.280 --> 00:26:29.560]   but for each peak, what we'll do is we take that peak, this infinitely high peak, but with integral
[00:26:29.560 --> 00:26:34.520]   one, and we decide how we distribute it. And how do we distribute it? So the convolution is how do
[00:26:34.520 --> 00:26:39.720]   we distribute it? Well, we distribute it according to this function here. This function is what?
[00:26:39.720 --> 00:26:44.280]   What is the Fourier transform of our signal, of our function, the function we're interested in,
[00:26:44.280 --> 00:26:50.280]   our image, for example, right? So it's a Fourier transform of our function. So when we sample it,
[00:26:50.280 --> 00:26:57.320]   when, so this was our model for sampling, right? So when we sample it, what we do is we normally
[00:26:57.320 --> 00:27:05.720]   have the function itself, but we'll actually build, we'll, you know, add the one peak. So remember
[00:27:05.720 --> 00:27:14.360]   the function here, right? It's in this space that we'll take all these peaks, and for each peak,
[00:27:14.360 --> 00:27:20.040]   we'll replace the peak with this, the Fourier transform of our function. And the next peak over,
[00:27:20.040 --> 00:27:26.440]   at one over t further, we again copy that thing. Okay? So actually, I have it on slide, so I'll show
[00:27:26.440 --> 00:27:35.560]   you in a second here. Okay, so it looks like this. We have our signal. You always, so this is one
[00:27:35.560 --> 00:27:42.920]   of these signals for simplicity of illustration. We have the spatial domain here. We have the
[00:27:42.920 --> 00:27:48.920]   frequency domain there. And so you can go from one to the other through the Fourier transform,
[00:27:48.920 --> 00:27:56.920]   or inverse Fourier transform. And so we now model sampling simply by multiplying this function
[00:27:56.920 --> 00:28:03.720]   with this function here. These are all Dirac, our delta functions. So, you know, which
[00:28:03.720 --> 00:28:07.400]   illustrates this little arrow here. That's actually to mean that it's a delta function,
[00:28:07.400 --> 00:28:13.880]   and not just something that goes to that value. Okay, so this is, but they rescale delta functions.
[00:28:13.880 --> 00:28:20.360]   They rescale by, you know, the local value of the function. So that's what we get here. Okay? And
[00:28:20.360 --> 00:28:25.720]   then, of course, ideally, we'd also be able to do a reconstruction and reconstruct the original
[00:28:25.720 --> 00:28:33.240]   signal. Okay? Now, so we've seen sometimes we get challenges, we get issues aliasing, and so on.
[00:28:33.240 --> 00:28:37.800]   So like, we'd like to understand a little bit better. So let's look at the frequency domain.
[00:28:37.800 --> 00:28:41.640]   Okay, so let's say we have a signal here. We can do the Fourier transform. We get some kind of
[00:28:41.640 --> 00:28:48.920]   spectrum. And as you've seen in the pictures that we showed of this tiger and this, no, was it
[00:28:48.920 --> 00:28:57.080]   leopard, and I think zebra, right? Essentially, most of the natural images have kind of a lot
[00:28:57.080 --> 00:29:01.960]   of low frequency, and then less and less high frequency. So typically, you get kind of a blob
[00:29:01.960 --> 00:29:08.600]   in general. Okay, so that's why here it's illustrated as a blob of a certain, let's say in this case,
[00:29:08.600 --> 00:29:14.040]   of a certain finite extent. So it has some frequency content, it's lower and lower, and at some point
[00:29:14.040 --> 00:29:20.520]   it's zero. Okay? So it doesn't essentially, beyond this point and this point, it's essentially zero.
[00:29:20.520 --> 00:29:29.640]   Okay? So now, here we simply multiply it. Here we convolve. So convolving is really, at every peak,
[00:29:29.640 --> 00:29:35.320]   we just place a copy. So, right, the peak is the, we distribute the peak, so it's like placing a copy
[00:29:35.320 --> 00:29:40.760]   of the original spectrum there. Okay? So convolving this with this here, just making a bunch of copies.
[00:29:40.760 --> 00:29:46.920]   So it's copy and shift. That's what we do. We copy and shift, and essentially, it depends now on this
[00:29:46.920 --> 00:29:53.000]   distance here, if that copy and shift will overlap or not. Okay? It depends on how wide is my blob,
[00:29:53.000 --> 00:29:59.960]   and on how far apart are the peaks. That depends if they actually overlap or not. In this case,
[00:29:59.960 --> 00:30:06.840]   luckily for us, they just nicely fit next to each other. Okay? So if they nicely fit next to each
[00:30:06.840 --> 00:30:12.680]   other, it means that if we can somehow, if we take this function now, this is our discrete, so this
[00:30:12.680 --> 00:30:18.520]   is the Fourier transform of this function, right? Of our discrete function. This is now a discrete
[00:30:18.520 --> 00:30:24.440]   function. It just has function values at discrete locations. Right? So this is our sample signal.
[00:30:24.440 --> 00:30:28.600]   This is now a mathematical representation, a bit complicated one, but it's a mathematical
[00:30:28.600 --> 00:30:35.240]   representation of, you know, essentially just a sample, a discretely sampled function.
[00:30:35.240 --> 00:30:41.080]   Okay? That's the spectrum that we have for it. That's actually a continuous thing, interestingly
[00:30:41.080 --> 00:30:47.880]   enough. Right? This is continuous. So it doesn't only have values at discrete locations. It's a
[00:30:47.880 --> 00:30:57.000]   continuous spectrum. Now, the concept of reconstructing the signal is actually quite easy,
[00:30:57.960 --> 00:31:03.800]   in a sense. How are we reconstructing? How could we reconstruct this? Like, what operations could
[00:31:03.800 --> 00:31:11.000]   we carry out to reconstruct from this here, from this signal to get back to the original function?
[00:31:11.000 --> 00:31:18.280]   And think in the, you know, so here you could kind of try to fit a function through. We've
[00:31:18.280 --> 00:31:22.360]   actually seen already a little bit of this, of these reconstruction filters. How you could do
[00:31:22.360 --> 00:31:27.000]   that? Take the closest value, for example, and so on, right? Or things like this. But if you think
[00:31:27.000 --> 00:31:41.160]   in a frequency domain, how could you kind of do this? Okay, so essentially we would want to pick,
[00:31:41.160 --> 00:31:44.920]   let's say, the one in the middle there, the original one, right? And get rid of the other ones.
[00:31:44.920 --> 00:31:52.680]   That's correct, but how do we do this? Any idea? A mask, yes, but a mask in a frequency domain.
[00:31:54.360 --> 00:32:05.080]   So that's a low pass filter, yes, exactly. So it's essentially a filter. It's a filter that we
[00:32:05.080 --> 00:32:11.400]   would like to preserve the frequencies in this range here. Right? So we want essentially all of
[00:32:11.400 --> 00:32:16.120]   these frequencies up there. We want to exactly preserve those. We don't want to, you know,
[00:32:16.120 --> 00:32:19.880]   like make them stronger or weaker. We want to exactly preserve those. And everything outside
[00:32:19.880 --> 00:32:28.520]   went to get to zero. If we go back to our pairs, okay? It's kind of like we want this thing here,
[00:32:28.520 --> 00:32:33.000]   right? In a sense, like conceptually, if we take, if we have this, that's exactly what we want.
[00:32:33.000 --> 00:32:41.480]   Filtering is a product in the frequency space. So we multiply with one here, and then outside of
[00:32:41.480 --> 00:32:46.920]   the blob, like outside of the blob, we multiply exactly with zero. So that's what we could do.
[00:32:47.800 --> 00:32:51.000]   Now, as you remember, this is actually a convolution with something of this type
[00:32:51.000 --> 00:32:54.200]   in the spatial domain. So it's kind of a convolution with really large filters,
[00:32:54.200 --> 00:32:59.800]   so it's not great. But this would be actually theoretically, you know,
[00:32:59.800 --> 00:33:08.680]   would allow us a perfect reconstruction. Okay. Oops. Here. Okay. So that works, yes?
[00:33:08.680 --> 00:33:22.200]   [ Inaudible ]
[00:33:22.200 --> 00:33:25.480]   Uh-huh. This here. Yeah.
[00:33:25.480 --> 00:33:31.560]   [ Inaudible ]
[00:33:31.560 --> 00:33:40.280]   Oh, sorry. This is zero, right? So low pass is limited from both sides.
[00:33:40.280 --> 00:33:48.120]   Okay. So high pass would actually be keeping this and keeping this. That's what a high pass is,
[00:33:48.120 --> 00:33:53.240]   actually, in this case. Okay. So it'd be kind of something like this here that preserves everything
[00:33:53.240 --> 00:33:57.160]   going forward here and everything going forward that way. That's what a high pass would be.
[00:33:57.160 --> 00:34:02.840]   Okay. So for everyone to be clear, this is zero. So low is around here, and high is, you know,
[00:34:02.840 --> 00:34:07.720]   around the other side, on the extremes, on both extremes, actually. Okay. That's good. You know,
[00:34:07.720 --> 00:34:11.720]   ask questions. I'm sure there's others that were thinking exactly the same way and didn't dare to
[00:34:11.720 --> 00:34:22.200]   ask the question. Okay. So now we get to the interesting part. I mean, I hope you found
[00:34:22.200 --> 00:34:26.040]   what was before also interesting. But now we essentially get to actually understand,
[00:34:26.680 --> 00:34:32.360]   you know, what ailiasing is. Okay. So essentially, same thing here. But now we decided to, you
[00:34:32.360 --> 00:34:39.800]   know, spend a few more bits, let's bits, you know, a few less bits here and sample less frequently.
[00:34:39.800 --> 00:34:46.840]   Okay. So we sample our signal less frequently. You see here, we have less samples. What does
[00:34:46.840 --> 00:34:53.480]   that mean in the frequency domain? Well, it means that there we, you know, if we're spacing things
[00:34:53.480 --> 00:35:00.440]   out in the spatial domain, it means we're squeezing things together in the frequency domain. So now,
[00:35:00.440 --> 00:35:05.880]   as we make for each of those, we make a copy of the spectrum, we end up with this here. Okay.
[00:35:05.880 --> 00:35:09.880]   And actually, we don't end up with this. We actually end up with, you know, like essentially
[00:35:09.880 --> 00:35:14.760]   that here, those two just get summed together. They, you know, they just get added together.
[00:35:14.760 --> 00:35:19.240]   And so you don't know anymore what came from what. And so you get a function that, you know,
[00:35:19.240 --> 00:35:23.880]   instead of nicely being like this, go to zero and then go to the next one. Now it's essentially
[00:35:23.880 --> 00:35:29.480]   doing something like this. And a big part is essentially overlapping. Okay. So now if you do
[00:35:29.480 --> 00:35:34.680]   this perfect cutout even, you know, you get something like this here where you see that this
[00:35:34.680 --> 00:35:42.040]   is really different from the original. Okay. It's essentially these other frequencies that are now
[00:35:42.040 --> 00:35:48.840]   being folded in and overlapping with our original frequencies. And we get a mix of both. And
[00:35:49.160 --> 00:35:54.360]   you know, there's no way to separate those anymore. Okay. Once it's like this, it's too late.
[00:35:54.360 --> 00:36:03.880]   Okay. So that's essentially the phenomenon of aliasing. Right. So this is the issue that we saw
[00:36:03.880 --> 00:36:08.760]   a few lectures ago where we had these strange artifacts showing up and so on. And essentially
[00:36:08.760 --> 00:36:13.720]   these high frequency pattern that suddenly showed up as these big kind of blobs spread over the
[00:36:13.720 --> 00:36:26.040]   image and so on. That's essentially what we have here. Okay. So what it means is that if we want to
[00:36:26.040 --> 00:36:34.120]   to work with, you know, on real signals, the upper line is the original signal
[00:36:36.280 --> 00:36:44.120]   which is high frequency. Before we sample it, we actually want to make sure that we band limit it.
[00:36:44.120 --> 00:36:49.160]   So it's important that before you sample, because as soon as you sample,
[00:36:49.160 --> 00:36:55.080]   you know, sampling corresponds to doing that. Okay. That's what sampling is. Right. So that's
[00:36:55.080 --> 00:36:59.320]   sampling. So once you put those two together, you get this, then it's too late. You can try to
[00:36:59.320 --> 00:37:04.680]   filter whatever you want. You can have a perfect filter. It will not work. It's too late. So,
[00:37:04.680 --> 00:37:09.880]   so the key is in the proper filter, proper sampling, you actually, and this is what I
[00:37:09.880 --> 00:37:18.600]   mean, is before you sample, you need to first apply low pass filter on, you need to apply
[00:37:18.600 --> 00:37:25.560]   low pass filter so that you avoid these high frequencies. Because if you have high frequencies,
[00:37:25.560 --> 00:37:29.960]   they'll get folded over on your low frequencies. And then you don't know actually if this was a
[00:37:29.960 --> 00:37:33.960]   low frequency or if there's a high frequency that got folded over your low frequency. You cannot
[00:37:33.960 --> 00:37:40.120]   separate this anymore. Okay. So essentially, first apply low pass filter so that now you have band
[00:37:40.120 --> 00:37:51.240]   limited. So essentially, as we saw in the first lecture, you essentially, you know, you know,
[00:37:51.240 --> 00:37:58.600]   based on your sampling, or actually, you know, you can also see here, it's kind of easy. Based on
[00:37:58.600 --> 00:38:05.240]   your sampling, you know how far your peaks are going to be apart. And so even with a perfect
[00:38:05.240 --> 00:38:12.840]   filter, you know, to the, which is the tightest you can make it, you kind of need those peaks to be
[00:38:12.840 --> 00:38:18.360]   a factor of two apart from the, this is your, the width of your signal, the bandwidth of your signal,
[00:38:18.360 --> 00:38:25.080]   up to this frequency. You need the next peak to be at least twice as far. Okay. Maybe you remember
[00:38:25.080 --> 00:38:31.720]   in the first lecture or second lecture, we had this Nyquist sampling theorem that said that you
[00:38:31.720 --> 00:38:40.440]   have to have your sampling frequency be at least twice the frequency of your signal. Right. Anybody
[00:38:40.440 --> 00:38:46.840]   remember that? Yeah. Okay. So now you see why two is similar is those peaks, if they're two apart,
[00:38:46.840 --> 00:38:51.560]   a factor two apart, then we can exactly place copies next to each other without them overlapping.
[00:38:51.560 --> 00:38:56.280]   Okay. Now that still implies you need a perfect filter to actually make it work.
[00:38:56.280 --> 00:39:01.160]   So if we don't use a perfect filter, we might want to take a little bit more margin
[00:39:01.160 --> 00:39:06.920]   to allow us to go from, you know, not distorting the signal, so keeping almost exactly one,
[00:39:06.920 --> 00:39:13.560]   and then have it go down at some extent and be close enough to zero when, when the next copy
[00:39:13.560 --> 00:39:18.360]   kind of shows up. Right. So that you don't have this, this high frequencies kind of coming.
[00:39:20.600 --> 00:39:23.640]   Okay. So this was aliasing. So here if it overlaps, it's too late.
[00:39:23.640 --> 00:39:29.320]   Okay. So essentially we first low pass filter the signal. We low pass filter it so that it's
[00:39:29.320 --> 00:39:34.120]   essentially just the width that will fit between our peaks. Okay. That's what we're talking about.
[00:39:34.120 --> 00:39:41.480]   Then we can sample, then we can safely sample essentially. And then from this, we have the
[00:39:41.480 --> 00:39:47.320]   potential to perfectly reconstruct where of course we're talking about perfectly reconstructing the
[00:39:47.320 --> 00:39:52.920]   low pass signal. Okay. The high, the high pass, we sure way it's gone. Okay. But, you know, if you
[00:39:52.920 --> 00:39:58.600]   look at this image, for example, you know, it's fine to go from this to this. And then as long as
[00:39:58.600 --> 00:40:02.920]   you can reconstruct this, it's kind of okay. So that's essentially what we'll be doing.
[00:40:02.920 --> 00:40:13.000]   So here's a few things about, a few things about filtering and so on. So the message is a free
[00:40:13.000 --> 00:40:18.360]   transform is that high frequencies lead to trouble with sampling. So the solution is to suppress
[00:40:18.360 --> 00:40:23.560]   those high frequencies before sampling. This can be done by multiplying the free transform
[00:40:23.560 --> 00:40:28.200]   of the signal with something that suppresses high frequencies. So low pass filter.
[00:40:28.200 --> 00:40:31.480]   So in other words, convolved with a low pass filter.
[00:40:31.480 --> 00:40:39.640]   A filter whose free transform is a box is bad because the filter kernel has infinite support.
[00:40:39.640 --> 00:40:44.680]   Right. So this would be the perfect filter, except that it's expensive or, you know,
[00:40:44.680 --> 00:40:50.200]   and brings other artifacts. The problem is for starters that the images are not infinite.
[00:40:50.200 --> 00:40:56.040]   And so you're kind of making assumptions about what happens beyond the image, etc., etc.
[00:40:56.040 --> 00:41:03.960]   Common solution is this Gaussian because as we saw, the Gaussian is the one that's most compact on
[00:41:03.960 --> 00:41:13.480]   both sides. And so in that sense, it's very practical for this. So multiplying by the free,
[00:41:13.480 --> 00:41:17.720]   the free transform by a Gaussian is equivalent to convolving the image with a Gaussian, which can
[00:41:17.720 --> 00:41:24.120]   also be done in a good approximation quite efficiently. So here's a little bit of an example
[00:41:24.120 --> 00:41:33.800]   of what happens. We already roughly saw this example before. You have here function to
[00:41:33.800 --> 00:41:40.680]   256 by 256 and then we sub-sample without filtering. And so everything goes well for a while
[00:41:40.680 --> 00:41:48.280]   until we go too far. And this is essentially when we get those two things to overlap. And of course,
[00:41:48.280 --> 00:41:51.880]   you know, then we do the reconstruction and we just consider everything as low frequencies as we
[00:41:51.880 --> 00:41:56.280]   reconstruct. And so essentially we get these things to pop up here, these strange things to pop up.
[00:41:56.280 --> 00:42:01.640]   What you see is here, it's not great because of renormalization, but essentially if you look
[00:42:01.640 --> 00:42:09.240]   at this here, this is the part that has, this is the frequency representation of this. So you see
[00:42:09.240 --> 00:42:15.480]   most of the energies in this little square in the middle. Then we sub-sample and we take the
[00:42:15.480 --> 00:42:21.000]   Fourier transform of this guy. Now what's interesting is we see at the edge these copies of this
[00:42:21.000 --> 00:42:26.200]   showing up here. That's what we see. And here and here and here. So in 2D, of course, it's a two
[00:42:26.200 --> 00:42:33.320]   dimensional repetition. Next one here. But you see that the core signal here, which is this part,
[00:42:33.320 --> 00:42:40.440]   is still nicely separated from the next one. Next thing, and then here in the renormalization,
[00:42:40.440 --> 00:42:45.560]   I think when these slides were made, it just automatically renormalized the image.
[00:42:45.560 --> 00:42:52.200]   This patch and this patch should be just as bright because there's no dark patches anymore and the
[00:42:52.200 --> 00:42:55.880]   image was just renormalized to have the same average intensity. It doesn't look very good.
[00:42:56.360 --> 00:43:02.200]   But essentially, you see that this box, it's kind of still nicely in there. It actually just fits.
[00:43:02.200 --> 00:43:09.560]   But then the next step, that's when it really goes wrong because now you essentially put a full copy
[00:43:09.560 --> 00:43:14.360]   on top of the other copy and they really start overlapping. And no surprise, you start seeing
[00:43:14.360 --> 00:43:18.760]   that essentially the, qualitatively, the image looks completely different now, suddenly, because
[00:43:18.760 --> 00:43:25.800]   you get like this really strong high frequency signal to just be interpreted as a low frequency.
[00:43:26.200 --> 00:43:32.760]   Signal and so it looks completely different at that resolution. Now here's what happens
[00:43:32.760 --> 00:43:41.160]   if you do some smoothing. So in this case, we smooth with a Gaussian with a sigma of one pixel
[00:43:41.160 --> 00:43:50.120]   and we do that in a, every time from one image to the next, we apply that. So for in this image,
[00:43:50.920 --> 00:43:58.760]   before sampling, we will actually blur this image, the 256 by 256, with a Gaussian with a sigma of
[00:43:58.760 --> 00:44:04.840]   one pixel. So that means that a sigma of a Gaussian, I think at one pixel, you're about,
[00:44:04.840 --> 00:44:09.720]   from one, you go to about two thirds and then it still has, you know, like two or three sigma,
[00:44:09.720 --> 00:44:16.120]   you get to something quite small. So maybe you have kind of something significant up to maybe
[00:44:16.760 --> 00:44:20.920]   two pixels for sure and then three pixels, it becomes close to zero. Okay.
[00:44:20.920 --> 00:44:27.000]   And then once we blur the image, which you know, you don't really see that this image was blurred,
[00:44:27.000 --> 00:44:32.600]   but once you blur the image, you then sub-sample. And so again, at this, this image here, we blur,
[00:44:32.600 --> 00:44:39.000]   we blur first and then we sub-sample. And then we blur and we sub-sample, we blur and we sub-sample.
[00:44:39.000 --> 00:44:45.640]   Okay. So it means that we've always been kind of blurring at different locations.
[00:44:45.640 --> 00:44:50.760]   You kind of see what happens here, but so essentially we'll be suppressing
[00:44:50.760 --> 00:44:57.400]   things. And in the end, you know, what you see here is that here it starts being affected. So your
[00:44:57.400 --> 00:45:01.880]   signal is actually in a sense less nice than it was here, maybe, although there's actually already
[00:45:01.880 --> 00:45:07.400]   some effects here. But in particular, once you can't represent the signal anymore, it's been blurred
[00:45:07.400 --> 00:45:11.960]   out by then. Okay. So there's high frequencies that are too much to represent at that resolution,
[00:45:11.960 --> 00:45:17.320]   16 by 16. They're just gone now. Okay. Okay. So and then we'll continue after the break.
[00:45:17.320 --> 00:45:21.080]   Okay. So let us continue.
[00:45:21.080 --> 00:45:30.280]   The, so this was one example. You still see a little bit of effects here, for example, and so on.
[00:45:30.280 --> 00:45:36.440]   Here's if we choose a slightly different Gaussian. So the different, the only difference is
[00:45:36.440 --> 00:45:42.440]   essentially here. Okay. So it's a slightly larger Gaussian. What does that mean? It means that it's
[00:45:42.440 --> 00:45:47.000]   filtering a little bit more aggressively, suppressing a little bit more the high frequencies.
[00:45:47.000 --> 00:45:54.440]   So this should actually, you know, avoid a little bit more artifacts, but of course,
[00:45:54.440 --> 00:45:57.960]   also blur things out a little bit more. So suppress the signal itself also a bit more.
[00:45:57.960 --> 00:46:05.480]   Okay. And that's kind of what you see here. So as you go, less artifacts, but essentially most of
[00:46:05.480 --> 00:46:11.960]   the images blurred out at the end. Right. You can also see here, it's kind of strongly.
[00:46:11.960 --> 00:46:16.680]   So before things get copied on top of each other, it kind of strongly suppresses them. And so
[00:46:16.680 --> 00:46:22.360]   it doesn't overlap, but you've kind of already erased a good part of the signal also. Right.
[00:46:22.360 --> 00:46:28.280]   This was the one before. So here you get most, you know, like you get little of a gap between.
[00:46:28.280 --> 00:46:35.080]   So there's, you use most of what you can represent with the 16 by 16 pixels. Here you've blurred more
[00:46:35.080 --> 00:46:40.120]   the signal away. You've kind of, you were over-protective like this. Essentially most of the stuff here is
[00:46:40.120 --> 00:46:47.400]   kind of erased. Okay. Just an example of what practically you would do with Gaussians. Okay.
[00:46:47.400 --> 00:46:55.960]   So now we get here to revisit the Nyquist sampling theorem. By now, ideally, this should kind of
[00:46:55.960 --> 00:47:01.880]   be relatively trivial. It should be obvious. You know, it's just double the space so that, you know,
[00:47:01.880 --> 00:47:08.440]   two copies just touch each other, but you can still keep them separate. That's this, the fact
[00:47:08.440 --> 00:47:15.000]   that the sampling frequency must be at least twice. So larger or equal to twice the highest
[00:47:15.000 --> 00:47:20.120]   frequency in the signal. Okay. The highest frequency in the signal is the extent up to where you have
[00:47:20.120 --> 00:47:30.440]   non-zero, you know, frequencies or non-zero presence, non-zero values for your frequency
[00:47:30.440 --> 00:47:37.160]   representation. So in other words, you Fourier transform of your original function. Okay. Or
[00:47:37.160 --> 00:47:45.720]   of the function after you prepared it. For example, as we showed here, after you prepared it, so after
[00:47:45.720 --> 00:47:52.120]   you low-pass filtered it, so that now, you know, like you need to ensure that that frequency is
[00:47:52.120 --> 00:47:57.080]   lower than twice this frequency, lower than half of this frequency.
[00:47:57.080 --> 00:48:09.800]   Oops. Okay. And so if this is not the case, then you need to apply ideally a low-pass filter.
[00:48:10.440 --> 00:48:16.840]   If not, you are likely to face, or actually if this is not satisfied, then you will face
[00:48:16.840 --> 00:48:23.960]   aliasing, essentially. Then that higher frequency will be somehow mapped to some, added up to some
[00:48:23.960 --> 00:48:34.360]   lower frequencies. Okay. This is an example. At some point, this was captured on live TV.
[00:48:34.360 --> 00:48:39.320]   So now the question is what happened here. Does anybody have a hypothesis?
[00:48:39.880 --> 00:48:53.400]   No. It's actually not a compression here.
[00:48:53.400 --> 00:49:03.560]   Okay. So who remembers how color cameras typically work? How did we sample for color?
[00:49:05.880 --> 00:49:09.640]   All right. So we said if we want high quality, we'll have three different sensors and so on,
[00:49:09.640 --> 00:49:12.760]   but in most cases, we actually don't. So we just have a single sensor.
[00:49:12.760 --> 00:49:21.880]   And then we sample color by actually, you know, sampling, you know, instead of for the actual
[00:49:21.880 --> 00:49:26.440]   pixels, we have some pixels very measure red and somewhere you measure green and somewhere you
[00:49:26.440 --> 00:49:32.920]   measure blue, et cetera. But so the sampling frequency is actually lower in the color
[00:49:33.880 --> 00:49:38.360]   than in the grayscale. So the grayscale image looks nice like this. No artifacts here,
[00:49:38.360 --> 00:49:42.520]   but here we have strong artifacts in the colors.
[00:49:42.520 --> 00:49:52.840]   So essentially, we're kind of in that factor of two between the grayscale image, which looks just
[00:49:52.840 --> 00:49:59.800]   fine, and the color image, which, you know, is sampling at only half the frequency.
[00:50:01.080 --> 00:50:06.200]   And so there you kind of get pretty strong aliasing, essentially color aliasing in this case.
[00:50:06.200 --> 00:50:17.320]   Okay. So it's this guy here. Okay. So now, so we've discussed a lot that part of the pipeline,
[00:50:17.320 --> 00:50:26.200]   the first part. By the way, you know, if you're the person, you know, behind the camera
[00:50:27.560 --> 00:50:32.280]   and you see this happening, or, you know, like, you know, like, what can you do?
[00:50:32.280 --> 00:50:42.520]   Yes. Yes, but that will be a little bit awkward.
[00:50:42.520 --> 00:50:47.160]   Anything else that's less drastic that you could do?
[00:50:47.160 --> 00:50:54.200]   Exactly. So you can actually a little bit change the focus, not the zoom, preferably,
[00:50:54.200 --> 00:50:58.440]   but the focus. People will barely notice you would just blur a little bit the image,
[00:50:58.440 --> 00:51:03.560]   but if you do that by factor of two, so that essentially now instead of seeing every pixel,
[00:51:03.560 --> 00:51:08.920]   you know, really sharply, you just have like two pixels kind of you blur to two pixels,
[00:51:08.920 --> 00:51:13.800]   then this would actually disappear. So that's, I don't have the video or so, but that's probably
[00:51:13.800 --> 00:51:18.600]   what a cameraman, you know, or women would quickly have done, essentially,
[00:51:20.200 --> 00:51:28.680]   on in this case here, if they noticed. Okay, so now after I looked at this, so in other words,
[00:51:28.680 --> 00:51:35.480]   again, like, if you actually, if this is in the space, if this is in the continuous domain,
[00:51:35.480 --> 00:51:44.840]   and then you sample here, this operation, this low pass filtering operation, has to happen in
[00:51:44.840 --> 00:51:48.920]   the continuous domain. So for example, in the physical domain, and so you can have the camera
[00:51:48.920 --> 00:51:55.080]   blur the signal. So in other words, the camera, the focus becomes a low pass filter on your,
[00:51:55.080 --> 00:52:01.240]   on your incoming, you know, light, you cannot sample first and then worry about this later,
[00:52:01.240 --> 00:52:04.920]   right? So remember, this is actually really critical. You once you sample is too late.
[00:52:04.920 --> 00:52:12.200]   Of course, you can already be in the digital in the discrete domain. In other words, in the
[00:52:12.200 --> 00:52:17.720]   digital domain. And if you're already there, but now you have a high resolution image, but you have
[00:52:17.720 --> 00:52:23.720]   a low resolution screen, for example, and you need to now sample your image to bring it on the screen,
[00:52:23.720 --> 00:52:29.880]   then it's okay. Then you're in this, in the, in the already in digital representation, and then you
[00:52:29.880 --> 00:52:34.200]   can apply essentially just, you know, digital filters to do the transformation. That's what we
[00:52:34.200 --> 00:52:39.080]   showed before was applying these gaussians, for example, which are discrete gaussians, discrete
[00:52:39.080 --> 00:52:45.000]   low pass filters that will apply and that will do that. So, but if we are, if this is the first time
[00:52:45.000 --> 00:52:53.240]   we sample, so the, if this is the point where we go from continuous from analog to like actually
[00:52:53.240 --> 00:52:59.880]   sample with a sensor, then we have to do something before, which for example is make sure that our
[00:52:59.880 --> 00:53:06.120]   lens is not too good, that our lens is kind of matched to the resolution of our pixels, but doesn't
[00:53:06.120 --> 00:53:11.160]   let through higher frequencies than, you know, what we can actually sample. So actually this is,
[00:53:11.880 --> 00:53:17.640]   there are actually filters in cameras and the lens is actually tuned to typically to the, to the
[00:53:17.640 --> 00:53:23.640]   sensor. There's no point in having a super sharp lens in front of a, you know, a low resolution
[00:53:23.640 --> 00:53:31.320]   sensor, because you're actually going to create more problems than anything else, essentially.
[00:53:31.320 --> 00:53:35.640]   Except if you wanted to do super resolution or things like that, then maybe there is something
[00:53:35.640 --> 00:53:42.200]   to be done there, but okay. So now we'll focus on the second part here. We have a sample signal.
[00:53:42.200 --> 00:53:47.560]   How do we reconstruct now the original signal? Okay. We've seen conceptually we can apply this
[00:53:47.560 --> 00:53:52.840]   perfect kind of reconstruction filter, this box filter, which becomes this very, you know,
[00:53:52.840 --> 00:53:59.160]   this sink in the spatial domain, but that's as we've, as we already briefly discussed, this is
[00:53:59.160 --> 00:54:07.080]   actually not the good way to do it. We'll also throw in some human vision in the middle.
[00:54:07.080 --> 00:54:15.240]   Who can recognize this person? Okay. So many of you can recognize him. Let me, okay. So this
[00:54:15.240 --> 00:54:21.480]   actually also showed up in art. So that person is the same as this person. This might already,
[00:54:21.480 --> 00:54:27.480]   so who recognizes that person? Still the same amount. Okay. Let me do this. Who recognizes
[00:54:27.480 --> 00:54:35.320]   now this person here? Okay. I see a few more hands at least. Okay. So that's what I was expecting.
[00:54:35.320 --> 00:54:43.480]   So of course this, you know, this is Lincoln, but it's actually easier to recognize him this way
[00:54:43.480 --> 00:54:49.880]   than it is to recognize him that way, right? Or not, like, who agrees that this was actually easier?
[00:54:49.880 --> 00:54:56.200]   Right? Okay. So most people. So why is that actually? Any idea?
[00:54:56.200 --> 00:55:12.600]   Yes. So essentially that's correct. And the reason is that essentially here,
[00:55:12.600 --> 00:55:18.200]   what you really have is you actually have thrown in a bunch of high frequencies that really are not,
[00:55:18.200 --> 00:55:22.760]   you know, like should not be there. Right? So this is really each of those edges here is actually
[00:55:22.760 --> 00:55:26.920]   a high frequency. So it's a very poor reconstruction. The reconstruction that throws in a bunch of
[00:55:26.920 --> 00:55:32.760]   high frequencies that really shouldn't be here in the reconstruction. Right? So you have a value
[00:55:32.760 --> 00:55:37.240]   measured at each of those discrete locations. And now you kind of copy those over, but that means
[00:55:37.240 --> 00:55:45.080]   you're actually, you're actually creating very high frequency content here of a very specific type.
[00:55:45.080 --> 00:55:51.480]   And so our brain is like getting confused by all these additional irrelevant high frequency content
[00:55:51.480 --> 00:55:58.200]   here. Okay. So let's look a little bit at a few possible reconstruction filters.
[00:55:58.200 --> 00:56:07.160]   So the first one is, you know, like the square pixel kind of filter. That's the closest.
[00:56:09.640 --> 00:56:15.640]   That's the nearest neighbor. That's essentially this one. Right? So it's simply,
[00:56:15.640 --> 00:56:29.400]   you know, it's essentially just applying for each value. You are copied to all the nearest pixels
[00:56:29.400 --> 00:56:39.000]   you copy over the value. In the Fourier domain, this essentially has all of these lobes here.
[00:56:39.000 --> 00:56:45.320]   Right? So in the Fourier domain, it means that you're now adding all of these high frequencies
[00:56:45.320 --> 00:56:50.760]   at this repeated thing. So that's what you have here. You add all these high frequencies. Those
[00:56:50.760 --> 00:56:55.320]   are not in the original signal, but you kind of add them in the reconstruction process.
[00:56:55.320 --> 00:57:01.880]   So those high frequencies are essentially these additional lobes, artificial lobes. Those actually
[00:57:01.880 --> 00:57:08.280]   shouldn't be there, but you're just adding them in, you know, just by using this nearest neighbor,
[00:57:08.280 --> 00:57:14.200]   essentially copy the value over to all your neighbors. Okay. The next one is by linear
[00:57:14.200 --> 00:57:20.440]   interpolation. Okay. So this was essentially, it's a function that looks like it's maximal
[00:57:20.440 --> 00:57:25.080]   also at the value itself, but then it linearly decreases until, you know, like where you hit
[00:57:25.080 --> 00:57:31.160]   the next pixel. So the first one was like this, right? Until half the pixel on both sides, it would
[00:57:31.160 --> 00:57:37.000]   be constant and then zero. This one is linear from where the pixel is to the next pixel it
[00:57:37.000 --> 00:57:42.200]   linearly degrades. Same in both directions. And so it ends up with this kind of function,
[00:57:42.200 --> 00:57:49.400]   actually, you know, like, so that the, so in two dimensions it's a bit more complicated,
[00:57:49.400 --> 00:57:53.800]   but essentially it ends up with that effect. Okay. In the Fourier domain, it looks like this here,
[00:57:53.800 --> 00:57:59.720]   which is not perfect. You can't see very much here, but essentially we'll see on the next
[00:57:59.720 --> 00:58:05.720]   slide, actually, you may get there. Okay. The first one was just a box, but if we actually
[00:58:05.720 --> 00:58:12.360]   take a box and convolve it with a box, okay, so we convolve a box with a box, then we get
[00:58:12.360 --> 00:58:18.040]   actually this here. If you actually look at this, so this was the original reconstruction filter,
[00:58:18.040 --> 00:58:23.800]   the nearest neighbor, right, from half a pixel to minus half to plus half. So it's really this
[00:58:23.800 --> 00:58:29.800]   constant. If you convolve that with itself, you actually get this function, which interestingly
[00:58:29.800 --> 00:58:36.280]   enough goes, you know, starts from twice as far. So from like the next pixel value, it starts going
[00:58:36.280 --> 00:58:41.720]   up until it's maximal here, and then it decreases from there linearly to the next pixel. So it's
[00:58:41.720 --> 00:58:47.560]   one here, but it's so at this place, you just really have that value. You copy over that value,
[00:58:47.560 --> 00:58:51.080]   but from there it linearly decreases until you get to the next pixel.
[00:58:53.640 --> 00:58:59.320]   So we've seen, so this is, you know, the, by the way, so this graph that you see, right, it's
[00:58:59.320 --> 00:59:05.400]   this, so the blue is the pixel centered here. The red is a convolution with, you know, it's
[00:59:05.400 --> 00:59:12.280]   what you will convolve with, with the same box. And then the yellow area is the area in common,
[00:59:12.280 --> 00:59:17.560]   and that's essentially the overlapping area. So when you multiply, when you convolve at every
[00:59:17.560 --> 00:59:22.760]   value, you kind of overlap, you do the integral, you get, and so the yellow is the integral,
[00:59:22.760 --> 00:59:28.520]   and so that's the, the value, and so you see kind of as the integral grows and shrink,
[00:59:28.520 --> 00:59:32.360]   you get the function to go up and down. Okay, so that's essentially a visualization
[00:59:32.360 --> 00:59:38.680]   of the convolution operation here, with, in the very simple case of two boxes, you know,
[00:59:38.680 --> 00:59:44.040]   one box convolving with another box. Okay, so this is the area under the product of the functions.
[00:59:44.760 --> 00:59:53.400]   Here, the yellow here. Okay, so what did we learn from the convolution theorem?
[00:59:53.400 --> 01:00:01.400]   If we convolve in the spatial domain, it's a product in the frequency domain, right? That was
[01:00:01.400 --> 01:00:05.560]   one of the two sides of the convolution theorem. So in other words, if we take that function,
[01:00:05.560 --> 01:00:12.520]   that decreases, you know, that is this sine function that decreases with one over x, that was
[01:00:12.520 --> 01:00:21.400]   what that function was. If, if we convolve that with itself, then in the frequency domain,
[01:00:21.400 --> 01:00:27.480]   it's a product with itself. Okay, so we get that sine function squared. Okay, so instead of going
[01:00:27.480 --> 01:00:33.800]   down slowly, it now go down, you know, like it ends, it ends up being suppressed, not by one over x,
[01:00:33.800 --> 01:00:40.040]   but one over x squared. Okay, so it goes much faster to zero. Okay, so that's what you kind of see
[01:00:40.040 --> 01:00:44.440]   here. There you still see a few of the extra lobes, although they're smaller, but you still see them.
[01:00:44.440 --> 01:00:50.040]   Here you don't see them anymore, at least not, I think, I can barely see them here also, but
[01:00:50.040 --> 01:00:54.040]   anyway, certainly on this here with, you know, barely any contrast here, you can't see them at
[01:00:54.040 --> 01:01:00.200]   all anymore, these secondary lobes. Okay, then if you actually think of the Gaussian, what is a Gaussian?
[01:01:00.200 --> 01:01:07.080]   Anybody of you here of the central limit theorem? That's also a way to get to the Gaussian, right?
[01:01:07.080 --> 01:01:11.800]   So the Gaussian is actually convolution of infinite amount of convolutions of boxes or other things
[01:01:11.800 --> 01:01:17.640]   with it, like you convolve every possible shape, like you keep convolving, eventually you'll end up
[01:01:17.640 --> 01:01:27.240]   with a Gaussian. In particular, if you would keep convolving boxes, oops, sorry, if you keep convolving,
[01:01:27.240 --> 01:01:31.320]   you know, so you get like this and you reconvolve that with itself and you reconvolve that with
[01:01:31.320 --> 01:01:35.480]   and so on, you keep going, you'll eventually have a Gaussian. That's what the central limit theorem says.
[01:01:36.920 --> 01:01:41.640]   So in a sense, if we keep going from, you know, the original square and then we
[01:01:41.640 --> 01:01:45.000]   convolve it with itself and then we would keep convolving in the limit, that's what we get.
[01:01:45.000 --> 01:01:53.560]   Interestingly enough. And then of course we have the, even further, so this one is the one that is
[01:01:53.560 --> 01:02:00.120]   kind of as compact as possible in both domains, right? This one is very compact in a spatial domain,
[01:02:00.120 --> 01:02:05.480]   but very non-compact in the frequency domain. This one is the opposite, the one that's the
[01:02:05.480 --> 01:02:11.880]   best trade-off between both is the Gaussian. So it's spatially a Gaussian, it's in the Fourier
[01:02:11.880 --> 01:02:18.600]   domain also a Gaussian. And then here is the perfect reconstruction filter, except that it's,
[01:02:18.600 --> 01:02:24.040]   it has a really large extent. And to not make errors, you need to actually, so it's not a
[01:02:24.040 --> 01:02:31.240]   practical one. So practically people would either use this or use the Gaussian.
[01:02:35.160 --> 01:02:44.200]   Okay, so here's an example of designing the perfect low-pass filter. Okay, so it's not very
[01:02:44.200 --> 01:02:49.000]   complicated. So here you have the original, an image here with some, you know, some specific
[01:02:49.000 --> 01:02:55.480]   patterns and this and that. You take the, this is only MATLAB, you take the Fourier transform,
[01:02:55.480 --> 01:03:01.880]   you get this. Notice that these strong edges in certain orientations are also showing up here
[01:03:01.880 --> 01:03:06.520]   in those frequencies, with high frequencies in those particular orientations, so on.
[01:03:06.520 --> 01:03:14.200]   Then if you want to low-pass filter this, well, you would want to essentially
[01:03:14.200 --> 01:03:20.520]   multiply this with a low-pass filter, a perfect low-pass filter. In this case in 2D, it would be,
[01:03:20.520 --> 01:03:26.600]   you could do a circle. And then essentially the product would be this. Okay, so that's a
[01:03:26.600 --> 01:03:32.040]   perfect low-pass filter. Essentially everything here is preserved, everything outside of a
[01:03:32.040 --> 01:03:37.400]   particular frequency range is exactly moved to zero. That's essentially the result here.
[01:03:37.400 --> 01:03:49.320]   So this also shows that the kind of perfect low-pass filter is not only by suppressing these
[01:03:50.200 --> 01:03:56.520]   low-pass, by suppressing these high frequencies, we see that we do get some kind of funny artifacts
[01:03:56.520 --> 01:04:03.400]   here. So we get kind of ghost boundaries to show up and so on. So just doing a perfect low-pass
[01:04:03.400 --> 01:04:09.400]   filtering is maybe also not what we want. The problem is that this filter has an infinite extent.
[01:04:09.400 --> 01:04:16.920]   And so it's kind of, if you want to suppress something like this strong edge here, you kind
[01:04:16.920 --> 01:04:21.800]   of create ghost edges kind of in parallel, like here also, because of this infinite extent of
[01:04:21.800 --> 01:04:29.480]   this filter. So although conceptually it might seem like the thing you want has a really nice
[01:04:29.480 --> 01:04:35.320]   property of exactly zeroing out those frequencies. The fact that the frequencies actually often,
[01:04:35.320 --> 01:04:42.200]   when you have a hard edge, it's a correlation of high and low frequencies. And then being too abrupt
[01:04:42.200 --> 01:04:48.440]   in killing frequencies off actually creates also some, you know, undesired effects or so. The
[01:04:48.440 --> 01:04:55.560]   fact that it's highly non-local. So that's where also the Gaussian typically comes out better.
[01:04:55.560 --> 01:05:00.520]   Here's a little video. Let me show that.
[01:05:00.520 --> 01:05:09.880]   Okay. So what you see here is essentially the kind of perfect filter
[01:05:11.960 --> 01:05:17.400]   applied. And so not only a perfect low-pass filter, but also band-pass filter. Okay.
[01:05:17.400 --> 01:05:22.920]   Literally, it was just keeping a particular, you know, frequency exactly. Let me replay it.
[01:05:22.920 --> 01:05:25.480]   Actually, I'm going to do like this.
[01:05:25.480 --> 01:05:35.560]   So you see this kind of initially just blurred image, but then you start seeing these artifacts
[01:05:35.560 --> 01:05:43.880]   that move around. Right? This is now band-pass. Very narrow band-pass. So you see that each of
[01:05:43.880 --> 01:05:49.320]   those is exactly one kind of frequency of patterns in all orientations mixed together. That shows up.
[01:05:50.520 --> 01:06:07.880]   Okay. Then, so one way to model or, you know, like we discussed earlier,
[01:06:07.880 --> 01:06:15.240]   essentially one way to, if you have a sharp image to model kind of blur,
[01:06:16.600 --> 01:06:24.520]   can be done with filters. What it kind of physically corresponds to is something else
[01:06:24.520 --> 01:06:32.520]   drawn here. So say that you have a point here in space. As we discussed, to get enough light
[01:06:32.520 --> 01:06:39.320]   to the sensor. So the sensor is here. This is the lens. If you just do a pinhole camera with
[01:06:39.320 --> 01:06:45.720]   a very small hole here, you get one light ray and then the image would be sharp from any distance,
[01:06:45.720 --> 01:06:52.440]   essentially, but you'd get a very dark image. So if you want to aggregate not light in a single
[01:06:52.440 --> 01:06:58.280]   ray, single direction, but you actually want to take a bigger cone of light. I mean, it's a very
[01:06:58.280 --> 01:07:02.600]   small cone of light, but a cone of light from the point where you are to the size of the lens,
[01:07:02.600 --> 01:07:10.360]   that kind of cone. And then, you know, and take that as kind of the light coming from this point
[01:07:10.360 --> 01:07:17.400]   here in the scene, then you need to make sure that you're, you know, the distance between the lens
[01:07:17.400 --> 01:07:22.840]   and the sensor is such that ideally you would actually, for this point, you would actually
[01:07:22.840 --> 01:07:26.920]   move your sensor a little bit closer so that it's here and you get a perfectly sharp image.
[01:07:26.920 --> 01:07:33.080]   Like in this case, if it's a little bit off, then you essentially get a little bit of blurring.
[01:07:33.080 --> 01:07:41.240]   You get a light to be spread out over a region. And so that's this blurring, but so in a sense for
[01:07:41.240 --> 01:07:47.560]   blurring that would correspond to this effect, you can obtain that by doing in the image a
[01:07:47.560 --> 01:07:57.880]   filtering operation, a convolution of this blurring kernel with the image, and then you go from that
[01:07:57.880 --> 01:08:06.440]   image to that image. This would be kind of if you had it for a pixel that's at the right distance
[01:08:06.440 --> 01:08:14.840]   for this focal length, you would have a sharp image, for example. And that's actually, it's
[01:08:14.840 --> 01:08:21.560]   actually symmetric the other way around, it would also be spread out, right? So that was the focus
[01:08:21.560 --> 01:08:27.640]   blur, then you can also have motion blur as we already briefly discussed. So here we'll assume
[01:08:27.640 --> 01:08:35.080]   we have a very simple model. So again, how do we mathematically represent this? And then potentially
[01:08:35.080 --> 01:08:41.080]   how can we undo the effect? So here we look at how we can restore that image. So that was like,
[01:08:41.080 --> 01:08:45.560]   let's say the original, or that would be the image we would like to have. This would be,
[01:08:45.560 --> 01:08:52.040]   we'd assume that somewhere underlying this pattern, but the image we get is this. And then what we'd
[01:08:52.040 --> 01:08:56.840]   like is from this image to go back to this image here, to extract this image from that image,
[01:08:56.840 --> 01:09:03.320]   or as close as possible. So to do that, what we'll do is we'll first model the effect that models
[01:09:03.320 --> 01:09:08.600]   from the image we wanted, how we ended up with an image like this here. We tried to physically
[01:09:08.600 --> 01:09:14.760]   model that. We model that with, we use these symbols, we assume that it's just in one dimension
[01:09:14.760 --> 01:09:24.600]   that it's blurred out in the horizontal dimension. And we'll use this step function here in this
[01:09:24.600 --> 01:09:31.480]   way to model it's zero. It goes to one for a while, and then it goes back to zero because we subtract
[01:09:31.480 --> 01:09:39.960]   minus one the step function after a while. So this way you see here, you get plus L here,
[01:09:39.960 --> 01:09:44.760]   and then minus, and then the function with minus L here. And so the combination is that
[01:09:44.760 --> 01:09:52.680]   from minus L to plus L, you have one, and outside of that you have zero. So you have a finite
[01:09:53.240 --> 01:09:58.600]   region here that's over which you integrate. In the other dimension, in the x2 dimension,
[01:09:58.600 --> 01:10:04.760]   the vertical direction, so this is blurring this way, modeling blurring this way. In the vertical
[01:10:04.760 --> 01:10:12.440]   direction, you essentially have still a Dirac impulse, so there's just a single, essentially
[01:10:12.440 --> 01:10:21.080]   a single pixel after sampling. You'll have a single pixel here. Okay, so that's our model for what's
[01:10:21.080 --> 01:10:29.720]   happening. And so we assume that there is such a function here, the one we would like to find back,
[01:10:29.720 --> 01:10:35.160]   but there was this filter applied to it that generated this image. This is the one we observed,
[01:10:35.160 --> 01:10:43.240]   the blurred image. And now what we would like is to get, apply another filter that actually somehow
[01:10:43.240 --> 01:10:51.720]   inverts the effect of the first filter. Okay, so what we're interested in is to compensate the
[01:10:51.720 --> 01:10:57.240]   effect of the image degradation. And so essentially we want that one filter convolved through the other
[01:10:57.240 --> 01:11:03.240]   filter should actually just give us perfectly preserved the function, so essentially just be
[01:11:03.240 --> 01:11:11.320]   the original sampling function. So you could kind of try to think of, okay, I have this
[01:11:12.360 --> 01:11:20.360]   convolution with this block, so how do I find the function that will, another function with
[01:11:20.360 --> 01:11:26.120]   another shape that if I apply one after the other, I convolve one with the other, I now get back the
[01:11:26.120 --> 01:11:32.760]   original function back, so that I get the Dirac impulse. Okay, so in the spatial domain,
[01:11:32.760 --> 01:11:36.520]   it's, you know, like there would be, I wouldn't know how to start it or so.
[01:11:36.520 --> 01:11:41.240]   But in the frequency domain, it's actually pretty straightforward, because in the frequency domain,
[01:11:41.240 --> 01:11:48.680]   it's just an individual frequency per frequency product. Okay, so if we don't look at h and h
[01:11:48.680 --> 01:11:54.360]   tilde, but we look in the frequency domain, we just have the constraint, right, instead of this
[01:11:54.360 --> 01:11:59.400]   constraint, which I really don't know how to solve, we now have this constraint, which is
[01:11:59.400 --> 01:12:07.720]   the Fourier transform of our filter times the Fourier transform, so the filter, the
[01:12:07.720 --> 01:12:11.640]   restoration filter run to apply, times the Fourier transform of the degradation filter,
[01:12:11.640 --> 01:12:18.920]   the blurring filter, the product of those two should be one. Okay, so that essentially, if we
[01:12:18.920 --> 01:12:24.600]   know this filter and we know its frequency response, we just have to do one over that number for each
[01:12:24.600 --> 01:12:28.680]   of the separate frequencies. This is why it's important, every frequency is treated fully
[01:12:28.680 --> 01:12:34.120]   separately, right? So it's very easy, you know, okay, for this frequency, the original filter
[01:12:34.120 --> 01:12:39.400]   divided this frequency by two, well, I just multiply it by two and done, right? And so you
[01:12:39.400 --> 01:12:44.920]   can immediately construct this function, I simply run over that function, and you would be done,
[01:12:44.920 --> 01:12:55.960]   essentially. Okay, yeah, so these could be different functions depending on for also,
[01:12:55.960 --> 01:13:01.400]   also these other effects before, we'll do it here for that, but you could also apply it for this one,
[01:13:01.400 --> 01:13:06.440]   for example. If you know this filter, you know, you're looking at Fourier domain, you do one over
[01:13:06.440 --> 01:13:16.040]   the filter, etc. Okay, but let's now look concretely at this one, okay? If we take the Fourier,
[01:13:16.040 --> 01:13:22.440]   we compute the Fourier transform and so on, we get, actually no surprise, we already looked at it
[01:13:22.440 --> 01:13:29.960]   many times, a box, this was just a box, right, in this one dimension. The Fourier transform of the
[01:13:29.960 --> 01:13:39.000]   box is this function here, this thing function, so the, you know, the sine divided by, so sine
[01:13:39.000 --> 01:13:44.840]   divided, you know, of sine of x divided by x, essentially, right? So it's this function that
[01:13:44.840 --> 01:13:51.400]   goes like this and slowly extinguishes out, and now we just do one over this function, easy, done.
[01:13:51.400 --> 01:13:59.000]   Okay, so that was the original function, now we do one over it, okay, so this is actually,
[01:13:59.000 --> 01:14:05.240]   we have a problem, because obviously there's a lot of zeros in this function, and well, one over
[01:14:05.240 --> 01:14:13.640]   zero is not a great idea, so essentially, we, like, we have a problem there, there are some values
[01:14:13.640 --> 01:14:18.440]   that actually, some frequencies we actually completely lost, some frequencies are just gone,
[01:14:18.440 --> 01:14:24.200]   they've been numerically eliminated, and so those we can just not recuperate, and trying to recuperate
[01:14:24.200 --> 01:14:29.960]   this is, them is a pretty bad idea, because value is pretty close to this here, to this, this value
[01:14:29.960 --> 01:14:35.400]   that's zero, but it's pretty close to that, it will also be, you know, they've been almost suppressed,
[01:14:35.400 --> 01:14:40.440]   so there's the value that's suppressed, that's one thing, but then there's the value that's not
[01:14:40.440 --> 01:14:46.040]   fully disappeared, but it's divided by a thousand, so now you take the number and you multiply by a
[01:14:46.040 --> 01:14:50.280]   thousand, then you get something very unstable, right, if there was any noise, boom, you know,
[01:14:50.280 --> 01:14:57.560]   it explodes, you multiply your noise by a thousand, so that's a bad idea, okay, so how do we address
[01:14:57.560 --> 01:15:03.000]   this in practice, you can do something like this here, okay, so to kind of regularize a bit, instead
[01:15:03.000 --> 01:15:13.560]   of doing one over F as the filter, the reconstruction filter, you do F divided by F squared plus a small
[01:15:13.560 --> 01:15:20.600]   number, okay, for example, you know, something that essentially is one twentieth or so, okay,
[01:15:20.600 --> 01:15:25.960]   for example, I think it's something like this that was used here, so like five percent or so,
[01:15:25.960 --> 01:15:30.920]   zero point zero five or so, and then it means that when this number gets very close to zero,
[01:15:30.920 --> 01:15:34.760]   this one starts dominating, and so you saturate at the ratio of those two numbers,
[01:15:36.360 --> 01:15:44.200]   and, or so, sorry, when this one gets very small, you know, this one disappears to zero,
[01:15:44.200 --> 01:15:47.320]   and then you get a small number divided by epsilon, okay,
[01:15:47.320 --> 01:15:53.080]   and so essentially that function then looks like something like this here,
[01:15:53.080 --> 01:16:00.840]   okay, so you see it saturates at the particular value, and so it will kind of avoid these,
[01:16:01.480 --> 01:16:05.480]   the kind of the, to blow up some values to something too large,
[01:16:05.480 --> 01:16:16.840]   and so essentially for the, yeah, so that's essentially what you get here,
[01:16:16.840 --> 01:16:24.360]   okay, so that, actually sorry, so does that make sense to everyone?
[01:16:28.120 --> 01:16:31.800]   So this essentially in the frequency domain, we can very easily do the inverse,
[01:16:31.800 --> 01:16:37.080]   the only problem is that there's actually, if the frequency disappears, it's gone,
[01:16:37.080 --> 01:16:41.880]   and so you have to drop it, okay, this is kind of what you are seeing here actually, right,
[01:16:41.880 --> 01:16:46.440]   these lost frequencies here, because of the finite extent of the shutter,
[01:16:46.440 --> 01:16:51.800]   this would essentially really have some frequencies completely disappear,
[01:16:51.800 --> 01:16:55.880]   and so there's no way to recuperate that pattern, that frequency,
[01:16:55.880 --> 01:17:01.960]   that's kind of the artifacts you saw here, here by actually having a mix of many different boxes,
[01:17:01.960 --> 01:17:11.960]   what you get is that, sorry, this function here, you know, you get like the zeros,
[01:17:11.960 --> 01:17:16.040]   like this has zeros in some places, but because you do many of different sizes,
[01:17:16.040 --> 01:17:18.840]   it means different widths, and you sum them all up and so on,
[01:17:18.840 --> 01:17:23.160]   and so you end up not having zeros, so the way that they did it here,
[01:17:23.160 --> 01:17:29.000]   it somehow avoids having zeros, okay, so let me now talk a little bit about
[01:17:29.000 --> 01:17:32.200]   space-time super resolution as an example,
[01:17:32.200 --> 01:17:43.000]   so you know, this shows a little bit the issues that we also saw with the wheel, right,
[01:17:43.000 --> 01:17:47.800]   so things look like they start turning in the other direction and so on, so you get everything,
[01:17:52.040 --> 01:17:57.960]   the here, this was an example where they would record with normal videos,
[01:17:57.960 --> 01:18:05.160]   normal video camera from many different, almost, you know, like cameras put next to each other,
[01:18:05.160 --> 01:18:12.520]   so they have many copies, and then they try to essentially reconstruct, you know, the signal,
[01:18:12.520 --> 01:18:19.560]   right, so I don't know if there's, yeah, okay, so if you look at these here, it's really completely
[01:18:19.560 --> 01:18:24.920]   blurred, I mean, it's, one is quite blurred, but it's also very sparse, it's here and then here and so on,
[01:18:24.920 --> 01:18:32.840]   but they managed to essentially align this, maybe actually was doing it, no, okay, anyway, so
[01:18:32.840 --> 01:18:42.760]   anyway, so here they managed to reconstruct the continuous nice full temporal resolution signal,
[01:18:45.720 --> 01:18:51.720]   this is a little bit, you know, what's going on here, so the input is blurry frame,
[01:18:51.720 --> 01:19:01.320]   but many of those, what you see here is kind of the input images, this is kind of the aperture
[01:19:01.320 --> 01:19:11.160]   of a single image, so it's kind of blurred out over, so the red here is, so the red here is the
[01:19:13.240 --> 01:19:19.480]   exposure you want to generate in the end, okay, so you want a sharp video at high frame rate in the
[01:19:19.480 --> 01:19:27.480]   end, and what they get is frames of these low frame rate and also in particular limited exposure
[01:19:27.480 --> 01:19:35.000]   time here, and so essentially they want to reconstruct at this frame rate here, okay,
[01:19:37.160 --> 01:19:44.360]   the, I think here they required 15 cameras to be able to do this reconstruction, it gets easier if
[01:19:44.360 --> 01:19:51.320]   the difference between the input exposure and the output is not too big, but essentially they were
[01:19:51.320 --> 01:19:57.080]   able to do a really good job here, and then if you remember we saw briefly an example and I show
[01:19:57.080 --> 01:20:03.960]   an example afterwards, if you do super resolution in the spatial domain, it turns out to be a lot
[01:20:03.960 --> 01:20:10.440]   harder, okay, so here in a temporal domain they managed to actually get really high quality
[01:20:10.440 --> 01:20:15.400]   reconstruction, so they get this as input and they can generate this as output, you see actually
[01:20:15.400 --> 01:20:21.720]   it's a factor of five, they only need 15 images, 15 cameras, and they managed to up sample by a factor
[01:20:21.720 --> 01:20:29.480]   of five the actual temporal resolution, okay, I kind of did it when we saw it in the first
[01:20:29.480 --> 01:20:38.840]   or second lecture that when you try to do super resolution spatially it's very hard to get beyond
[01:20:38.840 --> 01:20:45.480]   the factor of one or two or two or three at most or so, here with 15 images they get a factor of
[01:20:45.480 --> 01:20:56.120]   five in this example here, now why is that? Well it's because the, if you look at the temporal blur
[01:20:57.960 --> 01:21:05.000]   it's actually has very hard edges because it's actually something that you, you know, you switch
[01:21:05.000 --> 01:21:09.000]   the camera on and off or you have a shutter or you have something, but it's not that you kind of
[01:21:09.000 --> 01:21:14.920]   have opened the pixel, like smoothly open the pixel and then smoothly close it, it's actually on/off,
[01:21:14.920 --> 01:21:22.600]   so in other words, although this is blurred out here, it's actually a very sharp edge here and a
[01:21:22.600 --> 01:21:27.960]   very sharp edge here, you can kind of see how if you subtract this from another one that shifted
[01:21:27.960 --> 01:21:32.440]   a little bit, you can kind of easily reconstruct this or so, like as a difference between the two
[01:21:32.440 --> 01:21:40.440]   in some sense, so that's essentially what's happening here because it's a very sharp peak here
[01:21:40.440 --> 01:21:46.280]   they actually have, you know, in the frequency domain something with these additional lobes here
[01:21:46.280 --> 01:21:51.880]   and so these frequencies are not suppressed, they're still kind of there, okay, in the signal,
[01:21:51.880 --> 01:21:58.440]   so you do somehow measure things that higher frequencies are preserved essentially here, right,
[01:21:58.440 --> 01:22:03.880]   so you, the temporal blur does this, it means that it doesn't really suppress some of those higher
[01:22:03.880 --> 01:22:08.600]   frequencies, so you lose, you lose some of them as we saw, but essentially you, you do preserve
[01:22:08.600 --> 01:22:21.240]   things also in the higher frequencies, in the spatial case the, we actually have the, the combination
[01:22:21.240 --> 01:22:27.320]   of the lens and the pixels and all of this, actually even on purpose, we make sure that this is
[01:22:27.320 --> 01:22:35.560]   essentially blurring a little bit and so that we have our sampling rate kind of essentially
[01:22:35.560 --> 01:22:45.240]   correspond to, so we essentially have a smooth, a smooth line here and typically we'll have some,
[01:22:46.040 --> 01:22:52.040]   if you look at the optical lens on, we'll have a kind of essentially something that looks like a
[01:22:52.040 --> 01:22:58.280]   Gaussian in terms of suppressing high frequency, so in the sampling of the pixels we don't have like
[01:22:58.280 --> 01:23:03.320]   very sharp boundaries there, we actually have something that's,
[01:23:03.320 --> 01:23:11.800]   we have something that has a very smooth extinction here and quite fast and so the Fourier transform
[01:23:12.840 --> 01:23:17.160]   ends up being something that is actually quite sharp and
[01:23:17.160 --> 01:23:25.000]   so this, of the spatial blur and so it doesn't have these secondary lobes and so on
[01:23:25.000 --> 01:23:32.760]   and now if you want to do super resolution we'll try to take essentially this frequency here
[01:23:32.760 --> 01:23:39.720]   and boost it back, you know, to the original one which, okay if I go a little bit here I can
[01:23:39.720 --> 01:23:45.000]   still do it but you can see that if I try from here and I try to take whatever value I have here
[01:23:45.000 --> 01:23:54.520]   and boost it back to here it's just going to be impossible, okay, so here's kind of essentially
[01:23:54.520 --> 01:24:03.800]   a slide on spatial super resolution, so we have essentially a combination, so our filter looks
[01:24:03.800 --> 01:24:09.960]   like a combination of the point spread function, the focus of the lens not being perfect, so the
[01:24:09.960 --> 01:24:16.440]   light that comes in from a certain point will kind of spread itself a little bit out on the sensor
[01:24:16.440 --> 01:24:22.280]   and we actually also have the pixel itself, the sensor is kind of a, you know, a typically
[01:24:22.280 --> 01:24:27.400]   rectangular, small rectangular array, the combination of those two, the convolution of those two
[01:24:27.400 --> 01:24:32.120]   will essentially give us, you know, something that also looks like a Gaussian, something that looks
[01:24:32.120 --> 01:24:39.480]   like this, okay, so this is kind of our spatial filter sampling or, you know, before the sampling,
[01:24:39.480 --> 01:24:46.040]   so before we sample we'll have the original signal kind of somehow convolved with this here,
[01:24:46.040 --> 01:24:51.640]   that's our model essentially, a slight blur of the lens plus the fact that we actually aggregate
[01:24:51.640 --> 01:24:58.120]   over a pixel, that combination gives us a filter that looks like this roughly, so the original
[01:24:58.120 --> 01:25:03.000]   signal gets perturbed by this, if we want to do super resolution we want to invert that H filter
[01:25:03.000 --> 01:25:15.800]   essentially, okay, so the, and so if we do low resolution you can see this, the low resolution
[01:25:15.800 --> 01:25:27.000]   image can be modeled as a decimation filter times this filter here, times then, and then there's,
[01:25:27.000 --> 01:25:32.600]   okay, so there's the original high resolution image, a geometric warp that would, depending on
[01:25:32.600 --> 01:25:38.360]   the random image you take would have been slightly shifted, so it's exactly where you sample for a
[01:25:38.360 --> 01:25:44.680]   particular image, so you have the high res image, you shift it so that it's in front of the pixels
[01:25:44.680 --> 01:25:51.400]   of the lowest image, that's the gate here, and then the H is this blurring filter, and then the D
[01:25:52.360 --> 01:25:56.920]   is the decimation, it's only taking one out of two pixels or so, so going from the high resolution
[01:25:56.920 --> 01:26:02.840]   image to the low resolution image, okay, simplified, you could write it like this here,
[01:26:02.840 --> 01:26:09.720]   and you can actually permute those, these filters, it's, it's, they can be permuted,
[01:26:09.720 --> 01:26:19.400]   doesn't change anything in the operations, gay shift invariant, the, and commutes with H,
[01:26:20.840 --> 01:26:31.240]   so we can switch them, and so first we, so we have, what we try to do is to compute
[01:26:31.240 --> 01:26:41.480]   the high resolution image convolved with this, this pixel, you know, sensing essentially,
[01:26:41.480 --> 01:26:49.960]   so we'll try to reconstruct that first, and then after that we'll try to do the inversion of the H,
[01:26:50.600 --> 01:27:01.480]   the H blurring kernel, okay, so, so to compute this here, what we'll do is we have all these
[01:27:01.480 --> 01:27:05.160]   slightly shifted images, so first thing we need to do is actually compute that relative shift
[01:27:05.160 --> 01:27:10.440]   between all those images, so to do super resolution, there was a, I showed you a video in one of the
[01:27:10.440 --> 01:27:15.800]   first slides, essentially it's kind of, they took it, for example, you have, with a camera you move
[01:27:15.800 --> 01:27:20.120]   a little bit, so you, it shifts a little bit, it means that the exact samples are moving a little
[01:27:20.120 --> 01:27:26.920]   bit around, what you try to do is to reconstruct this combined image here, as precisely as possible,
[01:27:26.920 --> 01:27:33.320]   right, so you first need to make sure you somehow can figure out how to align those images, now,
[01:27:33.320 --> 01:27:37.000]   if it's really the same image with just a slight shift of the sensor of the camera,
[01:27:37.000 --> 01:27:43.800]   then all those should be the same, and you can do a global warp and compute that for sub pixel
[01:27:43.800 --> 01:27:49.400]   shifts so that they all align as well as possible to each other, so assuming you can do that well,
[01:27:49.400 --> 01:27:54.200]   and you've been able to compute, let's say, the exact positioning of all those slightly shifted
[01:27:54.200 --> 01:28:01.800]   images with respect to each other, then you can accumulate them all on top of each other,
[01:28:01.800 --> 01:28:08.200]   and average out the results, okay, by averaging out the results, you can essentially get rid of
[01:28:08.200 --> 01:28:17.080]   noise, you can get more precise measurement of the values, but the problem is you'll only improve
[01:28:17.080 --> 01:28:22.760]   the signal to noise ratio, as you know from combining measurements, you only ameliorate
[01:28:22.760 --> 01:28:32.440]   at square root of n type of rate of improving your measurements, right, if you take the average of a
[01:28:32.440 --> 01:28:40.360]   thousand numbers, of a hundred numbers, you'll only be ten times as good as taking the original
[01:28:40.360 --> 01:28:45.080]   measurement or so, right, so if you average a hundred measurements, you'll be ten times as good
[01:28:45.080 --> 01:28:50.680]   as the, in terms of uncertainty as the, as a single measurement by itself, right, it goes with the
[01:28:50.680 --> 01:28:59.880]   square root in terms of the variance, reduces only with the square root, so by adding, averaging
[01:28:59.880 --> 01:29:04.920]   out many images, you get a better and better estimate, but only improvement at this rate here,
[01:29:04.920 --> 01:29:13.400]   by adding many images together, the problem is that if you look at this blurring kernel here,
[01:29:14.120 --> 01:29:21.480]   as we've seen, it actually decreases with a kind of a double exponential, and so the value is as
[01:29:21.480 --> 01:29:26.680]   you go further down from your Gaussian peak, you know, here it's still easy and a little bit up to
[01:29:26.680 --> 01:29:31.400]   here, but then it actually goes down very, very fast from there, and so if you want to go from a
[01:29:31.400 --> 01:29:37.320]   factor of two increase in resolution to a factor of three or four in resolution, you need to overcome
[01:29:37.320 --> 01:29:44.760]   the fact that it's gone down from, you know, 66% to 5% to 1% to a thousand, you know, to a thousand,
[01:29:44.760 --> 01:29:51.000]   etc., in, in, you know, every time you go a little bit further, and so that's kind of the intrinsic
[01:29:51.000 --> 01:29:57.160]   limit is you can keep adding more images, but you only get, you know, if you now need to go from
[01:29:57.160 --> 01:30:04.040]   three sigma to four sigma, you know, the gap is so big that you need to take, you know,
[01:30:04.040 --> 01:30:08.360]   orders of magnitude more images to average, and then it's assuming that you can all perfectly
[01:30:08.360 --> 01:30:15.480]   align them and so on and so on and so on, and so essentially this is really kind of hopeless
[01:30:15.480 --> 01:30:21.480]   beyond a certain point of factor two or three, except some military cameras and satellites and so on,
[01:30:21.480 --> 01:30:25.320]   they can of course make sure that they don't have something that looks like this,
[01:30:25.320 --> 01:30:30.680]   but that they have actual special lenses and things that actually will preserve a lot of
[01:30:30.680 --> 01:30:36.360]   high frequencies, and then you can actually do super resolution potentially, right? Okay, so that's
[01:30:36.360 --> 01:30:43.640]   it for today. In terms of next week, we'll look at beyond the Fourier transform to other types of
[01:30:43.640 --> 01:30:53.880]   transforms, both wavelet transforms, which we've seen kind of this problem with Fourier, that
[01:30:53.880 --> 01:30:59.640]   there's actually for hard edges and things like this, and in real scenes you often have hard edges
[01:30:59.640 --> 01:31:05.160]   and so on. It's a challenge because all those, those are all the frequencies together, so you have
[01:31:05.160 --> 01:31:09.320]   a lot of frequencies that are correlated that you exactly have to align to reconstruct the image
[01:31:09.320 --> 01:31:17.080]   properly and so on. Wavelets are in a sense going to try to avoid that. Wavelets are both have a
[01:31:17.080 --> 01:31:21.800]   frequency component, but also a location component. Remember Fourier was global over the whole image.
[01:31:21.800 --> 01:31:28.520]   Here will do things, wavelets are a combination of they're both local, but they're also, they're
[01:31:28.520 --> 01:31:32.760]   both local in the frequency domain and in the spatial domain, typically. They have this, they
[01:31:32.760 --> 01:31:40.280]   bound in both spaces. Those are generic ones. We'll also look very specifically at can we find
[01:31:40.280 --> 01:31:46.760]   transformations for particular types of image collections? For example, faces. Can we, by
[01:31:46.760 --> 01:31:52.040]   knowing we look at faces that our image collection is about faces, can we do something more interesting
[01:31:52.040 --> 01:31:57.000]   than just assuming that it's generic images of, you know, anytime? So that's what we'll look at next
[01:31:57.000 --> 01:32:05.000]   week. Okay, I'll leave you with that.

